---
title: "Advanced Data Analysis - Project 2"
subtitle: MLR with Confounding and Interaction
author: "Sean Vieau"
date: "October 9, 2024"
output: html_document
toc: true
---

```{r setup, include=FALSE}
# Sets the default for all chunks as echo = TRUE (ensures they show unless specified not to)
knitr::opts_chunk$set(echo = TRUE)

# Create a function to pretty print our dataframes
pretty_print <- function(x) {
  kable(x, format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
}

# Create a function to pretty print useful parameters of a regression model
model_results <- function(x) {
  # Create a table of the coefficients of the model
  coefficients_ <- summary(x)$coefficients[]
  
  # Perform Bonferroni correction 
  p_values <- summary(x)$coefficients[,4] # This line selects the fourth column of the resulting coefficients      table from summary(model), which is the p-values
  p_adjusted <- p.adjust(p_values, method = "bonferroni")
  
  # Get the 95% CIs
  conf_intervals <- confint(x)
  
  # Compare adjusted p-values to unadjusted p-values, with 95% CI's
  model_output <- cbind(coefficients_, p_adjusted, conf_intervals)
  
  # Pretty print results
  pretty_print(model_output)
}

# Set options to avoid scientific notation
options(scipen = 999)
```

# Introduction

The aim of the current study is to assess how treatment response differs for HIV+ patients 2 years after initiating Highly Active Antiretroviral Therapy (HAART) based on hard drug usage (such as heroin or cocaine). This study is of particular scientific interest because it is unclear whether the use of hard drugs inhibits the immune system in humans; treatment strategies may differ based on these results. The researchers are interested in comparing subjects who never used hard drugs to current hard drug users (those that use hard drugs at year 2) or previous hard drug users (those who used drugs at year 0 or 1). Outcomes of interest are: viral load (HIV copies in a mL of blood), CD4+ T cell count (a measure of immunologic health), and aggregate physical and quality of life scores from the SF-36.

The clinical hypothesis is that, if hard drugs inhibit the immune system in humans, subjects who currently or previously used hard drugs will have higher viral load and lower CD4+ T cell counts than those who never used hard drugs. Additionally, the researchers are interested in knowing if potential differences between the drug use groups can be explained by differences in adherence to the treatment regimen. The researchers are agnostic on how quality of life changes after treatment, since side effects of the treatment are significant.

The project description provided by the PI is available below:

::: {style="text-align: center;"}
<img src="/Project_2/Project_2_R/Media/Project2_description1.png" width="85%"/>
:::

# Method


**Study Design**

This is a secondary data analysis of the Multicenter AIDS Cohort Study, an ongoing prospective cohort study investigating the natural and treated disease progression of HIV-1 in bisexual men in 4 major cities in the U.S. Measurements for all variables were taken once per year over an 8-year time period; however, the current analysis is only concerned with treatment outcomes after 2 years of HAART. Data was received as a longform .csv file containing 33 columns along with a data dictionary. The main outcomes of interest are viral load, CD4+ T cell count, and aggregate physical and quality of life scores. Adherence to treatment regiment will be investigated as a potential confounder.

Potential covariates of interest include: marijuana usage since last visit and frequency of usage, income, BMI, high blood pressure, diabetes, liver disease stage 3 / 4, kidney disease, frailty related phenotype, total cholesterol, triglycerides, fasting LDL, dyslipidemia, depression score, smoking status, alcohol use since last visit, heroin or opiate use since last visit, intravenous drug use since last visit, race, education at baseline, age, if they took ART at the visit or if they have ever taken it before, and years since initiating ART.

# Data Preparation

First we load the necessary packages

```{r, message = FALSE}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(plotly) # Used for interactive plots
library(naniar) # Used to visualize missing data
library(kableExtra) # Used for pretty printing (kable_styling)
library(table1) # Used to make Table 1
library(tidyr) # Used for reshaping
library(bestNormalize) # Used in selecting best transformation for a variable
library(corrplot) # Used to make the correlation matrix
library(corrtable) # used to make the table for the correlation matrix
library(interactions) # Easy plotting of interactions
library(car) # Used to get VIFs
library(olsrr) # used for backwards elimination model.
```

Then we import the data set.

```{r, message = FALSE}
# Read in data
data <- read_csv("C:\\Users\\sviea\\Documents\\Portfolio\\Project_2\\Project_2_R\\RawData\\hiv_dataset.csv")
```

And take a look.

```{r}
# Examine data
glimpse(data)
```

Everything appears properly imported, however all our categorical variables are coded as doubles.

## Labeling Categorical Variables

Let's factor and label our categorical variables so they are appropriately represented (and not doubles, which will yield incorrect results in models)

```{r, results='hide'}
# Converting all appropriate variables from doubles to categorical variables

data$HASHV <- factor(data$HASHV,
                     levels = c(1, 2),
                     labels = c("No", "Yes"))

data$HASHF <- factor(data$HASHF,
                     levels = c(0, 1, 2, 3, 4),
                     labels = c("Never", "Daily", "Weekly", "Monthly", "Less Often"))

data$income <- factor(data$income,
                      levels = c(1, 2, 3, 4, 5, 6, 7, 9),
                      labels = c("Less than $10,000", "$10,000-$19,999", "$20,000-$29,999", "$30,000-$39,999", "$40,000-$49,999", "$50,000-$59,999", "$60,000 or more", "Do not wish to answer"))

data$HBP <- factor(data$HBP,
                   levels = c(1, 2, 3, 4, 9, -1),
                   labels = c("No", "Yes", "No, based on data trajectory", "Yes, based on data trajectory", "Insufficient data, may include reported treatment without diagnosis", "Improbable Value"))

data$DIAB <- factor(data$DIAB,
                    levels = c(1, 2, 3, 4, 9),
                    labels = c("No", "Yes", "No, based on data trajectory", "Yes, based on data trajectory", "Insufficient data"))
                      
data$LIV34 <- factor(data$LIV34,
                     levels = c(1, 2, 9),
                     labels = c("No", "Yes", "Insufficient Data"))

data$KID <- factor(data$KID,
                   levels = c(1, 2, 3, 4, 9),
                   labels = c("No", "Yes", "No, based on data trajectory", "Yes, based on data trajectory", "Insufficient data"))

data$FRP <- factor(data$FRP,
                   levels = c(1,2,9),
                   labels = c("No", "Yes", "Insufficient Data"))

data$FP <- factor(data$FP,
                  levels = c(1,2,9),
                  labels = c("No", "Yes", "Insufficient Data"))

data$DYSLIP <- factor(data$DYSLIP,
                      levels = c(1, 2, 3, 4, 9),
                      labels = c("No", "Yes", "No, based on data trajectory", "Yes, based on data trajectory", "Insufficient data"))

data$SMOKE <- factor(data$SMOKE,
                     levels = c(1, 2, 3),
                     labels = c("Never Smoked", "Former Smoker", "Current Smoker"))

data$DKGRP <- factor(data$DKGRP,
                     levels = c(0, 1, 2, 3),
                     labels = c("None", "1-3 drinks/week", "4-13 drinks/week", ">13 drinks/week"))

data$HEROPIATE <- factor(data$HEROPIATE,
                         levels = c(1, 2, -9),
                         labels = c("No", "Yes", "Not Specified"))

data$IDU <- factor(data$IDU,
                   levels = c(1, 2),
                   labels = c("No", "Yes"))

data$ADH <- factor(data$ADH,
                   levels = c(1, 2, 3, 4),
                   labels = c("100%", "95-99%", "75-94%", "<75%"))

data$RACE <- factor(data$RACE,
                    levels = c(1, 2, 3, 4, 5, 6, 7),
                    labels = c("White, non-Hispanic", "White, Hispanic", "Black, non-Hispanic ", "Black, Hispanic",  "American Indian or Alaskan Native", "Asian or Pacific Islander", "Other Hispanic"))

data$EDUCBAS <- factor(data$EDUCBAS,
                       levels = c(1, 2, 3, 4, 5, 6, 7),
                       labels = c("8th grade or less ", "9,10, or 11th grade", "12th grade", "At least one year college but no degree", "Four years college or got degree", "Some graduate work", "Post-graduate degree"))

data$hard_drugs <- factor(data$hard_drugs,
                          levels = c(0, 1),
                          labels = c("No", "Yes"))

# Create labels for variables to make the names of each variable more professional in outputs
label(data$newid) <- "ID"
label(data$AGG_MENT) <- "Aggregate Mental QOL Score"
label(data$AGG_PHYS) <- "Aggregate Physical QOL Score"
label(data$HASHF) <- "Hash/Marijuana Use Since Last Visit"
label(data$HASHV) <- "Frequency of Hash/Marijuana Use"
label(data$income) <- "Income"
label(data$HBP) <- "High Blood Pressure"
label(data$DIAB) <- "Diabetes"
label(data$LIV34) <- "Liver Disease Stage 3/4"
label(data$KID) <-"Kidney Disease"
label(data$FRP) <- "Frailty Related Phenotype"
label(data$FP) <- "Fraily Phenotype"
label(data$BMI) <- "BMI"
label(data$TCHOL) <- "Total Cholesterol"
label(data$TRIG) <- "Triglycerides"
label(data$LDL) <- "LDL"
label(data$DYSLIP) < "Dyslipidemia"
label(data$SMOKE) < "Smoking Status"
label(data$CESD) <- "CESD Depression Score"
label(data$SMOKE) < "Smoking Status"
label(data$DKGRP) <- "Drinking Group"
label(data$HEROPIATE) <- "Heroin or Opiate Use Since Last Visit"
label(data$IDU) <- "Intravenous Drug Usage Since Last Visit"
label(data$LEU3N) <- "CD4+ T Cell Count"
label(data$VLOAD) <- "Viral Load"
label(data$ADH) <- "Adherence to Treatment Regimen"
label(data$RACE) <- "Race"
label(data$EDUCBAS) <- "Education at Baseline"
label(data$hivpos) <- "HIV Serostatus"
label(data$age) <- "Age"
label(data$ART) <- "Antiretroviral Therapy"
label(data$years) <- "Year of Visit"
label(data$hard_drugs) <- "Hard Drug Usage"
```

Let's take another look to check that those variables are no longer doubles.

```{r}
# Examine data
glimpse(data)
```

Looks good.

## Filtering Data Set

Now let's take a look at the header to get a good feeling for our data.

```{r}
# Pretty print data header
pretty_print(head(data))
```

Hmm, we have 8 years worth of data points, but the experimenters are only interested in the first 2 years.

Out of curiosity, let's look at how many participants they had each year.

```{r}
# Visualize patient drop off over 8 years of study
barplot(table(data$years))

# Check number of patients in each year
pretty_print(table(data$years))
```

This is interesting, we don't seem to have as drastic a drop off as I expected. The researchers managed to retain all participants for the first 2 years, and 50% by the end of the 8-year study.

Let's filter to only include values from the first 2 years, as this is the timeframe the researchers are interested in.

```{r}
# Filter long form data set to be include only first 2 years
data_2 <- data[data$years <= 2,]

# Check how many visits we have in the filtered data set.
dim(data_2)
```

We went from 3632 visits in the 8 year data set to 1650 in the 2 year filtered data set.

```{r}
# Double check if any patients dropped out within the first 2 years
any(is.na(data_2$years))
```

Luckily, no patients dropped out within the first 2 years of the study!

## Transpose to Wideform

We can also see that the provided data set is in longform. Let's convert that to wideform.

```{r}
# Create new wideform data set for first 2 years of study              
data_wide_2 <- pivot_wider(data_2, id_cols = newid, names_from = years, values_from = -c(newid, years))
```

And take a look at the header to check that was done correctly.

```{r}
# Pretty print header of wideform data
pretty_print(head(data_wide_2))
```

Good. now we have a long and wide form of the data set for the first two years of the study.

Finally, let's just clean that wide data set up a bit to drop repeat measures of variables that are constant over time (race, education at baseline, HIV serostatus, everART)

```{r}
# Clean up the wide data set a bit by deleting multiple observations across time for constant variables such as race
data_wide_2 <- data_wide_2 %>% select(-RACE_1, -RACE_2, -EDUCBAS_1, -EDUCBAS_2, -hivpos_1, - hivpos_2, -everART_1, -everART_2)
```

Now that our data sets are adequately prepared, we can move on to performing our data checks to ensure fidelity of the data set.

# Missingness I

First we begin by examining missingness in our data set

```{r}
# Check missingness for long form data
gg_miss_var(data_2)
```

This shows that we are missing the most values for `LDL`, `TRIG`, `ADH`, `TCHOL`, and `income`.

A closer examination reveals...

```{r}
# Visualize missing values for longform data
vis_miss(data_2)
```

53% of `LDL`, 53% of `TRIG`, 33% of `ADH`, 32% of `TCHOL`, and 24% of `income` values are missing.

`LDL` and`TRIG` have egregious amounts of missing data (\> 50%). `TCHOL` and `income` are in a range where we may be able to save them with MI or a linear mixed model that allows for missing data. We will have to see.

`ADH` is missing 33% of values. That could be problematic as that's a key variable the researchers are interested in.

But there's an odd, systematic pattern there... what if we look at the wide form of the data?

```{r}
# Visualize missing values for wideform data
vis_miss(data_wide_2)
```

Ah, 1/3 of the values for `ADH` are missing because there are 3 time points and you can't have baseline adherence to a protocol you just started (i.e. `ADH_0`).

There's a small blip there that looks like someone DOES have a value for `ADH_0`, I wonder what that's about...

```{r}
# For some reason participant 426 has an adherence of 1 at baseline
adh_at_baseline <- data_wide_2 %>%
  filter(ADH_0 == "100%") %>% 
  select(newid, ADH_0)

# Pretty print
pretty_print(adh_at_baseline)

```

Apparently if you're participant 426, you can have 100% adherence to a protocol you've just started (clearly a typo). Let's fix that.

```{r}
# Get rid of that value of 1 for adherence at baseline for patient 426
data$ADH[data$years == 0] <- NA
```

Great, we can still use `ADH` as a variable! We just have to use adherence at years 1 or 2.

# Data Cleaning

We just examined missingness as a preliminary check. However there is more work to be done.

The dataset we received has variables that were coded inconsistently. For instance, some variables are coded so that missing values are represented by a blank, and some variables (like `CESD`) are coded so that missing values are represented by -1. In other cases, such as with `BMI`, improbable values are coded as 999.

We can see this if we examine the mins and maxes for each numerical variable.

```{r}
# Code from ChatGPT
# This function summarizes the mins and maxes of numeric variables
summarize_column <- function(column) {
  if (is.numeric(column)) {
    return(data.frame(
      Type = "Numeric",
      Min = min(column, na.rm = TRUE),
      Max = max(column, na.rm = TRUE)
    ))
  }
}

# Apply the function to each column and bind the results into a single data frame
summary_df <- map_dfr(data_2, summarize_column, .id = "Column") %>%
  mutate(across(everything(), ~ format(., scientific = FALSE))) # Eliminates scientific notation

# Pretty print the mins and maxes of longform data_2
pretty_print(summary_df)
```

In effect, our data is not correctly showing all missing values. Let's clean all that up, variable by variable.

### Cleaning Dependent Variables {#Clean_DVs}

First we will begin by examining and cleaning our 4 primary outcomes of interest.

The first two are laboratory measures.

-   [Viral load (VLOAD):]{.underline} The number of HIV copies in a mL of blood
-   [CD4+ T cell count (LEU3N):]{.underline} A measure of immunologic health.

In untreated HIV infection, viral load increases over time and CD4+ T cell counts decline as the immune system is attacked by the virus. Once treatment is initiated, we expect viral load to decrease rapidly and CD4 counts to recover.

Our last two measures are quality of life measures from the [SF-36](https://www.rand.org/health-care/surveys_tools/mos/36-item-short-form.html).

-   [Aggregate physical quality of life score (AGG_PHYS)]{.underline}

-   [Aggregate mental quality of life score (AGG_MENT)]{.underline}

These scores range from 0 to 100, with higher scores indicating better quality of life. The researchers are not sure what happens to quality of life after initiating treatment. While in theory subjects’ improving health should result in increased quality of life, the side effects of these treatments are significant. If subjects experience declines in quality of life after initiating treatment, we would be concerned that they would stop treatment.

:::::: panel-tabset
## Viral Load

Standardized viral load

-   0 = 0 copies/ml

-   999,999,999 = 999,999,999 copies/ml

-   Blank = Missing

Our min max function earlier showed the max VLOAD was 190695039.60. I wonder if this is real or a data error?

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# create histogram of viral load
hist(data_2$VLOAD)

# Create qqplots of viral load
qqnorm(data_2$VLOAD)
qqline(data_2$VLOAD)
```

Yeah, looks like there are about 3 data points throwing off our qqplot from being normal.

Let's investigate.

```{r}
# Sort data set by descending viral load
sorted_data <- data_2[order(-data_2$VLOAD),] %>%
  select(newid, VLOAD, years)

# Pretty print resulting table
pretty_print(head(sorted_data))
```

So the highest VLOAD value is 75x the 5th highest, and the 4th highest is 2x 5th highest. All these values are from different patients at the baseline.

Based on the data dictionary provided, these values fall below the specified range of 999,999,999 copies/ml. That the PI's specified this range could mean these are real data points. Maybe immediately after when someone is first exposed to HIV the viral load is incredibly high, and these 4 or so patients fell in that time period?

I will first check if removing them makes our data normally distributed.

We will then add them back into the data set and keep them in mind. Checking with the jackknife residuals after we run our model will tell us if they are high leverage points.

```{r}
# Create boxplot to assess for outliers
outlier_vload <- boxplot(data_2$VLOAD, main = "Boxplot for VLOAD")$out
text(x = rep(1.2, length(outlier_vload)),
     y = outlier_vload, labels = outlier_vload, col = 'red', cex = 0.8)
```

Indeed the boxplot shows these values really mess with our data.

These top 4 patients based on VLOAD are 224, 78, 437, and 196. Patient 196 has double the VLOAD of the next highest person, which means this could be an outlier or real data, but let's remove them just to see.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Remove 4 highest viral load visits
data_vload_removed <- data
data_vload_removed$VLOAD[data_vload_removed$newid %in% c(224, 78, 437, 196)] <- NA

# Create plots to assess for normality
hist(data_vload_removed$VLOAD)
qqnorm(data_vload_removed$VLOAD)
```

Oh, that makes more sense. Those might not have been outliers, we just need to log transform viral load. Right, viral load is often used as a real world example of a biological measurement that is logarithmic...

Let's do that log transform, and just pretend we remembered that from the start.

```{r}
# Log transform viral load in the long form data set
data_2$VLOAD_log <- log(data_2$VLOAD)

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create a histogram of log transformed viral load
hist(data_2$VLOAD_log)

# Create qqplot of log transformed viral load
qqnorm(data_2$VLOAD_log)
qqline(data_2$VLOAD_log)

# Create boxplot of log transformed viral load to assess for potential outliers
outlier_vload <- boxplot(data_2$VLOAD_log, main = "Boxplot for VLOAD")
```

That looks much better!

I'd say that's roughly normally distributed, maybe a bit right tailed but likely still acceptable.

Looks like this took care of those values that were showing up as outliers before, and we have no outliers for this variable.

`VLOAD` has now been cleaned!

[Top of Tabset](#Clean_DVs)

## CD4+ T Cell Count

A measure of immunologic health.

Number of CD4 positive cells (helpers)

-   0 - 9999 cells
-   Blank = Missing

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of CD4 T Cells
hist(data_2$LEU3N, breaks = 24)

# Create qqplot of CD4 T Cells
qqnorm(data_2$LEU3N)
qqline(data_2$LEU3N)

# Sort data set by descending CD4 T Cell
sorted_data <- data_2[order(-data_2$LEU3N),] %>%
  select(newid, LEU3N, years)

# Pretty print resulting table
pretty_print(head(sorted_data))
```

These values all look believable and like there was no errors during data collection or entering. It is unclear whether this variable is right tailed because of outliers, or if it needs to be transformed.

Let's look at potential outliers.

```{r}
# Create boxplot of CD4 T cell count to assess for outliers
outlier_leu3n <- boxplot(data_2$LEU3N, main = "Boxplot for Leu3n")$out
text(x = rep(1.2, length(outlier_leu3n)),
     y = outlier_leu3n, labels = outlier_leu3n, col = 'red', cex = 0.8)
```

Yeah, the boxplot is showing a lot of outliers.

Let's try a log transform.

```{r}
# Log transform CD4 T Cell count
data_2$LEU3N_log <- log(data_2$LEU3N)

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of log transformed CD4 T cell count
hist(data_2$LEU3N_log)

# Create qqplot of log transformed CD4 T cell count
qqnorm(data_2$LEU3N_log)
qqline(data_2$LEU3N_log)
```

That... didn't work. Maybe let's try standardization.

```{R}
# Perform a standardization transformation of CD4 T Cell Count
data_2$LEU3N_standard <- scale(data_2$LEU3N)

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of standardized CD4 T Cell count
hist(data_2$LEU3N_standard)

# Create qqplot of standardized CD4 T Cell count.
qqnorm(data_2$LEU3N_standard)
qqline(data_2$LEU3N_standard)
```

Hmm, that didn't do the trick.

At this point I asked my professor in passing and he recommended the bestNormalize package (which he happened to write) to help in selecting the best transformation for a variable.

Let's take a shot at it.

```{r}
# Use bestNormalize R package to select the best transformation for CD4 T Cell count
BNObject <- bestNormalize(data_2$LEU3N)
BNObject
```

The bestNormalize function selects the best transformation according to the Pearson P statistic (divided by its degrees of freedom), as calculated by the nortest package. There are a variety of normality tests out there, but the benefit of the Pearson P / df is that it is a relatively interpretable goodness of fit test, and the ratio P / df can be compared between transformations as an absolute measure of the departure from normality (if the data follows close to a normal distribution, this ratio will be close to 1).

Here we can see that orderNorm (1.14), Yeo-Johnson (1.26), and Box-Cox (1.26) all perform relatively similar to each other. Let's see what those plots look like if I do those transformations.

```{r}
# Peform ordernNorm transformation of CD4 T Cell count
data_2$LEU3N_orderNorm <- orderNorm(data_2$LEU3N)$x.t

# Peform Box-Cox transformation of CD4 T Cell count
data_2$LEU3N_boxcox <- boxcox(data_2$LEU3N)$x.t

# Peform Yeo-Johnson transformation of CD4 T Cell count
data_2$LEU3N_yeojohnson <- yeojohnson(data_2$LEU3N)$x.t

# Plot all histograms using MASS
par(mfrow = c(3,1))
MASS::truehist(data_2$LEU3N_orderNorm, main = "OrderNorm transformation", nbins = 24)
MASS::truehist(data_2$LEU3N_boxcox, main = "Box Cox transformation", nbins = 24)
MASS::truehist(data_2$LEU3N_yeojohnson, main = "Yeo-Johnson transformation", nbins = 24)
```

```{r}
# This function visualizes the estimated normality statistics obtained for each fold and repeat of cross-validation via boxplots. It allows you to compare transformation methods
boxplot(log10(BNObject$oos_preds), yaxt = 'n')
axis(2, at=log10(c(.1,.5, 1, 2, 5, 10)), labels=c(.1,.5, 1, 2, 5, 10))
```

I will select Box-Cox as those two names are more familiar to me so I trust it more per the availability heuristic (and because orderNorm looks TOO good to be true).

More information on Box-Cox Transformation [here](https://www.statisticshowto.com/probability-and-statistics/normal-distributions/box-cox-transformation/)

::: callout-note
## Note: [Later in the document](#Variable_Creation) we see that the distribution of the change score for each outcome variable is normally distributed, and thus absolves us of the need to perform any transformations besides log transforming `VLOAD`.
:::

[Top of Tabset](#Clean_DVs)

## Aggregate Mental QOL Score

The values for `AGG_MENT` in our data set range from 7.229315 to 73.31224, which is believable and leads us to conclude there were no data entry errors here.

Let's examine normality.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create a histogram for aggregate mental QOL score
hist(data_2$AGG_MENT)

# Create qqplot for aggregate mental QOL score
qqnorm(data_2$AGG_MENT)
qqline(data_2$AGG_MENT)

# Sort by descending to examine highest values
sorted_data_2 <- data_2[order(data_2$AGG_MENT),] %>%
  select(newid, AGG_MENT, years)

# Pretty print resulting table
pretty_print(head(sorted_data_2))

# Create boxplot of aggregate mental QOL to assess for outliers
outlier_AGG_MENT <- boxplot(data_2$AGG_MENT, main = "Boxplot for Aggregate Mental QOL")$out
text(x = rep(1.2, length(outlier_AGG_MENT)),
     y = outlier_AGG_MENT, labels = outlier_AGG_MENT, col = 'red', cex = 0.8)
```

It appears that `AGG_MENT` only has 2 potential outliers, and is also not normally distributed, it is left-tailed. Let's address that.

```{r}
# Use bestNormalize function to test which transformation performs the best
BNobject <- bestNormalize(data_2$AGG_MENT)
BNobject
```

The orderNorm transformation beats out the other transformations by a mile. Let's perform that.

```{r}
# Perform orderNorm transformation of aggregate mental QOL score
data_2$AGG_MENT_orderNorm <- orderNorm(data_2$AGG_MENT)$x.t
MASS::truehist(data_2$AGG_MENT_orderNorm, main = "OrderNorm transformation", nbins = 24)
```

That appears to be what we have to do but I have some misgivings with orderNorm transforming everything...

::: callout-note
## Note: [Later in the document](#Variable_Creation) we see that the distribution of the change score for each outcome variable is normally distributed, and thus absolves us of the need to perform any transformations besides log transforming `VLOAD`.
:::

[Top of Tabset](#Clean_DVs)

## Aggregate Physical QOL Score

AGG_PHYS has a min of 9.12 and a max of 73.57. These are within the specified range of 0 - 100, and it appears there were no data error entries.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Creat histogram of aggregate physical QOL score
hist(data_2$AGG_PHYS)

# Create qqplots of aggregate physical QOL score
qqnorm(data_2$AGG_PHYS)
qqline(data_2$AGG_PHYS)
```

`AGG_PHYS` is not normally distributed, it is left-tailed.

Let's test which type of transformation might suit it.

```{r}
# Use bestNormalize function to test which transformation performs the best
BNobject <- bestNormalize(data_2$AGG_PHYS)
BNobject
```

Again orderNorm performs the best.

```{r}
# Perform orderNorm transformation of aggregate mental QOL score
data_2$AGG_PHYS_orderNorm <- orderNorm(data_2$AGG_PHYS)$x.t
MASS::truehist(data_2$AGG_PHYS_orderNorm, main = "OrderNorm transformation", nbins = 24)
```

OrderNorm transforming all our DVs might make interpration difficult...

::: callout-note
## Note: [Later in the document](#Variable_Creation) we see that the distribution of the change score for each outcome variable is normally distributed, and thus absolves us of the need to perform any transformations besides log transforming `VLOAD`.
:::

[Top of Tabset](#Clean_DVs)
::::::

### Cleaning Covariates {#Clean_IVs}

Now let's perform data quality checks on our covariates.

::: panel-tabset
## Hash Use

Hash/marijuana use since last visit

-   1 = no
-   2 = yes
-   blank = missing

```{r}
# Create a barplot for hash use
barplot(table(data_2$HASHV))
```

Missing data is correctly handled for this variable.

We have more visits where participants used hash since the last visit than visits where participants did not use hash.

<a href="#Clean_IVs">Back to top of tabset</a>

## Hash Frequency

Frequency hash/marijuana was used since last visit.

-   0 = Never
-   1 = Daily
-   2 = Weekly
-   3 = Monthly
-   4 = Less Often
-   Blank = Missing

```{r}
# Create barplot for hash frequency
barplot(table(data_2$HASHF))
```

This variable is coded correctly. Most participants answered they have never used Hash.

<a href="#Clean_IVs">Back to top of tabset</a>

## Income

Income

-   1 = Less than \$10,000
-   2 = \$10,000 - \$19,999
-   3 = \$20,000 - \$29,999
-   4 = \$30,000 - \$39,999
-   5 = \$40,000 - \$49,999
-   6 = \$50,000 - \$59,999
-   7 = \$60,000 or more
-   9 = Do not wish to answer

The min and max for income are 1 - 9, which matches that data dictionary.

```{r}
# Create barplot for income
barplot(table(data_2$income))

# Get values for each income level
pretty_print(table(data_2$income))
```

We have to convert those values of 'Do not wish to answer' to be NA.

```{r}
# Converting scores of 9 (do not wish to answer) to be NA
data_2$income[data_2$income == "Do not wish to answer"] <- NA

# Drop empty levels
data_2$income <- droplevels(data_2$income) 

# Create a barplot of income with cleaned values
barplot(table(data_2$income))
```

Looks good, we just converted 38 participants from do not wish to answer, to count as missing.

<a href="#Clean_IVs">Back to top of tabset</a>

## BMI

Body Mass Index

We have a min of -1 and a max of 1000.

-   -1: Improbable values

-   999: Insufficient data (why it shows up with decimals and is not exactly 999, who knows).

```{r}
# Create histogram of BMI
hist(data_2$BMI)
```

Let's convert those values of -1 and \>= 998 into missing values.

```{r}
# Convert missing and improbably values to NA
data_2$BMI[data_2$BMI < 0 | data_2$BMI >= 998] <- NA
```

And check out the histogram again and the qqplot.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of BMI
hist(data_2$BMI, breaks = 20)

# Create qqplot of BMI
qqnorm(data_2$BMI)
qqline(data_2$BMI)

summarize_column(data_2$BMI)
```

Looks better. Now we have a BMI range of 15.94 - 52.83.

The histogram and qqplots show BMI is slightly right skewed, with more morbidly obese patients than underweight. Is this close enough to normal to ignore, if we take out outliers?

The patient with a BMI of 52.83 may be an outlier based on the qqplot.

```{r}
# Investigating highest BMI value to see if its an outlier
highest_bmi <- data[data$newid == 206,]

# Plot BMI for each year for this patient
plot(highest_bmi$years, highest_bmi$BMI)
```

Interestingly, participant 206 got heavier over the first year, then dropped weight in the proceeding years. Either that or that second year entry point was an error and was meant to be 42.83

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Testing to see if these plots look normal after taking the participant with BMI of 52.83 out
data_2$BMI[data_2$newid == 206 & data_2$years == 1] <- NA
hist(data_2$BMI, breaks = 20)
qqnorm(data_2$BMI)
qqline(data_2$BMI)
 
# Add back in that value we removed
data_2$BMI[data_2$newid == 206 & data_2$years == 1] <- 52.832
```

After removing that highest BMI value, the histogram is still right tailed.

What do the boxplots look like?

```{r}
outlier_bmi <- boxplot(data_2$BMI, main = "Boxplot for BMI")$out
text(x = rep(1.2, length(outlier_bmi)),
     y = outlier_bmi, labels = outlier_bmi, col = 'red', cex = 0.8)
```

That's a lot of potential outliers for BMI. If we really want to use this variable we may have to remove these values to keep BMI normally distributed.

```{r}
# Run simple correlation matrix to see if BMI correlated with any outcomes of interest

# Correlation between VMI and VLOAD log
cor_test_result <- cor.test(data_2$BMI, data_2$VLOAD_log)
cor_test_result

# Correlation between BMI and CD4+ T Cell count boxcox
cor_test_result <- cor.test(data_2$BMI, data_2$LEU3N_boxcox)
cor_test_result


# Correlation between BMI and mental QOL 
cor_test_result <- cor.test(data_2$BMI, data_2$AGG_MENT)
cor_test_result

# Correlation between BMI and physical QOL.
cor_test_result <- cor.test(data_2$BMI, data_2$AGG_PHYS)
cor_test_result
```

BMI is correlated with all our outcome variables, so we should make sure it's cleaned.

It looks like we have a lot of outliers for BMI we can clean out from our data set to make sure it has a normal distribution.

```{r}
# Compute mean and sd values for BMI
mean_value <- mean(data_2$BMI, na.rm = TRUE)
sd_value <- sd(data_2$BMI, na.rm = TRUE)

# Use plotly to label outliers
fig <- plot_ly(data = data_2, type = 'box') 
fig <- fig %>% add_boxplot(y = ~BMI, name = "Suspected Outlier", 
                           boxpoints = 'suspectedoutliers',
                           marker = list(color = 'rgb(8,81,156)',
                                         outliercolor = 'rgba(219, 64, 82, 0.6)',
                                         line = list(outliercolor = 'rgba(219, 64, 82, 1.0)',
                                                     outlierwidth = 2)),
                           line = list(color = 'rgb(8,81,156)'),
                           text = ~paste("ID:", newid),
                           hoverinfo = "text")
fig

# Identify outliers
data_2$BMI_outlier <- (abs(data_2$BMI - mean_value) > 3* sd_value)

# See how many outliers we have
filtered_data <- data_2 %>%
  select(newid, BMI, BMI_outlier) %>%
  filter(BMI_outlier == "TRUE")
dim(filtered_data)

# Pretty Print
pretty_print(head(filtered_data))

```

We have 22 patients that had a BMI +- 3 SD from the mean. Let's clear them from the data set.

```{r}
# Filter our values greater than 3SD from the mean.
data_2$BMI[(abs(data_2$BMI - mean_value) > 3* sd_value)] <- NA

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of BMI now that we have removed outleirs
hist(data_2$BMI)

# Create qqplot of BMI now that we have removed outliers
qqnorm(data_2$BMI)
qqline(data_2$BMI)

# Plot outliers one more time
fig <- plot_ly(data = data_2, type = 'box') 
fig <- fig %>% add_boxplot(y = ~BMI, name = "Suspected Outlier", 
                           boxpoints = 'suspectedoutliers',
                           marker = list(color = 'rgb(8,81,156)',
                                         outliercolor = 'rgba(219, 64, 82, 0.6)',
                                         line = list(outliercolor = 'rgba(219, 64, 82, 1.0)',
                                                     outlierwidth = 2)),
                           line = list(color = 'rgb(8,81,156)'),
                           text = ~paste("ID:", newid),
                           hoverinfo = "text")
fig

```

Those all look a lot better! We can now conclude that `BMI` is normally distributed and can be used as a covariate in our models.

<a href="#Clean_IVs">Back to top of tabset</a>

## High Blood Pressure

High Blood Pressure (SBP \>= 140 or DBP \>= 90 or (diagnosed with hypertension and use of medication)

-   1 = No
-   2 = Yes
-   3 = No, based on data trajectory
-   4 = Yes, based on data trajectory
-   9 = Insufficient data, may include reported treatment without diagnosis
-   -1 = improbable value

We will have to exclude values of 9 or -1.

```{r}
# Create barplot of high blood pressure
barplot(table(data_2$HBP))
```

```{r}
# Get values for high blood pressure category
pretty_print(table(data_2$HBP))
```

There are 137 participants with insufficient data. Let's purge them from the data set.

```{r}
# Convert values of insufficient data to NA for high blood pressure
data_2$HBP[data_2$HBP == "Insufficient data, may include reported treatment without diagnosis"] <- NA

# Drop empty levels
data_2$HBP <- droplevels(data_2$HBP) 

# Create barplot of high blood pressure 
barplot(table(data_2$HBP))

# Pretty print table
pretty_print(table(data_2$HBP))
```

Looks better.

Only 34 visits where participants had no based on trajectory, and 4 that had yes based on trajectory.

We will have to decide to either exclude these or merge them into the no or yes groups, respectively. We can do that after we run our correlations to see if there's any relationship here worth pursuing.

<a href="#Clean_IVs">Back to top of tabset</a>

## Diabetes

Diabetes (GLUC 2 \>= 126 or (diagnosed with diabetes and use of medication))

-   1 = No
-   2 = Yes
-   3 = No, based on data trajectory
-   4 = Yes, based on data trajectory
-   9 = Insufficient data

```{r}
# Create barplot of diabetes
barplot(table(data_2$DIAB))

# Pretty print table
pretty_print(table(data_2$DIAB))
```

There are 881 visits with patient who had insuffiicent data to make a diabetes diagnosis!

Let's change those values to NA.

```{r}
# Convert values of insufficient data to NA for diabetes
data_2$DIAB[data_2$DIAB == "Insufficient data"] <- NA

# Drop empty levels
data_2$DIAB <- droplevels(data_2$DIAB)

# Create a barplot for diabetes
barplot(table(data_2$DIAB))

# Pretty print table
pretty_print(table(data_2$DIAB))

```

Great, `HBP` is now cleaned.

Notably, there were no visits with a yes, based on trajectory.

<a href="#Clean_IVs">Back to top of tabset</a>

## Liver Disease

Liver disease stage 3/4 (SGPT or SGOP \> 150), preliminary algorithm

-   1 = No
-   2 = Yes
-   9 = Insufficient data

```{r}
# Create barplot of liver disease stage
barplot(table(data_2$LIV34))

# Pretty print table
pretty_print(table(data_2$LIV34))
```

There are 507 patients with insufficient data for a liver disease diagnosis.

Let's convert those values to NA to reflect this.

```{r}
# Convert values of insufficient data to NA for liver disease stage
data_2$LIV34[data_2$LIV34 == "Insufficient Data"] <- NA

# Drop empty levels
data_2$LIV34 <- droplevels(data_2$LIV34)

# Create barplot of cleaned liver stage disease
barplot(table(data_2$LIV34))

# Pretty print table
pretty_print(table(data_2$LIV34))
```

Looks good, `LIV34` is now cleaned!

<a href="#Clean_IVs">Back to top of tabset</a>

## Kidney Disease

Kidney disease (EGFR \< 60 or UPRCR \>= 200)

-   1 = No

-   2 = Yes

-   3 = No, based on data trajectory

-   4 = Yes, based on data trajectory

-   \- 9 = Insufficient data

```{r}
# Create barplots of kidney disease
barplot(table(data_2$KID))

# Pretty print table
pretty_print(table(data_2$KID))
```

There are 1068 visits where there was insufficient data for a diagnosis.

Let's convert those to NA values.

```{r}
# Convert values of insufficient data to NA for kidney disease
data_2$KID[data_2$KID == "Insufficient data"] <- NA

# Drop empty levels
data_2$KID <- droplevels(data_2$KID)

# Create barplot of kidney disease
barplot(table(data_2$KID))
```

Looks good, `KID` is now cleaned!

<a href="#Clean_IVs">Back to top of tabset</a>

## Frailty Related Phenotype

Frailty Related Phenotype (3 out of 4 conditions = YES; WTLOS, PHDWA, HLTWB, HLTVA

-   1 = No
-   2 = Yes
-   9 = Insufficient data

```{r}
# Create barplot of frailty related phenotype
barplot(table(data_2$FRP))

# Pretty print table
pretty_print(table(data_2$FRP))
```

Only 3 patients with insufficient data.

Let's convert them to NA.

```{r}
# Convert values of insufficient data to NA for frailty related phenotype
data_2$FRP[data_2$FRP == "Insufficient Data"] <- NA

# Drop empty levels
data_2$FRP <- droplevels(data_2$FRP)

# Create barplot of frailty related phenotype
barplot(table(data_2$FRP))
```

Looks good, `FRP` is now cleaned.

<a href="#Clean_IVs">Back to top of tabset</a>

## Frailty Phenotype

Frailty Phenotype (3 out of 5 conditions = YES: WTLOS, PHWDA, HLTVA, SLOW, WEAK)

-   1 = No
-   2 = Yes
-   9 = Insufficient Data

```{r}
# Create barplot of frailty phenotype
barplot(table(data_2$FP))

# Pretty print table
pretty_print(table(data_2$FP))
```

357 visits with insufficient data. Let's convert to NA.

```{r}
# Convert values of insufficient data to NA for frailty phenotype
data_2$FP[data_2$FP == "Insufficient Data"] <- NA

# Drop empty levels
data_2$FP <- droplevels(data_2$FP)

# Create barplot of frailty phenotype
barplot(table(data_2$FP))
```

Looks good, `FP` is now cleaned!

<a href="#Clean_IVs">Back to top of tabset</a>

## Total Cholesterol

Total cholesterol mg/dL

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram for total cholesterol
hist(data_2$TCHOL)

# Create qqplot for total cholesterol
qqnorm(data_2$TCHOL)
qqline(data_2$TCHOL)
```

The histogram and qq plot show what may be outliers for total cholesterol at the higher range. How many values are potential outliers?

```{r}
# Create boxplot to assess for outliers for total cholesterol
outlier_tchol <- boxplot(data_2$TCHOL, main = "Boxplot for Total Cholesterol")$out
text(x = rep(1.2, length(outlier_tchol)),
     y = outlier_tchol, labels = outlier_tchol, col = 'red', cex = 0.8)

# Sort by descending total cholesterol
sorted_data <- data_2[order(-data_2$TCHOL),] %>%
  select(newid, TCHOL, years)

# Pretty print table
pretty_print(head(sorted_data))
```

The highest cholesterol value is \~2x higher than the next highest value. Let's see what happens if we remove it.

```{r}
# Delete highest total cholesterol value
data_2$TCHOL[data_2$TCHOL == 613] <- NA 

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of total cholesterol
hist(data_2$TCHOL)

# Create qqplot of total cholesterol
qqnorm(data_2$TCHOL)
qqline(data_2$TCHOL)
```

Looks better but still slightly right skewed. This variable had \~30% missing values, so we may end up not using it.

<a href="#Clean_IVs">Back to top of tabset</a>

## Triglycerides

Triglycerides, mg/dL

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of triglycerides
hist(data_2$TRIG)

# Create qqplot of triglycerides
qqnorm(data_2$TRIG)
qqline(data_2$TRIG)
```

VERY skewed! Based on the qqplots, it looks like we would have to perform a log transform on `TRIG` if we wanted to use it. However we have nearly 50% missing values for this variable, so we should drop it as a covariate.

<a href="#Clean_IVs">Back to top of tabset</a>

## Low Density Lipoprotein

Low Density Lipoprotein (fasting) mg/dL

```{r}
# Create a histogram for LDL
hist(data_2$LDL)
```

Looks like we may have an erroneous value at the highest range there.

```{r}
# Sort by descending total cholesterol
sorted_data <- data_2[order(-data_2$LDL),] %>%
  select(newid, LDL, years)

# Pretty print table
pretty_print(head(sorted_data))
```

Patients 19 and 413 have the same value of 704 at baseline. Clearly an error with the measurement process.

`LDL` has close to 50% missing values and we will not be using it in our model, so I will move on. But good to know we can't just blindly trust all the values to be correct!

<a href="#Clean_IVs">Back to top of tabset</a>

## Dyslipidemia

Dyslipidemia at visit. fasting TC \>=200 mg/dl or \>=130 mg/dl or HDL \< 40 mg/dl or triglycerides \>=150 mg/dl or use of lipid lowering medications (HICHOLRX) with self report or clinical diagnosis in the past.

-   1 = No
-   2 = Yes
-   3 = No, based on data trajectory
-   4 = Yes from data trajectory
-   9 = Insufficient data

```{r}
# Create barplot of dyslipidemia
barplot(table(data_2$DYSLIP))

# Pretty print table
pretty_print(table(data_2$DYSLIP))
```

There are 718 visits with insufficient data for a dyslipidemia diagnosis.

Let's convert those to NAs to reflect this.

```{r}
# Convert values of insufficient data to NA for dyslipidemia
data_2$DYSLIP[data_2$DYSLIP == "Insufficient data"] <- NA

# Drop empty levels
data_2$DYSLIP <- droplevels(data_2$DYSLIP)

# Create barplot of dyslipidemia
barplot(table(data_2$DYSLIP))
```

Looks good, `DYSLIP` is now cleaned!

<a href="#Clean_IVs">Back to top of tabset</a>

## Depression

Center for Epidemiological Studies Depression Scale ( \>= 16 is depressed).

-   0 - 60

-   -1 = missing

```{r}
# Create histogram for depression score
hist(data_2$CESD)
```

Let's correctly reflect those -1's as NA's

```{r}
# Remove depression scores that were coded as missing
data_2$CESD[data_2$CESD == -1] <- NA

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of depression score
hist(data_2$CESD)

# Create qqplot for depression score
qqnorm(data_2$CESD)
qqline(data_2$CESD)
```

Looks good. `CESD` is now cleaned!

For fun, let's see if a square root transformation helps at all.

```{r}
# Try a sqrt transformation
data_2$CESD_sqrt <- sqrt(data_2$CESD)

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of sqrt depression score
hist(data_2$CESD_sqrt)

# Create qqplot of sqrt depressions score
qqnorm(data_2$CESD_sqrt)
qqline(data_2$CESD_sqrt)
```

That does look a bit better, but the central limit theorem justifies inclusion of `CESD` without performing transformation.

<a href="#Clean_IVs">Back to top of tabset</a>

## Smoking Status

Smoking status

-   1 = Never smoked
-   2 = Former smoker
-   3 = Current smoker
-   Blank = missing

```{r}
# Create barplot of smoking status
barplot(table(data_2$SMOKE))
```

Looks good, nothing to do here.

<a href="#Clean_IVs">Back to top of tabset</a>

## Drinking Group

Alcohol use since last visit

-   0 = None
-   1 = 1 to 3 drinks/week
-   2 = 4 to 13 drinks/week
-   3 = More than 13 drinks/week
-   Blank = Missing

```{r}
# Create barplot of drinking group
barplot(table(data_2$DKGRP))
```

Looks good, nothing to do here.

<a href="#Clean_IVs">Back to top of tabset</a>

## Heroin or Opiate Use

Took heroin or other opiates since last visit?

-   1 = No
-   2 = Yes
-   -9 = Not specified in form
-   Blank = Missing

```{r}
# Create barplot of heroin or opiate use
barplot(table(data_2$HEROPIATE))

# Pretty print table
pretty_print(table(data_2$HEROPIATE))
```

Only 20 visits where participants did not specify drinking frequency on their form.

Let's correct those to be NA.

```{r}
# Convert values of insufficient data to NA for heroin or opiate use
data_2$HEROPIATE[data_2$HEROPIATE == "Not Specified"] <- NA

# Drop empty levels
data_2$HEROPIATE <- droplevels(data_2$HEROPIATE)

# Create barplot of heroin or opiate use
barplot(table(data_2$HEROPIATE))
```

Looks good. `HEROPIATE` is now cleaned!

<a href="#Clean_IVs">Back to top of tabset</a>

## Intravenous Drug Use

Took/used drugs with a needle since last visit?

-   1 = No
-   2 = Yes
-   Blank = Missing

```{r}
# Create barplot of intravenous drug use
barplot(table(data_2$IDU))
```

Looks good. Nothing to do here

<a href="#Clean_IVs">Back to top of tabset</a>

## Adherence

Adherence to meds taken since last visit

-   1 = 100%
-   2 = 95-99%
-   3 = 75-94%
-   4 \<75%
-   Blank = Missing

```{r}
# Create bar plot of adherence
barplot(table(data_2$ADH))

# Pretty print table
pretty_print(table(data_2$ADH))
```

VERY interesting. I was thinking that 100% vs 95-99% adherence was an arbitrary difference to choose to divide groups on, and was actually planning to merge the two. However, this shows why the experimenters likely made that decision: both groups have close to the same amount of observations (\~500)\> That's really good to know.

We could still play with the idea of simplifying this into two groups: \>= 95% and \< 95%. We will revisit that in the model selection.

<a href="#Clean_IVs">Back to top of tabset</a>

## Race

Race

-   1 = White, non-Hispanic
-   2 = White, Hispanic
-   3 = Black, non-Hispanic
-   4 = Black, Hispanic
-   5 = American Indian or Alaskan Native
-   6 = Asian or Pacific Islander
-   7 = Other 8 = Other Hispanic (created for 2001-03 new recruits)
-   Blank = Missing

```{r}
# Create barplot of race
barplot(table(data_2$RACE))

# Pretty print table
pretty_print(table(data_2$RACE))
```

This all looks coded properly. As is a common thing I am seeing, we have a predominant proportion of participants who are white, non-Hispanic. The data set might be large enough that we can use race as a covariate.

It might be worth dummy coding as white vs non white and see if there are any differences. That's not the main focus of this project though so I will leave that to if I have extra time at the end.

<a href="#Clean_IVs">Back to top of tabset</a>

## Education at Baseline

Baseline or earliest reported education (highest grade or level)

-   1 = 8th grade or less
-   2 = 9,10, or 11th grade
-   3 = 12th grade
-   4 = At least one year college but no degree
-   5 = Four years college / got degree
-   6 = Some graduate work
-   7 = Post-graduate degree
-   Blank = Missing

```{r}
# Create barplot of education at baseline
barplot(table(data_2$EDUCBAS))

# Pretty print table
pretty_print(table(data_2$EDUCBAS))
```

This all checks out. And it looks like there are enough participants in each group (except for 8th grade or less) to run analyses with this variable. It will be interesting to see what relationships arise, as I expect there to be a strong association between education and HIV exposure.

<a href="#Clean_IVs">Back to top of tabset</a>

## HIV Serostatus

HIV Serostatus

-   0 = Negative
-   1 = Positive

```{r}
# Checking that all patients are HIV pos
any(is.na(data_2$hivpos))
```

All patients in this data set are HIV+

<a href="#Clean_IVs">Back to top of tabset</a>

## Age

Age at visit

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram for age
hist(data_2$age)

# Create qqplot for age
qqnorm(data_2$age)
qqline(data_2$age)
```

Nice and normally distributed, how we like it.

<a href="#Clean_IVs">Back to top of tabset</a>

## Antiretroviral Therapy

Take ART at visit

-   0 = NO
-   1 = YES

```{r}
# Create barplot of antiretroviral therapy
barplot(table(data_2$ART))

# Pretty print table
pretty_print(table(data_2$ART))
```

I'm not too sure how useful this variable will be. It just means there were some visits where patients were not given ART, I suppose. But most visits had participants receiving ART.

<a href="#Clean_IVs">Back to top of tabset</a>

## everART

Ever took ART.

-   0 = NO
-   1 = YES

```{r}
# Create barplot of everART
barplot(table(data_2$everART))

# Pretty print table
pretty_print(table(data_2$everART))
```

This has the exact same split as `ART`. Which makes me think they are exactly the same values for each participant

```{r}
# Check if everART and ART are identical
all(data_2$everART == data_2$ART)
```

Yup, this is either an accidental duplicate of `ART`, or there is no distinction of significance between the two. What exactly does "Ever took ART" (the explanation provided by the data dictionary) mean? Was this taken at baseline?

Either way looks like we're not using this variable.

<a href="#Clean_IVs">Back to top of tabset</a>

## Hard Drug Use

Hard drug use (either injection drugs or illicit heroin/opiate use) since last visit

-   0 = No
-   1 = Yes
-   Blank = Missing

```{r}
# Create barplot of hard drug use category
barplot(table(data_2$hard_drugs))

# Pretty print table
pretty_print(table(data_2$hard_drugs))
```

There were 198 visits where participants had used hard_drugs since the last visit.

This variable looks good. We will just have to do some dummy coding to create the categories the researchers were interested in.

<a href="#Clean_IVs">Back to top of tabset</a>

## Summary

For the CONSORT diagram, we just removed:

38 visits where patients did not report income.

X BMI values that were missing and y values that were improbable.

137 visits with insufficient data for a HBP diagnosis

881 visits with insufficient data for a DIAB diagnosis.

507 visits with insufficient data for a LIV34 diagnosis

1068 visits with insuffcient data for a kidney disease diagnosis

3 visits with insuffiient data for FRP diagnosis

357 visits with insufficient data for FP diagnosis

718 visits with insufficent data for dyslipidemia diagnosis

X visits with missing values for CESD

20 visits where heroin or opiate use was not specified

COME BACK TO THIS BECAUSE i THINK I NEED TO COME BACK AND DELETE OUTLIERS.

<a href="#Clean_IVs">Back to top of tabset</a>
:::
:::

# Missingness II

We first examined missingness before performing data cleaning just to get a sense of the data set.

Let's compare what our missingness looked like pre- and post-data cleaning.

```{r}
# Visualize missingness for pre-cleaned data
gg_miss_var(data)

# Visualize missingness for post-cleaned data
gg_miss_var(data_2)
```

The order for missingness has changed, now with `KID` at the top, followed by `DIAB`, `LDL`, `TRIG`, and `DYSLIP`.

`TCHOL`, `LIV34`, and `income` are further behind, with levels of missingness that may be salvageable (\~30%).

```{r}
# Visualize missingness for pre-cleaned dataset
vis_miss(data)

# Visualize missingness for post-cleaned dataset
vis_miss(data_2)
```

And for good measure let's now examine missingness in the wide form data set.

```{r}
# Create new wideform data set for first 2 years of study              
data_wide_2 <- pivot_wider(data_2, id_cols = newid, names_from = years, values_from = -c(newid, years))

# Visualize missing values in the wideform data set
vis_miss(data_wide_2)
```

There are no real trends that become apparent when looking at this plot for the wideform data set.

To summarize, it appears that diagnoses that were determined by algorithm (such as `KID`, `DIAB`, `DYSLIP`, and `LIV34`, often had insufficient data to make a diagnosis, so perhaps this is an issue with those algorithms. Additionally, lab measurements of `LDL` and `TRIG` seem to have been too onerous for participants to have had collected. Maybe they opted out of those tests, or maybe the tests were only ordered under certain circumstances.

These would be valuable questions to bring forth to the PI. But for now it appear as if we won't be able to use these variables.

We may want to impute `income`, `LIV34`, and `TCHOL`, as these have missingness of 24%, 31%, and 32%, respectively.

#### Variables with minimal missing data (\<5%) that can be disregarded without affecting analysis integrity

-   `AGG_MENT`
-   `AGG_PHYS`
-   `HASH_V`
-   `HASHF`
-   `FRP`
-   `SMOKE`
-   `DKGRP`
-   `HEROPIATE`
-   `IDU`
-   `LEU3N`
-   `VLOAD`
-   `ADH`
-   `EDUCBASE`
-   `AGE`
-   `ART`
-   `years`
-   `hard-drugs`

#### Variables with moderate missing data (5-20%) that necessitate intervention

-   `BMI`
-   `HBP`

#### Variables with \>20% missing data that are edge cases and may require exclusion or imputation

-   `TCHOL`
-   `income`
-   `LIV34`

#### Variables with an excess of missing data (\>40%) that necessitate exclusion from the analysis

-   `LDL`
-   `TRIG`
-   `DIAB`
-   `KID`
-   `DYSLIP`

# Variable Creation {#Variable_Creation}

Here we will create the variables necessary for the analysis.

Since we cleaned the longform data set, let's go ahead and re-transpose it to update the wide form data set.

```{r}
# Create new wideform data set for first 2 years of study              
data_wide_2 <- pivot_wider(data_2, id_cols = newid, names_from = years, values_from = -c(newid, years))
```

:::::: panel-tabset
## Outcome Variable Change Scores

Here we will create our change scores for our dependent variables `LEU3N`, `VLOAD`, `AGG_MENT`, and `AGG_PHYS` to assess treatment response to ART. For `VLOAD` we will create change scores off the log transformed values.

Change scores are calculated as:

$$
y_{2year} - y_{baseline} = y_{change}
$$

::: callout-note
## Note

Change scores are coded such that:

-   For viral load, higher numbers are less desirable. Negative numbers signify a decrease in viral load over time, which is favorable.

-   For CD4+ T Cell count, higher numbers are more desirable. Negative numbers signify a decrease in leukocytes over time, which is not favorable.

-   For aggregate mental and physical QOL score, higher numbers signify an increase in mental/physical health from baseline. Negative values signify a decrease.
:::

```{r}
# Create change scores for outcome variables
data_wide_2$VLOAD_log_CHANGE <- data_wide_2$VLOAD_log_2 - data_wide_2$VLOAD_log_0
data_wide_2$LEU3N_CHANGE <- data_wide_2$LEU3N_2 - data_wide_2$LEU3N_0
data_wide_2$AGG_MENT_CHANGE <- data_wide_2$AGG_MENT_2 - data_wide_2$AGG_MENT_0
data_wide_2$AGG_PHYS_CHANGE <- data_wide_2$AGG_PHYS_2 - data_wide_2$AGG_PHYS_0
```

Now let's perform internal consistency checks to make sure those calculations were performed correctly, as well as reexamine the distributions of the change score for each variable.

::: panel-tabset
## Log Viral Load Change

```{r}
# Select only variables related to change scores to double check we performed calculation correctly.
filtered_data <- data_wide_2 %>%
  select(VLOAD_log_0, VLOAD_log_2, VLOAD_log_CHANGE)

# Pretty print
pretty_print(head(filtered_data))
```

The computation for change score was performed correctly.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create hist for vload log change score
hist(data_wide_2$VLOAD_log_CHANGE)

# Create qqplot for vload log change score
qqnorm(data_wide_2$VLOAD_log_CHANGE)
qqline(data_wide_2$VLOAD_log_CHANGE)
```

Looks like we have 1 outlier there that we should catch with the jackknife residuals after we fit the model, but `VLOAD_log_CHANGE` looks normally distributed!

[Top of Tabset](#Variable_Creation)

## CD4+ T Cell Count Change

```{r}
# Select only variables related to change scores to double check we performed calculation correctly.
filtered_data <- data_wide_2 %>%
  select(LEU3N_0, LEU3N_2, LEU3N_CHANGE)

# Pretty print
pretty_print(head(filtered_data))
```

The computation for change score was performed correctly.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create hist for CD4+ T Cell change score
hist(data_wide_2$LEU3N_CHANGE)

# Create qqplot for CD4+ T Cell change score
qqnorm(data_wide_2$LEU3N_CHANGE)
qqline(data_wide_2$LEU3N_CHANGE)
```

CD4+ T Cell count change score looks normally distributed, with 1 or 2 outliers that we can examine the leverage and influence of.

[Top of Tabset](#Variable_Creation)

## Aggregate Mental QOL Change

```{r}
# Select only variables related to change scores to double check we performed calculation correctly.
filtered_data <- data_wide_2 %>%
  select(AGG_MENT_0, AGG_MENT_2, AGG_MENT_CHANGE)

# Pretty print
pretty_print(head(filtered_data))
```

The computation for change score was performed correctly.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create hist for aggregate mental QOL change score
hist(data_wide_2$AGG_MENT_CHANGE, breaks = 24)

# Create qqplot for aggregate mental QOL change score
qqnorm(data_wide_2$AGG_MENT_CHANGE)
qqline(data_wide_2$AGG_MENT_CHANGE)
```

That looks more normally distributed now, and our sample size is very large so we can also count on the central limit theorem to help us with the assumption of normality.

[Top of Tabset](#Variable_Creation)

## Aggregate Physical QOL Change

```{r}
# Select only variables related to change scores to double check we performed calculation correctly.
filtered_data <- data_wide_2 %>%
  select(AGG_PHYS_0, AGG_PHYS_2, AGG_PHYS_CHANGE)

# Pretty print
pretty_print(head(filtered_data))
```

The computation for change score was performed correctly.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))
    
# Create hist for aggregate physical  QOL change score
hist(data_wide_2$AGG_PHYS_CHANGE, breaks = 24)

# Create qqplot for aggregate physical QOL change score
qqnorm(data_wide_2$AGG_PHYS_CHANGE)
qqline(data_wide_2$AGG_PHYS_CHANGE)
```

Aggregate physical QOL change score appears more normally distributed now.

[Top of Tabset](#Variable_Creation)

## Summary

After computing the change scores, our outcome variables are now normally distributed and we can move forward with using them in models!

[Top of Tabset](#Variable_Creation)
:::

## Hard Drug Use Groups

We need to make dummy codes for our hard drug use groups.

The criteria outlined by the researchers are as follows:

-   [Never User:]{.underline} No drug use reported at 0, 1, or 2 years
-   [Previous User:]{.underline} Drug use reported at 0 or 1 years, but not 2 years
-   [Current User:]{.underline} Drug use reported at 2 years

::: panel-tabset
## Drug Use Classification

First we will create dummy codes for whether a patient was a never, previous, or current hard drug user.

```{r}
# Create dummy code for current drug users (those who used at year 2)
data_wide_2$current_drug <- ifelse(data_wide_2$hard_drugs_2 == "Yes", 1, 0) 

# Create dummy code for previous drug users (those who used at years 0 or 1, but not 2)
data_wide_2$previous_drug <- ifelse((data_wide_2$hard_drugs_1 == "Yes" | data_wide_2$hard_drugs_0 == "Yes") & data_wide_2$hard_drugs_2 == "No", 1, 0)

# Create dummy code for never drug users (did not use at years 0, 1, or 2)
data_wide_2$never_drug <- ifelse(data_wide_2$hard_drugs_1 == "No" & data_wide_2$hard_drugs_0 == "No" & data_wide_2$hard_drugs_2 == "No", 1, 0)

```

And perform some internal consistency checks to ensure we coded that correctly.

```{r}
# Double check our criteria worked as intended
filtered_data <- data_wide_2 %>%
  select(newid, hard_drugs_0, hard_drugs_1, hard_drugs_2, never_drug, previous_drug, current_drug)

# Pretty print
pretty_print(head(filtered_data))

# Double check no overlapping group assignments (such as a current AND previous drug user)
no_overlap <- apply(data_wide_2[, c("never_drug", "previous_drug", "current_drug")], 1, sum) <= 1
all_no_overlap <- all(no_overlap)

# Print result
if (all_no_overlap) {
  print("No overlapping group assignments")
} else {
  print("There are overlapping group assignments in some rows")
}

```

Great, that looks like we coded it properly and there are no overlaps between drug use conditions (e.g. there are no current drug users who are also previous drug users).

[Top of Tabset](#Variable_Creation)

## Drug Use Group

Now we will use those dummy codes to make a variable for which group each patient was in

-   0: Never User
-   1: Previous User
-   2: Current User

```{r, results = "hide"}
# Create a single variable for drug use group
data_wide_2$hard_drugs_grp <- ifelse(data_wide_2$never_drug == 1, 0, 
                                 ifelse(data_wide_2$previous_drug == 1, 1,
                                        ifelse(data_wide_2$current_drug == 1, 2, NA)))

# Factor this new variable and label it too
data_wide_2$hard_drugs_grp <- factor(data_wide_2$hard_drugs_grp,
                                     levels = c(0,1,2),
                                     labels = c("Never User", "Previous User", "Current User"))

# Label the new variable for better output
label(data_wide_2$hard_drugs_grp) <- "Hard Drug Use Group"

```

And perform an internal consistency check to make sure there are no overlapping group assignments.

```{r}
# Double check our criteria worked as intended
filtered_data <- data_wide_2 %>%
  select(newid, hard_drugs_0, hard_drugs_1, hard_drugs_2, hard_drugs_grp)

# Pretty print
pretty_print(head(filtered_data))
```

Let's do a final check for how many patients we have in each group.

```{r}
# Pretty print categories
pretty_print(table(data_wide_2$hard_drugs_grp))
```

Looks good, we can now move forward with analyses using the `hard_drgs_grp` variable!

[Top of Tabset](#Variable_Creation)
:::

## Adherence Groups

The experimenters coded adherence with 4 levels:

-   1: 100%
-   2: 95-99%
-   3: 75-94%
-   4: \<75%
-   Blank = Missing

However, it may be also be useful to think of adherence in terms of high vs. low adherence.

Let's go ahead and create a new category for patients that had:

-   High: 95% - 100%
-   Low: \< 95%

We will be using adherence at year 2 for these categories.

```{r}
# Create new groups based on high vs low adherence (based on adherence at 2 years)
data_wide_2$ADH_HIGH <- ifelse(data_wide_2$ADH_2 == "100%" | data_wide_2$ADH_2 == "95-99%", 1, 0)
data_wide_2$ADH_LOW <- ifelse(data_wide_2$ADH_2 == "75-94%" | data_wide_2$ADH_2 == "<75%%", 1, 0)

# Create a variable for high vs low adherence
data_wide_2$ADH_HIGHVSLOW <- ifelse(data_wide_2$ADH_LOW == 1, 0,
                                    ifelse(data_wide_2$ADH_HIGH == 1, 1, NA))

# Factor this new variable and label it too
data_wide_2$ADH_HIGHVSLOW <- factor(data_wide_2$ADH_HIGHVSLOW,
                                     levels = c(0,1),
                                     labels = c("Low Adherence", "High Adherence"))


# Label the new variable for better output
label(data_wide_2$ADH_HIGHVSLOW) <- "Adherence Level"

# Drop empty levels
data_wide_2$ADH_HIGHVSLOW <- droplevels(data_wide_2$ADH_HIGHVSLOW) 

```

Let's perform a consistency check to make sure that coding worked as intended.

```{r}
# Double check our criteria worked as intended
filtered_data <- data_wide_2 %>%
  select(newid, ADH_2, ADH_HIGHVSLOW)

# Pretty print
pretty_print(head(filtered_data, 20))
```

Looks great, now we have a new variable `ADH_HIGHVSLOW` to compare how high and low adherence to the medication regiment since the last visit impacts outcomes.

[Top of Tabset](#Variable_Creation)

## Race Groups

First let's examine how many patients of each race we have.

```{r}
# Get number of patients of each race
pretty_print(table(data_wide_2$RACE_0))
```

We have a very low number of patients in the minority race categories.

It may be informative to see how outcomes differ based on white vs non-white, as our sample is predominantly white and there is otherwise not enough patients in each category to use race as a meaningful variable.

Let's create a variable that captures this.

```{r}
# Create dummy variable for race, white vs non-white
data_wide_2$RACE_WHITEYN <- ifelse(is.na(data_wide_2$RACE_0), NA, 
                                   ifelse(data_wide_2$RACE_0 == "White, non-Hispanic", 1, 0))


# Factor this new variable and label it too
data_wide_2$RACE_WHITEYN <- factor(data_wide_2$RACE_WHITEYN,
                                     levels = c(0,1),
                                     labels = c("Non-White", "White"))

# Label the new variable for better output
label(data_wide_2$RACE_WHITEYN) <- "Race"

# Double check our criteria worked as intended
filtered_data <- data_wide_2 %>%
  select(newid, RACE_0, RACE_WHITEYN)

# Pretty print
pretty_print(head(filtered_data, 10))
```

Our dummy coding was performed correctly.

Let's see what our counts looks like now.

```{r}
# Check counts for each category in the new whiteYN variable.
table(data_wide_2$RACE_WHITEYN)
```

We have 186 non-white participants and 340 white participants.

[Top of Tabset](#Variable_Creation)

## Education Groups

```{r}
# Get number patients in each education tier
pretty_print(table(data_wide_2$EDUCBAS_0))
```

Education at baseline is currently coded as a categorical variable with 7 levels. It may be more helpful to classify education as a bivariate variable of college vs no college.

```{r}
# Create new dummy variable for college vs no college
data_wide_2$EDUC_COLLEGE <- ifelse(is.na(data_wide_2$EDUCBAS_0), NA, 
                                   ifelse(data_wide_2$EDUCBAS_0 %in% c("At least one year college but no degree", 
                                                                       "Four years college or got degree", 
                                                                       "Some graduate work", 
                                                                       "Post-graduate degree"), 1, 0))

# Factor new variable
data_wide_2$EDUC_COLLEGE <- factor(data_wide_2$EDUC_COLLEGE,
                                     levels = c(0,1),
                                     labels = c("No College", "College"))

# Label the new variable for better output
label(data_wide_2$EDUC_COLLEGE) <- "College Status"

# Double check our criteria worked as intended
filtered_data <- data_wide_2 %>%
  select(newid, EDUCBAS_0, EDUC_COLLEGE)

# Pretty print
pretty_print(head(filtered_data, 10))

# Get number of patients in each category
table(data_wide_2$EDUC_COLLEGE)
```

Looks good, we have 125 patients with no college, and 425 with at least some college.

[Top of Tabset](#Variable_Creation)
::::::

# Descriptive Statistics {#Descriptives}

Here we will acquire the descriptive statistics of our data set and create Table 1. Code modified from [cran.r-project.org](https://cran.r-project.org/web/packages/table1/vignettes/table1-examples.html)

Please note: These descriptive statistics are based on the cleaned data set, and will be different from the original data (e.g. `income` values of "Do not wish to answer" have been recoded as missing values).

```{r, results = "hide"}
# Create labels for variables to make the names of each variable more professional in outputs
label(data_wide_2$AGG_MENT_0) <- "Aggregate Mental QOL Score"
label(data_wide_2$AGG_PHYS_0) <- "Aggregate Physical QOL Score"
label(data_wide_2$HASHF_0) <- "Hash/Marijuana Use"
label(data_wide_2$HASHV_0) <- "Frequency of Hash/Marijuana Use"
label(data_wide_2$income_0) <- "Income"
label(data_wide_2$HBP_0) <- "High Blood Pressure"
label(data_wide_2$DIAB_0) <- "Diabetes"
label(data_wide_2$LIV34_0) <- "Liver Disease Stage 3/4"
label(data_wide_2$KID_0) <-"Kidney Disease"
label(data_wide_2$FRP_0) <- "Frailty Related Phenotype"
label(data_wide_2$FP_0) <- "Fraily Phenotype"
label(data_wide_2$BMI_0) <- "BMI"
label(data_wide_2$TCHOL_0) <- "Total Cholesterol"
label(data_wide_2$TRIG_0) <- "Triglycerides"
label(data_wide_2$LDL_0) <- "LDL"
label(data_wide_2$DYSLIP_0) < "Dyslipidemia"
label(data_wide_2$SMOKE_0) < "Smoking Status"
label(data_wide_2$CESD_0) <- "CESD Depression Score"
label(data_wide_2$SMOKE_0) < "Smoking Status"
label(data_wide_2$DKGRP_0) <- "Drinking Group"
label(data_wide_2$HEROPIATE_0) <- "Heroin or Opiate Use"
label(data_wide_2$IDU_0) <- "Intravenous Drug Usage"
label(data_wide_2$LEU3N_0) <- "CD4+ T Cell Count"
label(data_wide_2$VLOAD_log_0) <- "Log Viral Load"
label(data_wide_2$ADH_1) <- "Adherence to Treatment Regimen at Year 1"
label(data_wide_2$ADH_2) <- "Adherence to Treatment Regimen at Year 2"
label(data_wide_2$RACE_0) <- "Race"
label(data_wide_2$EDUCBAS_0) <- "Education at Baseline"
label(data_wide_2$hivpos_0) <- "HIV Serostatus"
label(data_wide_2$age_0) <- "Age"
label(data_wide_2$ART_0) <- "Antiretroviral Therapy"
label(data_wide_2$hard_drugs_0) <- "Hard Drug Usage"
label(data_wide_2$AGG_MENT_CHANGE) <- "Aggregate Mental QOL Change Score"
label(data_wide_2$AGG_PHYS_CHANGE) <- "Aggregate Physical QOL Change Score"
label(data_wide_2$VLOAD_log_CHANGE) <- "Log Viral Load Change Score"
label(data_wide_2$LEU3N_CHANGE) <- "CD4+ T Cell Count Change Score"
```

```{r}
# Create Table 1 for the wideform data set,stratified by adherence group
table1 <- table1(~AGG_MENT_0 + AGG_PHYS_0 +  HASHV_0 + HASHF_0 + income_0 + BMI_0 + HBP_0 + DIAB_0 + LIV34_0 + KID_0 + FRP_0 + FP_0 + TCHOL_0 + TRIG_0 + LDL_0 + DYSLIP_0 + CESD_0 + SMOKE_0 + DKGRP_0 + HEROPIATE_0 + IDU_0 + LEU3N_0 +  VLOAD_log_0 + ADH_1 + ADH_2 + ADH_HIGHVSLOW +  RACE_WHITEYN + EDUC_COLLEGE + age_0 + AGG_MENT_CHANGE + AGG_PHYS_CHANGE + VLOAD_log_CHANGE + LEU3N_CHANGE + hard_drugs_grp | ADH_2, data = data_wide_2, caption = "Descriptive Statistics at Baseline", overall = c(left="Total"))
table1
```

# Correlation Matrix

First we will begin by making a correlation matrix to assess whether any of our IVs are related to each other (multicollinearity). This will also inform which variables to incorporate into the final model.

```{r}
# Let's clean our output by making a trimmed dataset excluding extaneous variables
data_for_matrix <- select(data_2, -newid, -ART, -everART, -LEU3N_log, -LEU3N_yeojohnson, -LEU3N_boxcox, -LEU3N_orderNorm, - LEU3N_standard, -AGG_MENT_orderNorm, -AGG_MENT_orderNorm, -BMI_outlier, -CESD_sqrt, -hivpos, -AGG_PHYS_orderNorm, - LIV34)

# We factored our variables at the start. To make a correlation matrix we must reconvert those back to numeric
data_for_matrix <- data.frame(lapply(data_for_matrix, function(x) if (is.factor(x)) as.numeric(x) else x))

# Make a correlation matrix with all variables of the trimmed data set
correlation_matrix <- cor(data_for_matrix, use = "complete.obs")

# Plot the matrix
corrplot(correlation_matrix, method = "circle")
```

There are a host of strong correlations in our data set.

### Precision Variables

`CESD` has a strong negative associated with `AGG_MENT`, which makes perfect sense. Those who are are more depressed will have lower mental health scores. `CESD` will have to be included as a precision variable for any analysis with `AGG_MENT` as the outcome variable.

`FRP` and `FP` are strongly negatively associated with `AGG_PHYS`. This also makes perfect sense: Those who are frail will have lower overall physical health scores. They are both highly correlated though and essentially measure the same thing. One will have to be dropped.

### Mutlicollinearity Issues

`EDUCBASE` is strongly associated with `income`, `RACE`, `SMOKE`, and weakly correlated with `TCHOL`, `LDL`, and `VLOAD_log`.

`Hard_drugs` is highly correlated with `HEROPIATE` and `IDU`, which makes perfect sense, as they are all basically the same thing.

We appear to have notable multicollinearity between `DYSLIP` and `TCHOL`, `LDL`, and `TRIG`. This makes sense because all these variables are highly related (dyslipidemia is abnormal levels of fats in the blood). This is interesting because these variables are where a lot of our missingness occured.

We also have some possible multicollinearity to be aware of between `KID`, `HBP`, and `DIAB`.

Let's clean this up a bit and remove unneccessary variables.

## Removing Superfluous Variables

We previously determined that `LDL`, `TRIG`, `DIAB`, `KID`, and `DYSLIP` had excessive missing values (\>40%).

Now that we have seen that they are not strongly related to the outcome variables, we can be assured that we can safely remove them with no need for imputation.

```{r}
# Drop variables with excessive missing values from the wideform data set
data_2 <- data_2 %>%
  select(-LDL, -TRIG, -DIAB, -KID, -DYSLIP)
```

`FRP` and `FP` are both precision variables for `AGG_PHYS`, but highly correlated to each other.

`FP` has more missing values (22%) than `FRP`(\~0%), and will thus be dropped.

```{r}
# Drop FP
data_2 <- data_2 %>%
  select(-FP)
```

`EDUCBASE` is highly correlated with `income`, `TCHOL`, `SMOKE`, and `RACE`.

`income` has 27% missing values and thus will be dropped from further analysis.

`TCHOL` has 32% missing values and will thus be dropped.

`SMOKE` and `RACE` will be dropped to avoid issues of multicollinearity, and `EDUCBASE` used as the covariate of choice.

```{r}
# Drop income, total cholesterol, smoke, and race
data_2 <- data_2 %>%
  select(-income, -TCHOL, -SMOKE, -RACE)
```

`Hard_drugs` is highly correlated with `HEROPIATE` and `IDU`.

`Hard_drugs` is our main independent variable of interest and thus we drop `HEROPIATE` and `IDU`.

```{r}
# Drop income, total cholesterol, smoke, and race
data_2 <- data_2 %>%
  select(-HEROPIATE, -IDU)
```

`HBP` is lightly correlated with `age` and `BMI`. Let's drop it to avoid multicollinearity.

```{r}
# Drop high blood pressure.
data_2 <- data_2 %>%
  select(-HBP)
```

## Correlation Matrix Redux

Let's take another look at that correlation matrix now that we have cleaned up our data set to remove variables with excessive missing values and issues of multicollinearity.

```{r}
# Let's clean our output by making a trimmed dataset excluding extraneous variables
data_for_matrix <- select(data_wide_2, AGG_MENT_CHANGE, AGG_PHYS_CHANGE, LEU3N_CHANGE, VLOAD_log_CHANGE, BMI_2, FRP_2, CESD_2, DKGRP_2, ADH_2, ADH_HIGHVSLOW, EDUC_COLLEGE, age_2, hard_drugs_grp)

# We factored our variables at the start. To make a correlation matrix we must reconvert those back to numeric
data_for_matrix <- data.frame(lapply(data_for_matrix, function(x) if (is.factor(x)) as.numeric(x) else x))

# Make a correlation matrix with all variables of the trimmed data set
correlation_matrix <- cor(data_for_matrix, use = "complete.obs")

# Plot the matrix
corrplot(correlation_matrix, method = "circle")
```

Looking MUCH better! Here we can see some potentially strong relationships emerge.

-   `CESD` as mentioned will be included as a precision variable for `AGG_MENT`

-   `FRP` as mentioned will be included as a precision variable for `AGG_PHYS`

-   `EDUCBASE` looks like it will be a predictor for all outcome variables except `AGG_MENT`

-   `BMI` appears to have a weak correlation with all outcome variables and will likely be included in the final models.

-   `age` also looks weakly correlated to all outcome variables except `VLOAD_log`

Let's run some individual regression and assess these relationships more closely.

p-values of \< 0.1 will be considered for the final models.

# Interactive Variable Selection {#EDA}

Here I will plot the data and perform a number of simple linear regressions to examine relationships between variables in order to determine which covariates to include in the model.

Remember that:

-   For viral load, higher numbers are less desirable. Negative numbers signify a decrease in viral load over time, which is favorable.

-   For CD4+ T Cell count, higher numbers are more desirable. Negative numbers signify a decrease in leukocytes over time, and which is not favorable.

-   For aggregate mental and physical QOL score, higher numbers signify an increase in mental/physical health from baseline. Negative values signify a decrease.

::::: panel-tabset
## Log Viral Load 

Let's focus first on a model predicting Log Viral Load change.

::: panel-tabset
## PEV - Hard Drug Use

Let's begin by seeing if there appears to be a difference in log viral load change based on hard drug use, the primary explanatory variable.

```{r}
# Create boxplots of log viral load change by hard drug use group
p <- ggplot(data_wide_2, aes(x = hard_drugs_grp, y = VLOAD_log_CHANGE, fill = hard_drugs_grp)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Log Viral Load Change by Hard Drug Use Group",
       x = "Hard Drug Use Group",
       y = "Log Viral Load Change") +
  guides(fill = guide_legend(title = "Hard Drug Use Group"))

ggplotly(p)
```

There may be a difference between log viral load change and hard drug use group, especially between never users and previous users. Visually, it appears that that never use group had more of a decrease in log viral load over 2 years compared to the previous and current drug use groups.

Let's run the regression to see if this relationship is statistically significant.

```{r}
# Perform regression predicting log vload change by hard drug use group with never user as the reference group
model <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)
```

```{r}
# Gather p-values of the model
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

Change the reference level to previous users and re-run the model.

```{r}
# Relevel to change to the reference group to previous user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression predicting log vload change by hard drug use group, with previous users as the reference group
model <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)

# Apply Bonferroni correction
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

The overall model is significant (F~(2,529)~= 3.991, p = 0.01903). The group comparisons were not significant after applying Bonferroni correction however (all p-adjusted > 0.05). They may be significant after including precision variables or confounders, and thus we continue with the analysis and include `hard_drugs_group` as the PEV.

[Top of Tabset](#EDA)

## Adherence

The researchers are interested in if treatment response between the drug use groups can be explained by differences in adherence to the HAART treatment regimen.

The first step toward investigating this is to examine if there is a relationship between adherence and treatment response, starting with log viral load change.

We can examine this by plotting the average log viral loads each year by adherence group.

```{r}
# Clear out that one participant that had an adherence value at year 0, which is a data entry error.
data_2$ADH[data_2$years == 0]<- NA

# Get means for each year
summary_data <- data_2 %>%
  group_by(ADH, years) %>%
  summarize(Average_VLOAD_log = mean(VLOAD_log, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_VLOAD_log, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Log Viral Load Change by Adherence Group Over 2 Years",
       x = "Year",
       y = "Average Log Viral Load Change",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

Indeed we can see that, across the first 2 years of the study, as adherence decreased, average log viral load increased!

That is, groups with higher adherence had a smaller increase in log viral load over 2 years compared to those with lower adherence. This is evidence that the ART treatment is efficacious in reducing viral load!

Let's examine that relationship with boxplots.

```{r}
# Create boxplots of log viral load change by adherence group
p <- ggplot(data_wide_2, aes(x = ADH_2, y = VLOAD_log_CHANGE, fill = ADH_2)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Log Viral Load Change by Adherence at Year 2",
       x = "Adherence at year 2",
       y = "Log Viral Load Change") +
  guides(fill = guide_legend(title = "Adherence Group"))

ggplotly(p)
```

This relationship is reflected in the boxplots: Groups with high adherence had a greater decrease in log viral load over 2 years compared to those with low adherence.

Let's run the regression to ensure this difference is statistically significant.

```{r}
# Perform regression predicting log vload change by adherence group at year 2, with the 100% adherence group as the reference level
model <- lm(VLOAD_log_CHANGE ~ ADH_2, data = data_wide_2)

# Examine Summary
summary(model)
```

```{r}
# Apply Bonferroni correction
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

Change the reference level to the 75-94% group and re-run the model.

```{r}
# Relevel to change to the reference group to 75-94%
data_wide_2$ADH_2 <- relevel(data_wide_2$ADH_2, ref = "75-94%")

# Perform regression predicting log vload change by adherence group at year 2, with the 75-94% group as the reference level
model <- lm(VLOAD_log_CHANGE ~ ADH_2, data = data_wide_2)

# Examine Summary
summary(model)

# Apply Bonferroni correction
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```


The overall model is significant (F~(3, 528)~= 8.261, p < .0001). 

Looking at the between-group comparisons, the 100% group is statistically different from the 75-95% group (p-adjusted < 0.0001) and the <75% group (p-adjusted = 0.0266). 

The 75-95% group is significantly different from the 95-99% group (p-adjusted <0.0001).

The 100% and 95-99% group were not significantly different from each other (p-adjusted > .05), and the 75-95% and <75% groups were not significantly different from each other (p-adjusted > 0.5).

In other words, there is no difference between the two highest adherence groups from each other, and between the two lowest adherence groups from each other, providing strong evidence for grouping these levels together and separating based on high vs low adherence.


::: callout-note
Based on the above findings, there is no difference between the two highest adherence level groups from each other, and the two lowest adherence level groups from each other.

Therefore, analyses moving forward will only make comparisons between high vs low adherence for ease of interpretation.
:::

[Top of Tabset](#EDA)

## Adherence High vs Low

Based on the plots and regression results from looking at adherence group and log viral load, there is no difference between the two highest adherence level groups from each other, and the two lowest adherence level groups from each other.

Therefore, it is more prudent to collapse this variable and make comparisons only between high adherence (95-100%) and low adherence (<95%) groups

Let's examine change in log viral load based on these criteria.

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(ADH_HIGHVSLOW))

# Create boxplots of log viral load change by adherence group
p <- ggplot(data_no_na, aes(x = ADH_HIGHVSLOW, y = VLOAD_log_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Boxplot of Log Viral Load Change by Adherence at Year 2",
       x = "Adherence Level",
       y = "Log Viral Load Change") +
  guides(fill = guide_legend(title = "Adherence Group"))

ggplotly(p)
```

Indeed, this plot is simpler and encapsulates the true relationships better!

The high adherence group had a greater decrease in log viral load over 2 years compared to the low adherence group.

Let's perform the linear regression.

```{r}
# Perform regression predicting log vload change by adherence group at year 2
model <- lm(VLOAD_log_CHANGE ~ ADH_HIGHVSLOW, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is statistically significant (F~(1,518)~= 17.78, p < 0.0001). On average, those in the high adherence group have a mean change in log viral load that is 1.86 log copies/mL (or 72.44 copies/mL) lower than those in the low adherence group

`ADH_HIGHVSLOW` will absolutely be included in the final model for `VLOAD_log`.

[Top of Tabset](#EDA)

## BMI

The correlation matrix reveals a relationship between BMI and each outcome variable. Let's examine this relationship more closely.

```{r}
# Create a scatterplot of log vload change by BMI at baseline
p <- ggplot(data_wide_2, aes(x = BMI_0, y = VLOAD_log_CHANGE, color = BMI_0)) + 
  geom_point() +
  theme_minimal() +
  labs(title = "Log Viral Load Change by BMI at Baseline",
       y = "Log Viral Load Change",
       x = "BMI at Baseline") + 
  scale_fill_brewer(palette = "Pastel2")

# Make the plot interactive
ggplotly(p)
```

That does not look like a very strong association.

Let's run a regression to see if there is any kind of linear relationship in there.

```{r}
# Perform a linear regression predicting log viral load change by BMI at baseline
model <- lm(VLOAD_log_CHANGE ~ BMI_0, data = data_wide_2)

# Examine model summary
summary(model)
```

`BMI` is not a significant predictor of log viral load change (p = 0.246) and will not be included in the final model.

[Top of Tabset](#EDA)

## College Education

Based on the correlation matrix, `EDUC_COLLEGE` appears to be significantly associated with our outcome variables.

```{r}
# Create a scatterplot of log vload change by college education
ggplot(data_wide_2, aes(x = EDUC_COLLEGE, y = VLOAD_log_CHANGE, fill = EDUC_COLLEGE)) + 
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  labs(title = "Log Viral Load Change by College Education",
       y = "Log Viral Load Change",
       x = "College Education") + 
  scale_fill_brewer(palette = "Pastel2")
```

There appears to be a difference in log viral load change based on college education. Remember that this is on a logarithmic scale, so the real differences will be much more pronounced, even if the differences seem small here!

Let's run the regression.

```{r}
# Perform a linear regression predicting log viral load change by college education
model <- lm(VLOAD_log_CHANGE ~ EDUC_COLLEGE, data = data_wide_2)

# Examine model summary
summary(model)
```

The overall model is significant F~(1,530)~= 9.204, p = 0.002533). On average, those with a college educaton had change in viral load that was 0.8979 log copies/mL (or 7.9 copies/mL) than those who did not have a college education.

`EDUC_COLLEGE` is a significant predictor of log viral load change and should be included in the final model.

[Top of Tabset](#EDA)

## Summary

Based on the results of the exploratory data analysis, the variables that will be included in the final model for `VLOAD_log_CHANGE` are `hard_drug_grp`, `ADH_HIGHLOW`, and `EDUC_COLLEGE`.

[Top of Tabset](#EDA)

:::

## CD4+ T Cell Count

Now let's examine relationships for the model predicting CD4+ T Cell Count

::: panel-tabset

## PEV - Hard Drug Use

Let's see if there is a a difference in CD4+ T Cell count based on hard drug use, the primary explanatory variable.

```{r}
# Relevel to change the reference cateory to Never User
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Create boxplots of CD4+ T Cell count change by hard drug use group
p <- ggplot(data_wide_2, aes(x = hard_drugs_grp, y = LEU3N_CHANGE, fill = hard_drugs_grp)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of CD4+ T Cell Count Change by Hard Drug Use Group",
       x = "Hard Drug Use Group",
       y = "CD4+ T Cell Count Change") +
  guides(fill = guide_legend(title = "Hard Drug Use Group"))

ggplotly(p)
```

Previous and current hard drug users may have low CD4+ T Cell count compared to never users.

Let’s run the regression to see if this relationship is statistically significant.

```{r}
# Perform regression predicting CD4+ T Cell count change by hard drug use group with never user as the reference group
model <- lm(LEU3N_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)

# Gather p-values of the model
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

Change the reference group to previous users and re-run the model. 

```{r}
# Relevel to change the reference category to Previous User
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression predicting CD4+ T Cell count change by hard drug use group with previous user as the reference group
model <- lm(LEU3N_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)

# Gather p-values of the model
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

The overall model is statistically significant F~(2,529)~ = 12.55, p < 0.0001). On average current drug users have a change in CD4+ T cell count that is 119.467 cells lower than never drug users (p-adjusted < 0.0001). The other between group comparisons were not significant (p-adjusted > 0.05).

`hard_drug_grp` will be included as a predictor in the final model for `LEU3N`.

[Top of tabset](#EDA)

## Adherence High vs Low

For ease of mind, let's plot our average `LEU3N` values each year by adherence group.

```{r}
# Get means for each year
summary_data <- data_2 %>%
  group_by(ADH, years) %>%
  summarize(Average_LEU3N = mean(LEU3N, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_LEU3N, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average CD4+ T Cell Count change by Adherence Group Over 2 Years",
       x = "Year",
       y = "Average CD4+ T Cell Count",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

We have the same relation we did with log viral load, where higher adherence groups tend to have better outcomes (higher average CD4+ T Cell count in this case). The <75% has a pretty high average CD4+ T cell count, but I think we can chalk this up to variance due to a smaller sample size. We still see the general trend that both high adherence groups are performing better than both low adherence groups, and we can safely collapse these categories into high adherence (95-100%) and low adherence (<95%) groups. 

Let’s examine change in CD4+ T Cell count based on high vs low adherence.

```{r}
# Create boxplots of CD4+ T Cell count change by adherence group
ggplot(data_no_na, aes(x = ADH_HIGHVSLOW, y = LEU3N_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Boxplot of CD4+ T Cell Count Change by Adherence at Year 2",
       x = "Adherence Level",
       y = "CD4+ T Cell Count Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```

It appears that the high adherence group may have a slightly higher gain in CD4+ T Cells over 2 years (its pretty close though).

Let's run a regression to see if this is statistically significant.

```{r}
# Perform regression predicting CD4+ T Cell count change by adherence group at year 2
model <- lm(LEU3N_CHANGE~ ADH_HIGHVSLOW, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is not significant (F~(1,518)~= 2.152, p = 0.143).

Just for sanity's sake let's run that with our uncollapsed adherence categories.

```{r}
# Perform regression predicting CD4+ T Cell count change by adherence group at year 2
model <- lm(LEU3N_CHANGE~ ADH_2, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is significant (F~(3, 528)~, = 4.353, p = 0.0048). However, none of those between group comparisons are significant after Bonferroni correction.

So no matter how you run it, adherence is not related to CD4+ T Cell count.

We will still include `ADH_HIGHLOW` as a covariate in the final model for `LEU3N_CHANGE`, since it was a confounder in the model predicting `VLOAD_log_CHANGE`, and new relationships may become apparent if it is included in this model.

[Top of tabset](#EDA)

## BMI

The correlation matrix reveals a potential relationship between BMI and each CD4+ T Cell count.

Let's assess.

```{r}
# Create a scatterplot of CD4+ T Cell Count change by BMI at baseline
ggplot(data_wide_2, aes(x = BMI_0, y = LEU3N_CHANGE, color = BMI_0)) + 
  geom_point() +
  theme_minimal() +
  labs(title = "CD4+ T Cell Count Change by BMI at Baseline",
       y = "CD4+ T Cell Count Change",
       x = "BMI at Baseline") + 
  scale_fill_brewer(palette = "Pastel2")
```

There does not appear to be a strong relationship between BMI and CD4+ T Cell count change.

We perform the regression to double check.

```{r}
# Perform a linear regression predicting CD4+ T Cell count change by BMI at baseline
model <- lm(LEU3N_CHANGE ~ BMI_0, data = data_wide_2)

# Examine model summary
summary(model)
```

Let's plot the regression line.

```{r}
# Create a scatterplot of CD4+ T Cell Count change by BMI at baseline
ggplot(data_wide_2, aes(x = BMI_0, y = LEU3N_CHANGE, color = BMI_0)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal() +
  labs(title = "CD4+ T Cell Count Change by BMI at Baseline",
       y = "CD4+ T Cell Count Change",
       x = "BMI at Baseline") + 
  scale_fill_brewer(palette = "Pastel2")
```

The overall model is non-significant (F~(1,517)~ = 2.798, p = 0.095). On average, every 1 unit increase in BMI is associated with a 0.0034 increase in CD4+ T Cell count. Though not significant, the model is below that p = 0.10 cutoff for potential covariates we established a priori. On average, every 1 unit increase in BMI is associated with a 0.0034 increase in CD4+ T Cell count.

`BMI` will be included as a potential precision variable for the model predicting `LEU3N_CHANGE`.

[Top of Tabset](#EDA)

## Frailty Related Phenotype

Fraily related phenotype was also correlated to CD4+ T Cell count in the correlation matrix. 

Let's assess that relationship.

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(FRP_2))

# Create boxplots of CD4+ T Cell count change by frailty related phenotype at year 2
ggplot(data_no_na, aes(x = FRP_2, y = LEU3N_CHANGE, fill = FRP_2)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Boxplot of CD4+ T Cell Count Change by Frailty Related Phenotype",
       x = "Frailty Related Phenotype",
       y = "CD4+ T Cell Count Change") +
  guides(fill = guide_legend(title = "Frailty Related Phenotype"))
```
It appears that those with a frailty related phenotype have a lower increase in CD4+ T Cell count over the 2 years of the study.

Let's run a regression to see if that relationship is statistically significant.

```{r}
# Perform regression predicting physical QOL change by Frailty Related Phenotype
model <- lm(LEU3N_CHANGE ~ FRP_2, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is statistically significant (F~1,528)~= 11.66, p < 0.0001). On average, those with a frailty related phenotype had a change in CD4+ T Cell count over 2 years that was 124.046 cells lower than those without a frailty related phenotype (p < 0.0001).

`FRP_2` will be included as a precision variable for the model predicting `LEU3N_CHANGE`.

[Top of Tabset](#EDA)

## College Education

College education did not look strongly related to CD4+ T Cell count change, but let's run a simple regression just to make sure.

```{r}
# Create a scatterplot of CD4+ T Cell count change by college education
ggplot(data_wide_2, aes(x = EDUC_COLLEGE, y = LEU3N_CHANGE, fill = EDUC_COLLEGE)) + 
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  labs(title = "CD4+ T Cell Count Change by College Education",
       y = "CD4+ T Cell Count Change",
       x = "College Education") + 
  scale_fill_brewer(palette = "Pastel2")
```
They appear comparable, but there may be a slight difference. Run regression to be sure.

```{r}
# Perform regression predicting log vload change by college education
model <- lm(LEU3N_CHANGE ~ EDUC_COLLEGE, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is significant (F~(1,530)~= 4.231, p = 0.0401). On average, those with a college education had a change in CD4+ T cell count that was 40.20 cells higher than those without a college education.

`EDUC_COLLEGE` will be included as a precision variable for the model predicting `LEU3N_CHANGE`.

[Top of Tabset](#EDA)


## CESD Depression

Depression was lightly correlated to CD4+ T Cell Count based on the correlation matrix.

Let's examine that relationship.

```{r}
# Create a scatterplot of CD4+ T Cell Count change by BMI at baseline
ggplot(data_wide_2, aes(x = CESD_0, y = LEU3N_CHANGE, color = CESD_2)) + 
  geom_point() +
  theme_minimal() +
  labs(title = "CD4+ T Cell Count Change by Depression at Year Two",
       y = "CD4+ T Cell Count Change",
       x = "Depression at Year Two") + 
  scale_fill_brewer(palette = "Pastel2")
```

```{r}
# Perform a linear regression predicting CD4+ T Cell count change by depressions core
model <- lm(LEU3N_CHANGE ~ CESD_2, data = data_wide_2)

# Examine model summary
summary(model)
```

```{r}
# Create a scatterplot of CD4+ T Cell Count change by BMI at baseline
ggplot(data_wide_2, aes(x = CESD_0, y = LEU3N_CHANGE, color = CESD_2)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal() +
  labs(title = "CD4+ T Cell Count Change by Depression at Year Two",
       y = "CD4+ T Cell Count Change",
       x = "Depression at Year Two") + 
  scale_fill_brewer(palette = "Pastel2")
```

The overall model is significant (F~(1, 525)~= 4.23, p = 0.0403). On average, every 1 point increase in CES-Depression score was associated with a 1.53 cell decrease in CD4+ T Cell count.

The association is very weak (R-squared = 0.0080), but we can still include it in the final model. It makes sense that people who are more depressed have fewer white blood cells, and we may as well account for this in the final model.

`CESD_2` is will be included as a precision variable in the model predicting `LEU3N_CHANGE`.

[Top of Tabset](#EDA)

## Summary 

Based on the results of the exploratory data analysis, the variables that will be included for consideration in the final model for `LEU3N_CHANGE` are `hard_drugs_grp`, `ADH_HIGHLOW`, `BMI_2`, `FRP_2`, and `EDUC_COLLEGE`, and `CESD_2`.

[Top of Tabset](#EDA)
:::

## Aggregate Mental QOL Change

Now let's examine relationships for the model predicting aggregate mental QOL change. 

The researchers are concerned that the a

They want to investigate how mental QOL is after 2 years. If there is a 

We can also see if mental QOL differs by hard drug use grp and adherence, and any other covariates.

Does viral load predict mental QOL?

does LEU3n predict mental QOL?

Do I have to do something here concerning dropout?


::: panel-tabset

## PEV - Hard Drug Use

Let's assess if mental QOL is related to the hard drug use categories.

```{r}
# Create boxplots of log viral load change by hard drug use group
ggplot(data_wide_2, aes(x = hard_drugs_grp, y = AGG_MENT_CHANGE, fill = hard_drugs_grp)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Mental QOL Change by Hard Drug Use Group",
       x = "Hard Drug Use Group",
       y = "Aggregate Mental QOL Change") +
  guides(fill = guide_legend(title = "Hard Drug Use Group"))
```

There does not appear to be much of a difference in mental QOL by hard drug use groups.

Let's run a regression.

```{r}
# Perform regression predicting mental QOL change by hard drug use group
model <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)
```

`hard_drugs_grp` is not a significant predictor of `AGG_MENT_CHANGE`.

This is interesting, because when we plot average mental QOL over 8 years by hard drug use, we can see a clear relationship 

```{r}
# Get means for each year
summary_data <- data %>%
  group_by(hard_drugs, years) %>%
  summarize(Average_agg_ment = mean(AGG_MENT, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_agg_ment, color = hard_drugs)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average mental QOL by Hard Drug Use Over 8 Years",
       x = "Year",
       y = "Average mental QOL",
       color = "Hard Drug Use") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

Where those who did not use hard drugs since the last visit had higher mental QOL.

It seems that somewhere when we created our 3 hard drug use categories of never user, previous user, and current user, we lost some of this information.

`hard_drg_group` will still be included as a potential covariate in case there is a confounding variable present.

[Top of Tabset](#EDA)

## Adherence 

If adverse reactions from the HAART treatment negatively impacted patients, then we would expect to see the higher adherence groups having a smaller increase, or even decrease, in mental QOL compared to those in the low adherence groups.

Let's first examine this by plotting the average mental QOL for each year by adherence group.

```{r}
# Get means for each year
summary_data <- data_2 %>%
  group_by(ADH, years) %>%
  summarize(Average_AGG_MENT = mean(AGG_MENT, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_AGG_MENT, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Mental QOL by Adherence Group Over 2 Years",
       x = "Year",
       y = "Average Mental QOL",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

This plot shows that, over the first 2 years, the < 75% adherence group had the highest increase in mental QOL! This is the opposite of expected; you would expect the 100% adherence group to have the highest mental QOL if there were no adverse effects from the drug and it was improving QOL overall by decreasing HIV viral load.

However, the relationship looks different if we create this same plot over the entire 8 years of the study.

```{r}
# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_QOL = mean(AGG_MENT, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_QOL, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Mental QOL Score by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average Mental QOL Score",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

Here we see the true relationship emerge! The 100% adherence group has the highest aggregate mental QOL score across the 8 years of the study, followed by the 95-99% adherence group, then the 75-94% and <75% adherence groups trailing behind with fair amounts of year to year variation.

Could we calculate AUC and use that to answer the researchers' question?

Therefore we can reasonably conclude that higher adherence is related to better overall mental QOL. Which would likely not be the case if the side effects of the drug were worse than the benefits from taking them.


Let's examine these relationships with boxplots.

First looking at adherence split into four categories.

```{r}
# Change reference group
data_wide_2$ADH_2 <- relevel(data_wide_2$ADH_2, ref = "100%")

# Create boxplots of mental QOL change by adherence group
ggplot(data_wide_2, aes(x = ADH_2, y = AGG_MENT_CHANGE, fill = ADH_2)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Mental QOL Change by Adherence at Year 2",
       x = "Adherence at year 2",
       y = "Mental QOL Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```

And then adherence split into two categories of high vs low.

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(ADH_HIGHVSLOW))

# Create boxplots of mental QOL change by adherence group
ggplot(data_no_na, aes(x = ADH_HIGHVSLOW, y = AGG_MENT_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Mental QOL Change by Adherence at Year 2",
       x = "Adherence at year 2",
       y = "Mental QOL Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```
This plot shows that there is a slight difference in aggregate mental QOL over the first 2 years of the study between the high and low adherence groups.

While not a perfect encapsulation of the true relationship between adherence and mental QOL over time, I believe this comparison adequately captures the differences between adherence groups we can see with our data visualizations.

Let's perform a regression to see if this relationship is statistically significant.

```{r}
# Perform regression predicting mental QOL change by adherence group
model <- lm(AGG_MENT_CHANGE ~ ADH_HIGHVSLOW, data = data_wide_2)

# Examine Summary
summary(model)
```

Great! `ADH_HIGHLOW` is a significant predictor of mental QOL change over 2 years (F~(1,530)~= 6.092). On average, those who had high adherence to the treatment regiment had an aggregate mental QOL score that was 4.79 points higher than those who had low adherence (p = 0.0139).

`ADH_HIGHLOW` will be included in the final model as a predictor of `AGG_MENT_CHANGE`.

[Top of Tabset](#EDA)

## CESD - Depression

The only other variable that flagged as being associated with mental QOL was the CESD Depression score.

Let's examine this relationship with a plot.

```{r}
# Create a scatterplot of mental QOL change score by depression at 2 years
ggplot(data_wide_2, aes(x = CESD_2, y = AGG_MENT_CHANGE, color = CESD_2)) + 
  geom_point() +
  theme_minimal() +
  labs(title = "Mental QOL Change by Depression at Baseline",
       y = "Mental QOL Change ",
       x = "Depression Score") + 
  scale_fill_brewer(palette = "Pastel2")
```

There appears to be a negative linear relationship here. Let's run the regression and fit the model.

```{r}
# Perform a linear regression predicting mental QOL change by depression at baseline
model <- lm(AGG_MENT_CHANGE ~ CESD_2, data = data_wide_2)

# Examine model summary
summary(model)
```

```{r}
# Create a scatterplot of mental QOL change score by depression at baseline
ggplot(data_wide_2, aes(x = CESD_2, y = AGG_MENT_CHANGE, color = CESD_2)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal() +
  labs(title = "Mental QOL Change by Depression at Baseline",
       y = "Mental QOL Change ",
       x = "Depression Score") + 
  scale_fill_brewer(palette = "Pastel2")
```

Depression score is a significant predictor of mental QOL change over the first 2 years of treatment (F~(1, 536)~= 52.05). On average, a 1-point increase in depression score is associated with a 0.33 point decrease in mental QOL score (p < 0.0001).

`CESD_0` will be included as a precision variable in the model predicting `AGG_MENT_CHANGE`

## Depression and Hard Drug Use

It appears that depression and hard drug use may be correlated based on the correlation matrix. 

If so, we have potential confounding between hard drug use and depression. Maybe those who used hard drugs have worse QOL, but it's because they are depressed. Or vice versa. 

Let's assess.

First we can plot depression by hard drug use group.

```{r}
# Create a scatterplot of depression score at year 2 by hard drug use group
ggplot(data_wide_2, aes(x = hard_drugs_grp, y = CESD_2, fill = hard_drugs_grp)) + 
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Depression Score by Hard Drug Use Group",
       y = "Depression Score ",
       x = "Hard Drug Use Group") + 
  scale_fill_brewer(palette = "Pastel2")
```

It appears that current and previous drug users have higher depression scores than those who never used drugs.

Let's run a regression to see if that relationship is statistically significant.

```{r}
# Refactor to never users as reference group
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform a linear regression predicting depression by hard drug use group
model <- lm(CESD_2 ~ hard_drugs_grp, data = data_wide_2)

# Examine model summary
summary(model)
```

Hard drug use is a significant predictor of depression score (F~(2, 542)~= 14.31). On average, current hard drug users had depression scores that were 5.23 points higher than never hard drug users (p < 0.0001), and previous hard drug users had depression scores that were 7.29 points higher than those who never used hard drugs (p < 0.0001).

`hard_drug_grp` will be included as a possible confounder for the relationship between depression and mental QOL. Or rather depression will be included as a possible confounder for the relationship between hard_drug_use and mental QOL.

[Top of Tabset](#EDA)

:::

## Aggregate Physical QOL Change

If the ART has a strong adverse effect on QOL, then we can expect those with high adherence to have worse QOL. Maybe.

::: panel-tabset

## Drug Use Groups

Let’s assess if physical QOL is related to the hard drug use categories by itself.

```{r}
# Create boxplots of aggregate physical QOL by hard drug use group
ggplot(data_wide_2, aes(x = hard_drugs_grp, y = AGG_PHYS_CHANGE, fill = hard_drugs_grp)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Aggregate Physical QOL by Hard Drug Use Group",
       x = "Hard Drug Use Group",
       y = "Aggregate Physical QOL Change") +
  guides(fill = guide_legend(title = "Hard Drug Use Group"))
```

It looks like current hard drug users have a lower physical QOL score than never hard drug users.

Let's run a regression to see if that difference is statistically significant.

```{r}
# Perform regression predicting physical QOL change by hard drug use group
model <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)
```

```{r}
# Gather p-values of the model
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

Change the reference group to previous drug users and re-run the model.

```{r}
# Relevel hard drug use to have the reference level as previous users
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression predicting physical QOL change by hard drug use group
model <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)

# Gather p-values of the model
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

Yes it is. Hard drug use is a significant predictor of physical QOL change over 2 years (F~(2, 540)~= 9.019). On average, current drug users have a physical QOL score that is 4.90 points lower than never drug users (p-adjusted = 0.0000792), and 4.65 points lower than previous drug users (p-adjusted = 0.0147).

`hard_drug_group` will be included as a predictor of `AGG_PHYS_CHANGE`.

[Top of Tabset](#EDA)

## Adherence

If adverse reactions from the HAART treatment negatively impacted patients, then we would expect to see the higher adherence groups having a smaller increase, or even decrease, in physical QOL compared to those in the low adherence groups.

Let’s first examine this by plotting the average mental QOL for each year by adherence group.

```{r}
# Get means for each year
summary_data <- data_2 %>%
  group_by(ADH, years) %>%
  summarize(Average_AGG_PHYS = mean(AGG_PHYS, na.rm = TRUE))
```

```{r}
# Create plot
ggplot(summary_data, aes(x = years, y = Average_AGG_PHYS, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Physical QOL by Adherence Group Over 2 Years",
       x = "Year",
       y = "Average Physical QOL",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

Here we can see that the 2 highest adherence groups have the highest physical QOL scores, which tracks with what we would expect if the drugs were helping.

For good measure, let's examine this relationship across the entire 8 years of the study.

```{r}
# Get rid of that value of 1 for adherence at baseline for patient 426
data$ADH[data$years == 0] <- NA

# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_AGG_PHYS = mean(AGG_PHYS, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_AGG_PHYS, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Physical QOL Score by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average Physical QOL Score",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

We see a similiar relationship looking at the full 8 years of the study. You can visualize how the two highest adherence groups would have a greater AUC than the two lowest adherence groups.

Let’s examine these relationships with boxplots.

First looking at adherence split into four categories.

```{r}
# Change reference group
data_wide_2$ADH_2 <- relevel(data_wide_2$ADH_2, ref = "100%")

# Create boxplots of physical QOL change by adherence group
ggplot(data_wide_2, aes(x = ADH_2, y = AGG_PHYS_CHANGE, fill = ADH_2)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Physical QOL Change by Adherence at Year 2",
       x = "Adherence at year 2",
       y = "Physical QOL Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```

That doesn't look as informative as our high vs low comparison should be.

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(ADH_HIGHVSLOW))

# Create boxplots of Physical QOL change by adherence group
ggplot(data_no_na, aes(x = ADH_HIGHVSLOW, y = AGG_PHYS_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Physical QOL Change by Adherence at Year 2",
       x = "Adherence at year 2",
       y = "Physical QOL Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```
It appears that the high adherence group has a higher increase in physical quality of life compared to the low adherence groups. 

Let's run the regression to see if that difference is statistically significant.

```{r}
# Perform regression predicting physical QOL change by adherence
model <- lm(AGG_PHYS_CHANGE ~ ADH_HIGHVSLOW, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is statistically significant (F~(1,530)~=12.7). On average, those with high adherence had a change in physical QOL score that was 4.81 points higher than those with low adherance. (p = 0.00399).

`ADH_HIGHVSLOW` will be included as a predictor for `AGG_PHYS_CHANGE`.

[Top of Tabset](#EDA)

## Frailty Related Phenotype

Frailty related phenotype was strongly correlated to pysical QOL change in the correlation matrix.

Let’s assess that relationship.

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(FRP_2))

# Create boxplots of physical QOL change by frailty related phenotype at year 2
ggplot(data_no_na, aes(x = FRP_2, y = AGG_PHYS_CHANGE, fill = FRP_2)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Boxplot of Physical QOL Change by Frailty Related Phenotype",
       x = "Frailty Related Phenotype",
       y = "Physical QOL Change") +
  guides(fill = guide_legend(title = "Frailty Related Phenotype"))
```

There is a very strong association here: those with frailty related phenotype have a large decrease in physical QOL over 2 years compared to those without a frailty related phenotype, who seem to have barely had any decrease in physical QOL at all.

Let's assess this relationship with a regression.

```{r}
# Perform regression predicting physical QOL change by Frailty Related Phenotype
model <- lm(AGG_PHYS_CHANGE ~ FRP_2, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is statistically significant (F~(1,541)~ = 72.39. On average, those with a frailty related phenotype had a change in physical QOL that was 12.79 points lower than those without a frailty related phenotype (p < .0001).

`FRP_2` will be included as a precision variable for the full model predicting  `AGG_PHYS_CHANGE`.

[Top of Tabset](#EDA)

## CESD Depression

```{r}
# Perform regression predicting physical QOL change by depression
model <- lm(AGG_PHYS_CHANGE ~ CESD_2, data = data_wide_2)

# Examine Summary
summary(model)
```

Is sig. but teeny tiny amount, not really needed.

[Top of Tabset](#EDA)

## CD4+ T Cell Count

```{r}
# Perform regression predicting physical QOL change by CD4+ T Cell Count
model <- lm(AGG_PHYS_CHANGE ~ LEU3N_CHANGE, data = data_wide_2)

# Examine Summary
summary(model)
```

Is sig but that doesn't even make sense cause that's one of our outcome variables.

Unless we're making this a complex model with multiple inputs.

[Top of Tabset](#EDA)

## College Education

```{r}
# Perform regression predicting physical QOL change by college education
model <- lm(AGG_PHYS_CHANGE ~ EDUC_COLLEGE, data = data_wide_2)

# Examine Summary
summary(model)
```

Not sig baby. Don't need to include.

[Top of Tabset](#EDA)

## Age

```{r}
# Perform regression predicting physical QOL change by age
model <- lm(AGG_PHYS_CHANGE ~ age_2, data = data_wide_2)

# Examine Summary
summary(model)
```

Not significant, `age` will not be included as a potential covariate for `AGG_PHYS_CHANGE`.

## BMI

```{r}
# Perform regression predicting physical QOL change by BMI
model <- lm(AGG_PHYS_CHANGE ~ BMI_2, data = data_wide_2)

# Examine Summary
summary(model)
```

`BMI` is a significant predictor of `AGG_PHYS_CHANGE` and will be included as a potential covariate.

## DKGRP

```{r}
# Perform regression predicting physical QOL change by drinking group
model <- lm(AGG_PHYS_CHANGE ~ DKGRP_2, data = data_wide_2)

# Examine Summary
summary(model)
```

`DKGRP_2` has a p-value below the threshold we set of p = 0.10, and will be included as a potential covariate for `AGG_PHYS_CHANGE`.


[Top of Tabset](#EDA)

:::
::::::

# Data Analysis {#Data_Analysis}

Now we will perform the actual analyses. We will have one model for each of:

 - Log Viral Load Change
 - CD4+ T Cell Count
 - Aggregate Mental QOL
 - Aggregate Physical QOL

## Log Viral Load Change

::: panel-tabset

## Full Model

As determined by [interactive variable selection](#EDA), the variables of interest for a model predicting `VLOAD_log_CHANGE` are `hard_drug_grp`, `ADH_HIGHVSLOW`, and `EDUC_COLLEGE`. 

The researchers are interested in if differences in treatment response between the drug use groups can be explained by differences in adherence to the HAART regimen, so we will also include an interaction term between hard drug use group and adherence.

Thus the full model is:

                                         ADD LATEX MATH SYNTAX HERE.
                                         
::: panel-tabset

## Analysis
                                         
Let's run the regression for the full model.
                                         
```{r}
# Relevel reference group
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel reference group
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform the regression on log viral load change with the full model
model_VLOAD_full1 <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_wide_2)
library(sjPlot)
# Examine summary
summary(model_VLOAD_full1)
tab_model(model_VLOAD_full1)
```

```{r}
# Print useful model parameters
model_results(model_VLOAD_full1)

# Get the VIFs
vif_values <- vif(model_VLOAD_full1)
pretty_print(vif_values)
```

The overall model is highly significant (p < 0.000001) and we're getting some interesting significant relationships. It looks like all of our main variables and interaction term are significant. Multicollinearity for this model is not a concern.

For low adherence, previous and current drug users have a higher increase in log viral load change over 2 years compared to never hard drug users (p > 0.05).

For never drug users, there is no difference in log viral load over 2 years in those with high adherence compared to those with low adherence (p = 0.11).

Let's keep going.

Change the reference category to high adherence, to compare the impact of hard drug use groups for those with high adherence to the treatment regiment.

```{r}
# Relevel reference group
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "High Adherence")

# Perform the regression on log viral load change with the full model
model_VLOAD_full2 <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_wide_2)

# Examine summary
summary(model_VLOAD_full2)
```

```{r}
# Print useful model parameters
model_results(model_VLOAD_full2)
```

At the high adherence levels, there is no difference between previous and current hard drug users and never hard drug users on log viral load change (p > 0.05).

Change the reference categories to previous users and low adherence to compare the impact of hard drug use groups for those with low adherence to the treatment regiment.

```{r}
# Relevel reference group
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Relevel reference group
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform the regression on log viral load change with the full model
model_VLOAD_full3 <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_wide_2)
```

```{r}
# Examine summary
summary(model_VLOAD_full3)

# Print useful model parameters
model_results(model_VLOAD_full3)
```

At low adherence, there is a significant difference between previous and current drug users, with current drug users having a higher increase in log viral load over 2 years (p < 0.0001).

For previous drug users, those with high adherence had less of an increase in log viral load over 2 years compared to those with low adherence (p < 0.0001).

Change the reference group to previous drug users and high adherence.

```{r}
# Relevel reference group
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Relevel reference group
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "High Adherence")

# Perform the regression on log viral load change with the full model
model_VLOAD_full4 <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_wide_2)

# Examine summary
summary(model_VLOAD_full4)
```


```{r}
# Print useful model parameters
model_results(model_VLOAD_full4)
```

At the high adherence level, there is no difference in log viral load change between current and previous hard drug users (p > 0.05).

Change the reference categories to current users and low adherence to compare the impact of hard drug use groups for those with low adherence to the treatment regiment.

```{r}
# Relevel reference group
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Current User")

# Relevel reference group
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform the regression on log viral load change with the full model
model_VLOAD_full5 <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_wide_2)

# Examine summary
summary(model_VLOAD_full5)
```

For current hard drug users, those with high adherence have a lower increase in log viral load over 2 years compared to those with low adherence (p = 0.011).

[Top of Tabset](#Data_Analysis)

## Model Selection

We can see that all variables, including `EDUC_COLLEGE`, are significant, and thus there is no need to compare the full model to reduced models; [this is our final model for `VLOAD_log_CHANGE`]{.underline}

We can double check this with a partial F-test comparing the full model with the reduced model without the interaction term 

```{r}
# Perform full model with interaction term
model_log_VLOAD_full <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + EDUC_COLLEGE + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Perform reduced model without interaction term
model_log_VLOAD_red <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_wide_2)

# Perform F-Test
anova(model_log_VLOAD_red, model_log_VLOAD_full)
```

The p-value is significant (p < 0.0001), indicating that the interaction term adds explanatory power to the model and should be included. Thus we move on with interpreting the interaction.

[Top of Tabset](#Data_Analysis)

## Interpretation

#### Overall Model

There were significant differences in change in log viral load based on hard drug usage and adherence to the treatment regiment, while controlling for education at baseline (F~(6, 513)~= 9.51), p < 0.0001). 

#### Hard Drug Use

The relationship between hard drug use and change in log viral load over 2 years depended on adherence to the treatment regiment.

##### Hard Drug Use at Low Adherence

For those with low adherence to the treatment regiment, current hard drug users had a change in log viral load that was 3.48 log copies/mL (or change in copies/mL that was 32.32 times) higher than never hard drug users (t = 2.458, p-adjusted  = 0.04284, 95% CI: 0.70 to 6.25 log copies/mL, or 2.01 to 519.78 times copies/mL). Additionally, for those with low adherence to the treatment regimen, previous hard drug users had a change in log viral load that was 5.81 log copies/mL (or change in copies/mL that was 333.05 times) greater than never hard drug users (t = 4.90, p-adjusted < 0.0001, 95% CI: 3.48 to 8.14 log copies/mL, or 32.42 to 3421.49 times copies/mL). 

For those with low adherence to the treatment regiment, the difference between previous and current drug users was not statistically significant (t = -1.35, p-adjusted = 0.177, 95% CI: -5.72 to 1.05 log copies/mL, or 0.0033 to 2.87 times copies/mL). 

##### Hard Drug use at High Adherence

For those with high adherence to the protocol, there was no difference in log viral load between current and never hard drug users (t = 1.920, p-adjusted = 0.388, 95% CI: -0.017 to 1.48 log copies/mL), previous and never hard drug users (t = -0.086, p-adjusted = 1.00, 95% CI: -0.86	to 0.94 log copies/mL), or previous and current hard drug users (t = 1.355, p-adjusted = 1.00, 95% CI: -0.35 to 1.89 log copies/mL).

#### Adherence

The relationship between adherence to the treatment regiment and change in log viral load over 2 years differed by hard drug use.

##### Adherence for Current Hard Drug Users

For current hard drug users, those with high adherence had a change in log viral load that was 3.53 log copies/mL (or 0.029 times) less than that of those with low adherence (t = -2.554, p-adjusted = 0.0999936, 95% CI: -6.25 to -0.70 log copies/mL, or 0.0019 to 0.50 times). However, this relationship was not statistically significant following Bonferroni correction, likely due to the small number of patients who were hard drug users with low protocol adherence (n = 4). This relationship however does appear to be real based on trends in the data, and we recommend increasing the sample size to discover the true differences.

##### Adherence for Previous Hard Drug Users

For previous hard drug users, those with high adherence had a change in log viral load that was 6.64 log copies/mL less (or 0.0013 times) than those with low adherence (t = -5.63, p-adjusted < 0.0001, 95% CI: -8.95 to -4.32 log copies/mL, or 0.00013 to 0.013 times).

##### Adherence for Never Hard Drug Users

For never hard drug users, the difference in log viral load between those with high adherence and low adherence was not statistically significant (t = -1.61, p-adusted = 0.759, 95% CI: -1.75 to 0.17 log copies/mL, or 0.17 to 1.19 times). 

#### Additional Interaction Comparisons

There are additional comparisons we can make in the interaction between hard drug usage and adherence, but they are of little clinical relevance (e.g. current hard drug users with low adherence had a higher viral load compared to never hard drug users with high adherence). Basically, any comparison made between a current or previous hard drug user with low adherence was significant.

#### College Education at Baseline

Education at baseline is a significant predictor for change in log viral load over 2 years, while controlling for hard drug use and adherence to treatment regiment (t = -2.872, p = 0.00424). On average, those with a college education had an 0.85 log copies/mL (or 2.34 times) greater decrease in log viral load than those without a college education (95% CI:-1.43 to -0.27 log copies/mL).

[Top of Tabset](#Data_Analysis)

## Visualizing the Interaction

The interaction between hard drug use and adherence group on log viral load can be visualized in the graph below.

```{r}
# Relevel reference group
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel reference group
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform a regression of the full model predicting log viral load change
model_VLOAD_full <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp * ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_wide_2)

library(interactions)

# Use interactions package to plot interaction
cat_plot(
  model_VLOAD_full, 
  pred = hard_drugs_grp, 
  modx = ADH_HIGHVSLOW, 
  geom = "line", 
  colors = "Pastel2",
  x.label = "Hard Drugs Group",
  y.label = "Predicted Log Viral Load Change"
)
```

This very clearly illustrates the relationships we saw in our model.

We can see the relationship between adherence and change in log viral load based on hard drug use: for previous and current hard drug users, those with high adherence had a reduced viral load compared to those with low adherence.

Similarly, we can see the relationship between hard drug use and change in log viral load based on adherence: For those with low adherence, previous and current drug users had a higher viral load compared to those with high adherence. 

Interestingly, viral load did not seem to differ for never users based on adherence, **suggesting that the ART treatment is most important for those with current or previous hard drug use history**.

Importantly however, this plot is not replicated exactly when I recreate it in ggplot2.

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(ADH_HIGHVSLOW))

# Summarize the data (using mean as an example)
data_summary <- data_no_na %>%
  group_by(hard_drugs_grp, ADH_HIGHVSLOW) %>%
  summarize(mean_VLOAD_log_CHANGE = mean(VLOAD_log_CHANGE, na.rm = TRUE))

# Create the plot with lines
ggplot(data_no_na, aes(x = hard_drugs_grp, y = VLOAD_log_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Interaction between Hard Drugs and Adherence on Log Viral Load Change",
       x = "Hard Drugs Group",
       y = "Log Viral Load Change") +
  guides(fill = guide_legend(title = "Adherence Group")) +
   theme_minimal() 
```

We can see that the boxplot for low adherence previous users (n = 4), and low adherence hard drug users (n = 6) are either really tiny or really large, respectively. This makes sense, because the sample size for both of those categories is so small.

```{r}
# Create table of hard drugs group by adherence group
pretty_print(table(data_wide_2$hard_drugs_grp, data_wide_2$ADH_HIGHVSLOW))
```

And let's examine how close those 4 values all are to each other.

```{r}
data_wide_2 %>%
  filter(hard_drugs_grp == "Current User" & ADH_HIGHVSLOW == "Low Adherence") %>%
  select(newid, VLOAD_log_CHANGE, hard_drugs_grp, ADH_HIGHVSLOW)
```

```{r}
data_wide_2 %>%
  filter(hard_drugs_grp == "Previous User" & ADH_HIGHVSLOW == "Low Adherence") %>%
  select(newid, VLOAD_log_CHANGE, hard_drugs_grp, ADH_HIGHVSLOW)
```

The values for current users with low adherence have low variance, explaining the tiny boxplot, and the values for previous users with low adherence have high variance, explaining the larger boxplot.

So I guess that's just a testament to the fact that you can't rely on packages!


::: callout-note
This is a very important limitation that will need to be addressed in the discussion!! 

While we see this interaction between hard drug use and adherence on the outcome variables in the data, more data must be collected to get a minimum of 30 patients per group and the analyses re-run to confirm these relationships hold!!
::: 

[Top of Tabset](#Data_Analysis)

:::

## Reduced Model - No Interaction

::: panel-tabset

## Analysis

Understanding the limitations of an interaction model with only n=4 or n=6 in some categories, we chose to also run the model without the interaction term to acquire the main effects of hard drug use group and adherence on log viral load change, while controlling for baseline education.

```{r}
# Relevel reference group
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform a regression on log viral load change without interaction term
model_VLOAD_red1 <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_wide_2)

# Examine summary
summary(model_VLOAD_red1)
```

```{r}
# Print useful model parameters
model_results(model_VLOAD_red1)
```

```{r}
# Relevel reference group
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform a regression on log viral load change without interaction term
model_VLOAD_red2 <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_wide_2)

# Examine summary
summary(model_VLOAD_red2)
```

```{r}
# Print useful model parameters
model_results(model_VLOAD_red2)
```

The overall model is significant (F(~4, 515)~= 8.241, p < 0.0001).

[Top of Tabset](#Data_Analysis)

## Interpretation

### Hard Drug Use

Hard drug use is a significant predictor of log viral load change, while controlling for adherence to the treatment regiment and college education. Specifically, current hard drug users had a change in log viral load that was 0.92 log copies/mL (or 2.50 times) greater than never hard drug users (t = 2.442, p-adjusted = 0.0447, 95% CI: 0.18 to 1.65 log copies/mL, or 1.20 to 5.23 times). There was no difference between previous and current hard drug users in change in log viral load over 2 years (t = 0.363, p-adjusted = 1.00, 95% CI: -0.87 to 1.27 log copies/mL, or 0.42 to 4.81 times).

### Adherence

Adherence to the treatment regiment is a significant predictor of change in log viral load, while controlling for hard drug usage and college education (t = -4.21, p < 0.0001). Specifically, those with high adherence to the protocol had an average change in log viral load that was 1.84 log copies/mL (or 0.16 times) less than those with low adherence to the protocol.

### College Education at Baseline

Finally, college education is a significant predictor of log viral load change, while controlling for hard drug usage and adherence to the treatment regiment (t = -2.32, p = 0.0206). On average, those with a college education had a change in log viral load that was 0.69 log copies/mL (or 1.99 times) less than those without a college education (95% CI: -2.70 to -0.98 log copies/mL, or 0.067 to 0.37 times).

[Top of Tabset](#Data_Analysis)

## Comparisons

The reduced model without the interaction has an adjusted R-squared of 0.0529, compared to the full model with the interaction term (R^2-adjusted = 0.090).

Therefore, dropping the interaction term causes us to lose explanation of 3.71% of the variance in log viral load change, but is also more statistically sound since we no longer have small sample size issues. 

[Top of Tabset](#Data_Analysis)

:::

## Confounding

Under the classical definition of a confounder, a variable Z is a confounder if:

 - 1) It is associated with outcome Y
 - 2) It is associated with PEV X
 - 3) It is not on the causal pathway (not a mediator)
 
We know that `ADH_HIGHVSLOW` is a predictor of `VLOAD_log_CHANGE`.

To assess if `ADH_HIGHVSLOW` is associated with hard drug use group, we can run a Fisher's test

```{r}
# Create a contingency table
contingency_table <- table(data_wide_2$hard_drugs_grp, data_wide_2$ADH_HIGHVSLOW)

# We have to run Fisher's Exact test since we have fewer than 5 observations in some categories
fisher_test <- fisher.test(contingency_table)

fisher_test
```


```{r}
# Create a contingency table
contingency_table <- table(data_wide_2$hard_drugs_grp, data_wide_2$EDUC_COLLEGE)

# We have to run Fisher's Exact test since we have fewer than 5 observations in some categories
fisher_test <- fisher.test(contingency_table)
```


They are not associated. 

However, it is not necessary for this associaton to be statistically significant for there to be important confounding present.

When we ran `drug_use_grp` by itself as a predictor on log viral load, the overall model was significant, but after correcting for multiple pairwise comparisons, none of the between-group comparisons was significant (p > 0.05).

However, after including `ADH_HIGHVSLOW` in the model, the current vs never drug use comparison is significant, even after performing a Bonferroni correction (p-adjusted = 0.0447). In the model without ADH, this same comparison was p-adjusted =  0.1377. 

Thus, `ADH_HIGHVSLOW` is associated with the outcome variable, and changes the relationship between the PEV and outcome variable in a meaningful way when included in the model (changes it from not significant to significant), meeting the definition of a confounder under the classical definition. However, the beta coefficient of the PEV does not change by > 20%, not satisfying the  operational definition of a confounder.

Adherence to the treatment regiment is therefore a maverick variable!

[Top of Tabset](#Data_Analysis)

## Visualizing Main Effects

Here we will create some simple plots to help with visualizing the main effects of hard drug use and adherence on log viral load change.

```{r}
# Create boxplots of log viral load change by hard drug use group
ggplot(data_wide_2, aes(x = hard_drugs_grp, y = VLOAD_log_CHANGE, fill = hard_drugs_grp)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Log Viral Load Change by Hard Drug Use Group",
       x = "Hard Drug Use Group",
       y = "Log Viral Load Change") +
  guides(fill = guide_legend(title = "Hard Drug Use Group"))
```

We can see that current and previous drug users had less of a decrease in log viral load over 2 years compared to never hard drug users.

```{r}
# Create boxplots of log viral load change by adherence group
ggplot(data_no_na, aes(x = ADH_HIGHVSLOW, y = VLOAD_log_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Log Viral Load Change by Adherence at Year 2",
       x = "Adherence at year 2",
       y = "Log Viral Load Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```
And here we can see those with high adherence had a higher decrease in log viral load over 2 years compared to those with low adherence.
:::
:::

## CD4+ T Cell Count Change

The second outcome variable of interest was change in CD4+ T Cell Count over the first 2 years of the study.

::: panel-tabset

## Full Model 

::: panel-tabset

## Model Selection

The candidate variables for inclusion in our model predicting `LEU3N_CHANGE` were `hard_drugs_grp`, `ADH_HIGHLOW`, `BMI_2`, `FRP_2`, and `EDUC_COLLEGE`. 

The researchers are interested in if differences in treatment response between the drug use groups can be explained by differences in adherence to the HAART regimen, so we will also include an interaction term between hard drug use group and adherence.

We begin by examining the full model with all these variables included.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on CD4+ T Cell count change by hard drugs group, include adherence as confounder, and BMI, frailty related phenotype, and college education as precision variables.
model_LEU3N_full1 <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + BMI_2 + FRP_2 + EDUC_COLLEGE + CESD_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Exmamine the summary
summary(model_LEU3N_full1)
```
We get an NA for the interaction term. This is likely because we dropped the n=6 patients that were previous hard drug users with low adherence, making the interaction impossible to make. Indeed we can see we only have 7, 453 degrees of freedom.

BMI is significant, but has 10% missing values. Let's try running the regression without it so we can examine that interaction term, which is the main research question. (it's also correlated to college education, so we can kind of capture it with that variable).

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Current User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on CD4+ T Cell count change by hard drugs group, include adherence as confounder, and BMI, frailty related phenotype, and college education as precision variables.
model_LEU3N_red1 <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + EDUC_COLLEGE + CESD_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Exmamine the summary
summary(model_LEU3N_red1)
```

### Backwards Elimination

We will perform model selection using backwards elimination and BIC to select the most parsimonious model.

A delta BIC of >2 indicates a difference in model performance.

```{r}
# Perform backward elimination regression selection based on BIC 
ols_step_backward_sbc(model_LEU3N_red1, include = c("hard_drugs_grp", "ADH_HIGHVSLOW"))
```
As predicted, the most parsimonious model is with `CESD_2` and `EDUC_COLLEGE` removed, and only including `FRP_2` as a precision variable.

[Top of Tabset](#Data_Analysis)

## Analysis

Let's investigate the key relationships in the final model for `LEU3N_CHANGE` as determined through backwards selection.

First let's look at the impact of hard drug use on CD4+ T Cell change, at low adherence.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on CD4+ T Cell count change by hard drugs group with covariates as determined by backward elimination
model_LEU3N_final1 <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_LEU3N_final1)
```

```{r}
# Print useful model parameters
model_results(model_LEU3N_final1)
```

The overall model is highly significant (F~(6,512)~= 8.42, p < 0.00001).

At low adherence, previous hard drug users have a higher CD4+ T Cell count than never hard drug users (p-adjusted = 0.043), but current hard drugs users did not differ from never drug users (p-adjusted = 0.40).

Additionally, for never hard drug users, those with high adherence have a higher CD4+ T Cell count than those with low adherence (p = 0.011895)

Now let's compare hard drug usage for those with high adherence.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "High Adherence")

# Perform regression on CD4+ T Cell count change by hard drugs group with covariates as determined by backward elimination
model_LEU3N_final2 <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_LEU3N_final2)
```


```{r}
# Print useful model parameters
model_results(model_LEU3N_final2)
```

For those with high adherence, previous hard drug users had a lower CD4+ T Cell count (p-adjusted = 0.0032), and current hard drug users had a lower CD4+ T Cell (p-adjusted < 0.0001) count compared to never hard users.

Now we make the same comparisons with previous hard drug users as the baseline.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on CD4+ T Cell count change by hard drugs group with covariates as determined by backward elimination
model_LEU3N_final2 <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_LEU3N_final2)
```

```{r}
# Print useful model parameters
model_results(model_LEU3N_final2)
```

At low adherence, current hard drug users had a CD4+ T Cell count compared to previous hard drug users (p-adjusted = 0.011).

Additionally, for previous hard drug users, those with high adherence had a greater decrease in CD4+ T Cell count compared to those with low adherence (p = 0.0073).

Now let's change the reference level to compare high adherence previous vs current drug users.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "High Adherence")

# Perform regression on CD4+ T Cell count change by hard drugs group with covariates as determined by backward elimination
model_LEU3N_final3 <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_LEU3N_final3)
```

```{r}
# Print useful model parameters
model_results(model_LEU3N_final3)
```



For those with high adherence, previous vs current hard drug users did not differ in CD4+ T Cell Count (p-adjusted= 1.00).

Finally let's compare the impact of adherence for hard drug users.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Current User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on CD4+ T Cell count change by hard drugs group with covariates as determined by backward elimination
model_LEU3N_final4 <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_LEU3N_final4)
```

```{r}
# Print useful model parameters
model_results(model_LEU3N_final4)
```

For current hard drug users, those with high adherence did not differ significantly compared to those with low adherence (p = 0.22)

`FRP_2` was a significant predictor for `LEU3N_CHANGE`, while controlling for hard drug use and adherence to the treatment regiment (t = -3.21, p = 0.0014). On average, those with a Frailty Related Phenotype had a decrease in CD4+ T cells that was 113.63 cells greater than those without a Frailty Related Phenotype (95% CI: 44.12 to  183.13 cells).

[Top of Tabset](#Data_Analysis)

## Interpretation

### Overall Model

There were significant differences in change in CD4+ T Cell count over 2 years based on hard drug usage and adherence to the treatment regiment, while controlling for Frailty Related Phenotype (F~(6,512)~ = 8.42, p < 0.00001). 

#### Hard Drug Use

The relationship between hard drug use and change in CD4+ T Cell count over 2 years depended on adherence to the treatment regiment.

##### Hard Drug Use at Low Adherence

For those with low adherence to the treatment regiment, previous hard drug users had on average a 197.90 cells greater *increase* in CD4+ T Cell count compared to never hard drug users (t = 2.46, p-adjusted =  0.043,
95%: 39.77	to 356.03). Current hard drug users did not differ from never hard drug users (t = -1.50, p-adjusted = 0.40, 95% CI: -332.74 to 44.54). Additionally, current hard drug users had on average a -342.00 cells greater decrease in CD4+ T Cell count compared to previous hard drug users (t = -2.922, p-adjusted = 0.011, 95% CI: -571.97 to -112.02).

##### Hard Drug Use at High Adherence

For those with high adherence to the treatment regiment, previous hard drug users had on average a 99.23 cells greater decrease (t = -3.29, p-adjusted = 0.0032, 95% CI: -158.4533 to -40.00727), and current hard drug users had on average a 111.16	cells greater decrease (t = -4.27, p-adjusted < 0.0001, 95% CI: -162.31	to -60.00) compared to never hard drug users. in CD4+ T cell count compared never hard drug users. Current hard drug users did not differ from previous hard drug users on change in CD4+ T Cell count over 2 years (t = -0.32, p-adjusted= 1.00, 95% CI: -85.79	to 61.93).

### Adherence

The relationship between adherence to the treatment regiment and change in CD4+ T Cell count over 2 years differed by hard drug use.

#### Adherence for Current Hard Drug Users

For current hard drug users, those with high adherence did not differ significantly in average change in CD4+ T Cells over two years compared to those with low adherence (t = 1.24, p-adjusted = 0.22, 95% CI: -68.51 to 300.57). 

### Adherence for Previous Hard Drug Users

For previous hard drug users, those with high adherence had on average a 214.03 cells greater decrease in CD4+ T Cell count compared to those with low adherence (t = -2.70, p = 0.0073, 95% CI: -370.05 to -58.020).	

### Adherence for Never Hard Drug Users

For never drug users, those with high adherence had on average a 83.09 cells greater decrease in CD4+ T Cell count compared to those with low adherence (t = 2.52, p = 0.0119, 95% CI: 18.42283	147.76529).

### Additional Interaction Comparisons

There are additional comparisons we can make in the interaction between hard drug usage and adherence, but they are of little clinical relevance (e.g. comparing current hard drug users with low adherence to never hard drug users with high adherence). 
### Frailty Related Phenotype

Frailty Related Phenotype was a significant predictor for change in CD4+ T Cell count over 2 years, while controlling for hard drug use and adherence to the treatment regiment (t = -3.21, p = 0.0014). On average, those with a Frailty Related Phenotype had a 113.63 cells greater decrease in CD4+ T Cell count than those without a Frailty Related Phenotype (95% CI: 44.12 to  183.13 cells).

[Top of Tabset](#Data_Analysis)

## Visualizing the Interaction

The below plot is useful in interpreting the interaction

```{r}
# Use interactions package to plot interaction
cat_plot(
  model_LEU3N_final1, 
  pred = hard_drugs_grp, 
  modx = ADH_HIGHVSLOW, 
  geom = "line", 
  colors = "Pastel2",
  x.label = "Hard Drugs Group",
  y.label = "Predicted CD4+ T Cell Count Change")

# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(ADH_HIGHVSLOW))

# Create the plot with lines
ggplot(data_no_na, aes(x = hard_drugs_grp, y = LEU3N_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Interaction between Hard Drugs and Adherence on LEU3N Change",
       x = "Hard Drugs Group",
       y = "LEU3N Change") +
  guides(fill = guide_legend(title = "Adherence Group")) +
   theme_minimal() 
```

Here we can see the key relationships in our model.

For current hard drug users, those with high adherence did not differ from those with low adherence. This may be an artifact of the small number of current hard drug users with low adherence, however (n = 6). 

For previous hard drug users, those with high adherence had *a smaller increase* in CD4+ T Cell count compared to those with low adherence. **This is a counter-inuitive finding and may be an artifact of the small number of previous hard drug users with low adherence, however (n=4).** It may be of interest to the clinicians however, and we therefore report it here.

For never hard drug users, those with high adherence had a greater increase in CD4+ T Cell count compared to those with low adherence.

At low adherence, previous hard drug users had *greater increase* in CD4+ T Cell count compared to never hard drug users, and also  when compared to current hard drug users. Current hard drugs users did not differ crom never hard drug users in change in CD4+ T Cell count at low adherence.

At high adherence, never drug users had a greater increase in CD4+ T cell count compared to previous and current hard drug users. Current hard drug users did not differ from previous hard drug users at high adherence.

[Top of Tabset](#Data_Analysis)

:::

## Reduced Model - No Interaction

::: panel-tabset

Understanding the limitations of an interaction model with only n=4 or n=6 in some categories, we chose to also run the model without the interaction term to acquire the main effects of hard drug use group and adherence on change in CD4+ T Cell count, while controlling for Frailty Related Phenotype.

## Analysis

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on CD4+ T Cell count change by hard drugs group with covariates as determined by backward elimination
model_LEU3N_final_noX1 <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2, data = data_wide_2)

# Examine the summary
summary(model_LEU3N_final_noX1)
```

```{r}
# Examine the summary
model_results(model_LEU3N_final_noX1)
```

Change the reference level to previous users and re-run the model

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on CD4+ T Cell count change by hard drugs group with covariates as determined by backward elimination
model_LEU3N_final_noX2 <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2, data = data_wide_2)

# Examine the summary
summary(model_LEU3N_final_noX2)
```

```{r}
# Examine the summary
model_results(model_LEU3N_final_noX2)
```

## Interpretation

### Overall Model

The overall model is significant (F~(4, 514)~ = 9.31, p < .0001). 

### Hard Drug Use

Hard drug use is a significant predictor of change in CD4+ T Cell count over 2 years.

Current hard drug users had an average change in CD4+ T Cell count that was 112.84 cells lower than never drug users, while controlling for adherence to treatment regiment and Frailty Related Phenotype (p-adjusted < 0.0001, 95% CI: -162.70 to -62.98). 

Previous hard drug users did not differ from never hard drugs users (p-adjusted = 0.088, 95% CI:-118.33 to	-6.29), or current hard drug users (p-adjusted = 0.483, 95% CI: -121.26 to 20.20).

### Adherence

Adherence was not a significant predictor for change in CD4+ T Cell count over 2 years, after controlling for hard drug use and Frailty Related Phenotype (t = 1.60,  p = 0.110).

### Frailty Related Phenotype

Frailty related phenotype is a significant predictor for change in CD4+ T Cell count over 2 years, while controlling for hard drug use and adherence to the treatment regiment (t = -3.20, p = 0.00145). On average, those with a frailty related phenotype had a change in CD4+ T Cell count that was 114.33 cells lower than those without a frailty related phenotype (95% CI: -184.51 to -44.16).

[Top of Tabset](#Data_Analysis)

## Visualizing Main Effects

### Hard Drug Use

Here we will create some simple plots to help with visualizing the main effects of hard drug use and adherence on change in CD4+ T Cell count.

```{r}
# Relevel to change the reference cateory to Never User
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Create boxplots of CD4+ T Cell count change by hard drug use group
ggplot(data_wide_2, aes(x = hard_drugs_grp, y = LEU3N_CHANGE, fill = hard_drugs_grp)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of CD4+ T Cell Count Change by Hard Drug Use Group",
       x = "Hard Drug Use Group",
       y = "CD4+ T Cell Count Change") +
  guides(fill = guide_legend(title = "Hard Drug Use Group"))
```
Current hard drug users had less of an increase in CD4+ T Cells over 2 years compared to never hard drug users. All other between-group comparisons were not significant.

### Adherence

```{r}
# Create boxplots of CD4+ T Cell count change by adherence group
ggplot(data_no_na, aes(x = ADH_HIGHVSLOW, y = LEU3N_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Boxplot of CD4+ T Cell Count Change by Adherence at Year 2",
       x = "Adherence Level",
       y = "CD4+ T Cell Count Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```
Change in CD4+ T Cell count did not differ based on adherence.

### Frailty Related Phenotype

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(FRP_2))

# Create boxplots of CD4+ T Cell count change by frailty related phenotype at year 2
ggplot(data_no_na, aes(x = FRP_2, y = LEU3N_CHANGE, fill = FRP_2)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Boxplot of CD4+ T Cell Count Change by Frailty Related Phenotype",
       x = "Frailty Related Phenotype",
       y = "CD4+ T Cell Count Change") +
  guides(fill = guide_legend(title = "Frailty Related Phenotype"))
```
Those with a Frailty Related Phenotype had less of an increase in CD4+ T Cell count compared to those without.

:::
:::

## Mental QOL Change

The candidate variables for mental QOL change as determined by interactive variable selection are `hard_drug_grp`, `ADH_HIGHLOW`, `CESD_2`.

::: panel-tabset

## Model Exploration

::: panel-tabset

## Analyses

Let's begin by running the full model as determined by interactive model selection.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_full1 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW +  CESD_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_full1)
```

Compare hard drug use groups at high adherence

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "High Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_full2 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW +  CESD_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_full2)
```

Compare hard drug use groups at low adherence

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_full3 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW +  CESD_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_full3)
```

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "High Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_full4 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW +  CESD_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_full4)
```

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Current User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "High Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_full5 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW +  CESD_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_full5)
```

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Current User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_full6 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW +  CESD_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_full6)
```

Interestingly, we have lost a lot of the significant relationships we were seeing before with our main predictors of hard drug use and adherence.

It seems that the main driver of this model, and best predictor of change in mental QOL score is depression score.

Within adherence levels, none of the hard drug use groups differed from each other on QOL (p-adjusted > 0.05).

The only significant difference in mental QOL change is for previous drug users. For previous drug users, those with low adherence have a mental QOL change that is on average 13.39 points lower than those with high adherence (p= 0.0118). Depending on how we handle multiple pairwise comparisons, this may not be significant!

Something fishy is going on here...

Let's examine this in a simplified model with no interactions.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_simple <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW +  CESD_2, data = data_wide_2)

# Examine the summary
summary(model_MENT_simple)
```

Indeed, we can see that, when including depression in the model, hard drug use and adherence are no longer significant predictors of change in mental QOL!

This suggests that depression score is either a mediator, a moderator, or a confounder for the relationship between hard drug use and adherence on mental QOL.

Let's explore.

[Top of Tabset](#Data_Analysis)

## Depression as a Confounder

### Confounder is related to PEV

We saw [earlier](#EDA) that hard drug use was a significant predictor for depression. Specifically:

Hard drug use is a significant predictor of depression score (F~(2, 542)~= 14.31). On average, current hard drug users had depression scores that were 5.23 points higher than never hard drug users (p < 0.0001), and previous hard drug users had depression scores that were 7.29 points higher than those who never used hard drugs (p < 0.0001).

Thus, depression meets criteria 1 of the classical definition for a confounder: It is related to the PEV.

### Confounder is related to the Outcome Measure

We also saw in the interactive variable selection that depression was significantly related change in mental QOL change.

Thus depression meets criteria 2 of the classical definition for a confounder: it is related to the main outcome.

### Confounder is not a Mediator

It is possible that depression is on the causal pathway for mental QOL (hard drug use -> depression -> mental QOL), but it is likewise possible that mental QOL is on the causal pathway for depression (hard drug use -> mental QOL -> depression). Thus we cannot conclude that depression is a mediator.

### Confounder Meaningfully Changes the Relationship of PEV on Outcome

We also saw that including depression in the model changed hard drug use from being significant to not significant. Thus depression score changes the relationship between the PEV and outcome measure in a very meaningful way.

I therefore feel justified in exploring depression as a confounder, and analyzing whether an interaction term between hard drug use group and depression will add explanatory power to our model. 

[Top of Tabset](#Data_Analysis)

## Including Depression Interaction Term

Let's run a new full model, with the included interaction term between hard drug use group and depression. In essence we are running a three way interaction. It will need to be emphasized in the discussion that this was exploratory data analysis.

```{r}
# Relevel to change to the reference group
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Current User")

# Relevel to change to the reference group
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_newfull <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW +  CESD_2 + hard_drugs_grp*ADH_HIGHVSLOW + hard_drugs_grp*CESD_2, data = data_wide_2)

# Examine the summary
summary(model_MENT_newfull)
```
We get a highly significant p-value for the interaction between hard drug use group and depression (p < 0.0001) 

Our adjusted R-squared also shot up from 0.090 to 0.16. We're on to something here.

Let's run backwards model selection and examine the BIC to see if we need to include the hard drug use * depression interaction score. 

### Backwards Elimination

We are going to force inclusion of our main variables of interest, `hard_drugs_grp` and `ADH_HIGHVSLOW`, and the interaction between them, since those were the main questions the researchers posed.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_newfull <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW +  CESD_2 + hard_drugs_grp*ADH_HIGHVSLOW + hard_drugs_grp*CESD_2, data = data_wide_2)

# Perform backward elimination regression selection based on BIC 
ols_step_backward_sbc(model_MENT_newfull, include = c("hard_drugs_grp", "ADH_HIGHVSLOW", "hard_drugs_grp:ADH_HIGHVSLOW"))
```

No variable was removed from the model, indicating that the interaction between hard drug use group and depression adds significant explanatory power and should be included in the model.

This puts us in a tricky position, it is clear that there is a relationship between hard drug use and mental quality of life, and that this differs based on both adherence and depression. However we don't necessarily have the sample size to run a three-way interaction.

### Next Steps

Thus, we will proceed in two ways from here, and run separate models for:

 - 1) Does the relationship between hard drug use and mental QOL differ based on adherence (irrespective of depression)?
 - 2) Does the relationship between hard drug use and mental QOL differ based on depression (irrespective of adherence)?
 
Removing the confounder of depression in model 1 allows us to answer the main research question for this project. Model 2) will be presented as an exploratory data analysis and allows us to explore how depression is related to hard drug use, and how that is affecting our main model.

[Top of Tabset](#Data_Analysis)

:::

## Model 1 - Main Research Question

This is the model predicting `AGG_MENT_CHANGE`, including only `hard_drugs_grp` and `ADH_HIGHVSLOW`, and their interaction term. 

This addresses the main research question of how mental QOL is impacted by ART, based on hard drug use and adherence to the treatment regimen.

::: panel-tabset

## Analysis

Let's run the regression as specified.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_main1 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW+ hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_main1)
```

```{r}
# Print useful model parameters
model_results(model_MENT_main1)

# Get the VIFs
vif_values <- vif(model_MENT_main1)
pretty_print(vif_values)
```

The overall model is significant (F~(5,526)~ = 4.78, p = 0.000278, and we are getting significant interactions.

At the same time, this is a weaker model than when we included depression. Our R-adjusted is now 0.034, meaning we now only explain 3.4% of the variance in mental QOL (compared to 16% in the full model).

At low adherence, the previous group has a greater decrease in mental QOL compared to never users.

For never users, there is no difference in mental QOL based on high or low adherence (t = 1.5744837, p-adjusted = 0.116, 95% CI: -0.85 to 7.72).

Change the reference group to compare drug use group at high adherence

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "High Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_main2 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW+ hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_main2)
```

```{r}
# Print useful model parameters
model_results(model_MENT_main2)
```


At high adherence, there is no difference in mental QOL between previous and never hard drug users (t = 1.41,  p-adjusted = 0.48, 95% CI: -1.12 to 6.73), or between current and never hard drug users (t = -1.85, p-adjusted = 0.195, 95% CI: -6.55 to	0.20).

Change reference level to compare previous hard drug users at low adherence.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_main3 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW+ hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_main3)
```

```{r}
# Print useful model parameters
model_results(model_MENT_main3)
```

Here we can see that all our p-values are now very low (all have at least 2 decimal places). This gives me confidence that this is a meaningful and strong model. All the most important comparisons are with previous drug users at low adherence!

At low adherence, current hard drug users have a higher mental QOL (p-adjusted = 0.00657), and never hard drug users have a higher mental QOL (p-adjusted = 0.00886) compared to previous hard drug users.

Additionally, for previous hard drug users, those with high adherence had a higher increase in mental QOL compared to those with low adherence (p < 0.0001).

Change reference category to compare high adherence previous hard drug users.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "High Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_main4 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_main4)
```

```{r}
# Print useful model parameters
model_results(model_MENT_main4)
```

At high adherence, there is a borderline significant difference between previous and current drug users (p-adjusted = 0.050). Considering the small sample size in both categories, this could become a non significant difference with a larger N.

Change the reference level to compare current hard drug users

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Current User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_main5 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_main5)
```

```{r}
# Print useful model parameters
model_results(model_MENT_main5)
```

For current hard drug users, there was no difference in mental QOL based on adherence (t = -1.24, p = 0.227, 95% CI: -19.94 to	4.53).

[Top of Tabset](Data_Analysis)

## Interpretation

### Overall model

There were significant differences in change mental QOL over 2 years based on hard drug usage and adherence to the treatment regiment (F~(5,526)~ = 4.78, p = 0.000278).

### Hard Drug Use

The relationship between hard drug use and change in mental QOL over 2 years depended on adherence to the treatment regiment.

#### Hard Drug Use at Low Adherence

For those with low adherence to the treatment regiment, previous hard drug users had a 15.95 point decrease in mental QOL compared to never hard drug users (t = -2.99, p-adjusted = 0.00886, 95% CI: -26.46 to -5.50), and a 23.91 point decrease compared to current hard drug users (t = 3.078, p-adjusted =  0.00657, 95% CI: 8.65 to 39.17). There was no difference in mental QOL between current and never hard drug users at low adherence (t = 1.25,	p-adjusted = 0.636, 95% CI: -4.56 to	20.48).

#### Hard Drug use at High Adherence

For those with low adherence to the treatment regiment, there was no difference in mental QOL between previous and never hard drug users (t = 1.41,  p-adjusted = 0.48, 95% CI: -1.12 to 6.73), or between current and never hard drug users (t = -1.85, p-adjusted = 0.195, 95% CI: -6.55 to	0.20). The difference in mental QOL for current and previous users was borderline significant (t= -2.40, p-adjusted = 0.050, 95% CI: -10.88	to -1.09), and with a larger sample size may become non-significant.

### Adherence

The relationship between adherence to the treatment regiment and change in mental QOL over 2 years differed by hard drug use.

#### Adherence for Current Hard Drug Users

For current hard drug users,there was no difference in mental QOL change over 2 years based on adherence (t = -1.24, p = 0.227, 95% CI: -19.94 to	4.53).

#### Adherence for Previous Hard Drug Users

For previous hard drug users, there was a statistically significant difference in change in mental QOL over 2 years based on adherence (t = 4.21, p-adjusted =  0.000536). On average, previous hard drug users with high adherence had a 22.19 point increase in mental QOL over 2 years compared to those with low adherence (95% CI: 11.84 to 32.54).

#### Adherence for Never Hard Drug Users

For never hard drug users, there was no difference in change in mental QOL over 2 years based on high or low adherence (t = 1.5744837, p-adjusted = 0.116, 95% CI: -0.85 to 7.72).

[Top of Tabset](#Data_Analysis)

## Visualizing the Interaction

The below plot is useful in interpreting the interaction

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Use interactions package to plot interaction
cat_plot(
  model_MENT_main1, 
  pred = hard_drugs_grp, 
  modx = ADH_HIGHVSLOW, 
  geom = "line", 
  colors = "Pastel2",
  x.label = "Hard Drugs Group",
  y.label = "Predicted Mental QOL Change")
```
Here we see the main interaction finding: for previous users, those with low adherence had a decrease in mental QOL over 2 years compared to those with high adherence who had an slight increase.

Additionally, for those with low adherence, previous hard drug users had a decrease in mental QOL over 2 years compared to current hard drug users and never hard drug users.

We interpret this to mean that previous hard drug users (those in either their first or second year of sobriety) are struggling to deal with withdrawals, addiction, or the adverse effects of the treatment. While current users are in the midst of using hard drugs as a coping mechanism, and thus are protected from the negative impact of the treatment on mental QOL.

Thus, **previous hard drug users are a vulnerable population, and high adherence to the treatment regiment might buffer them against the adverse effects of the HAART treatment.**

[Top of Tabset](#Data_Analysis)

:::

## Model 2 - Depression Interaction Term

This is the model predicting `AGG_MENT_CHANGE`, including only `hard_drugs_grp` and `CESD_2`, and their interaction term. 

This addresses the confounding of depression on the relationship between hard drug use and change in mental QOL.

::: panel-tabset

## Analysis

Compare slopes for never users.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_sub1 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + CESD_2 + hard_drugs_grp*CESD_2, data = data_wide_2)

# Examine the summary
summary(model_MENT_sub1)

# Get the VIFs
vif_values <- vif(model_MENT_sub1)
pretty_print(vif_values)
```

```{r}
# Print useful model parameters
model_results(model_MENT_sub1)
```

The overall model is highly significant (F~(5, 532)~ = 19.84, p < 0.0001, adjusted R-squared = 0.149).

For never hard drug users, there was a significant relationship between depression and mental QOL (t = -4.42, p < 0.0001). Specifically, for never hard drug users, a 1 point increase in depression score was associated with 0.23 point decrease in mental QOL (95% CI: -0.34 to -0.13).

Current hard drug users did not differ significantly from never hard drug users while controlling for the other variables in the model (t = -1.05, p-adjusted = 0.89, 95% CI: -8.74 to 2.66). Previous hard drug users had on average a 16.98 higher increase in mental QOL compared to never hard drug users (at low depression scores?) (t = 2.91062, p-adjusted < 0.0001.

The slope for depression on mental QOL did not differ between current and never hard drug users (t = 0.73, p-adjusted = 1.00, 95% CI: -0.19 to 0.41). However, the slope for depression on mental QOL did differ between previous and never hard drug users (t = -6.17, p-adjusted < 0.0001). For each point increase in depression, the mental QOL score for previous hard drug users decreases an additional 0.80 points compared to never hard drug users (95% CI: -1.06	to -0.55).

Previous hard drug users have an increase of approximately 16.98 units in mental QOL, holding all other variables constant. This difference is statistically significant, suggesting that prior hard drug use is associated with a considerably higher outcome measure in this model. (It's significant because we're not account for the interaction with this estimate.)

Compare slopes for previous users.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_sub2 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + CESD_2 + hard_drugs_grp*CESD_2, data = data_wide_2)

# Examine the summary
summary(model_MENT_sub2)
```

```{r}
# Print useful model parameters
model_results(model_MENT_sub2)
```

For previous hard drug users, there was a significant relationship between depression and mental QOL (t = -8.74, p < 0.0001). Specifically, for previous hard drug users, a 1 point increase in depression score was associated with a 1.04 point decrease in mental QOL (95% CI: -1.27 to -0.80). That is nearly 5 times more of a decrease compared to never users!

Compare slopes for current users.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Current User")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_sub3 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + CESD_2 + hard_drugs_grp*CESD_2, data = data_wide_2)

# Examine the summary
summary(model_MENT_sub3)
```

```{r}
# Print useful model parameters
model_results(model_MENT_sub3)
```

For current users, the relationship between depression and mental QOL is not significant (t = 0.88, p = 0.377, 95% CI: -0.40 to 0.15).               

The slope for depression on mental QOL depended on hard drug use (t = -4.946, p-adjusted < 0.0001). For each point increase in depression, the mental QOL score for previous hard drug users decreased by an additional 0.91 points compared to current hard drug users (95%: -1.28 to -0.55).

[Top of Tabset](#Data_Analysis)

## Interpretation 

### Overall Model

The overall model is highly significant (F~(5, 532)~ = 19.84, p < 0.0001, adjusted R-squared = 0.149).

The relationship between depression and mental QOL depended on hard drug use.

### Depression Slopes **within** Hard Drug Use Group

#### Depression for Current Hard Drug Users

For current hard drug users, the relationship between depression and mental QOL is not significant (t = 0.88, p = 0.377, 95% CI: -0.40 to 0.15). 

#### Depression for Previous Hard Drug Users

For previous hard drug users, there was a significant relationship between depression and mental QOL (t = -8.74, p < 0.0001). Specifically, a 1 point increase in depression score was associated with a 1.04 point decrease in mental QOL for previous hard drug users (95% CI: -1.27 to -0.80). That is nearly 5 times more of a decrease compared to never users!

#### Depression for Never Hard Drug Users

For never hard drug users, there was a significant relationship between depression and mental QOL (t = -4.42, p < 0.0001). Specifically, a 1 point increase in depression score was associated with 0.23 point decrease in mental QOL for never hard drug users (95% CI: -0.34 to -0.13).

### Depression Slopes **between** Hard Drug use Group

The slopes for the relationship between depression and QOL differed based on hard drug use.

For each point increase in depression, the mental QOL score for previous hard drug users decreased an additional 0.80 points compared to never hard drug users (t = -6.17, p-adjusted < 0.0001, 95% CI: -1.06	to -0.55).

Additionally, for each point increase in depression, the mental QOL score for previous hard drug users decreased by an additional 0.91 points compared to current hard drug users (t = -4.946, p-adjusted < 0.0001, 95%: -1.28 to -0.55).

The slope for depression on mental QOL did not differ between current and never hard drug users (t = 0.73, p-adjusted = 1.00, 95% CI: -0.19 to 0.41). 

[Top of Tabset](#Data_Analysis)

## Visualizing the Interaction

The plot below is helpful in interpreting the interaction between hard drug use and depression on mental QOL.

```{r}
# Create a scatterplot of mental QOLchange by depression score, colored by hard drug use group.
ggplot(data_wide_2, aes(x = CESD_2, y = AGG_MENT_CHANGE, color = hard_drugs_grp)) + 
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  labs(title = "Mental QOL Change by Depression at 2 years, Colored by Hard Drug Use Group",
       y = "Mental QOL Change",
       x = "Depression Score") + 
  scale_fill_brewer(palette = "Pastel2")
```

Here we can see the key relationships found in the model.

There is a negative relationship between depression and mental QOL scores at each level of drug usage. However, this relationship is much stronger for previous hard drug users, where every 1 point increase in depression scores is associated with an almost 5x greater decrease in mental QOL score over 2 years (~1 point for previous users compared to ~0.2 points for current and never user).

And most importantly the slopes differed significantly by hard drug use group, with previous hard drug users having an additional 0.8 or 0.9 greater decrease in mental QOL score compared to never and current hard drug users, respectively.

Thus, we used this relationship as **further evidence that previous hard drug users are a vulnerable group**. They are susceptible to losses in mental QOL if they have low adherence to the treatment regiment, and depression has a greater impact on the mental QOL of previous hard drug users compared to current and never hard drug users.

[Top of Tabset](#Data_Analysis)
:::

## Conclusion

We found a dual interaction where the impact of hard drug use on mental QOL depended on both adherence to the treatment regimen and depression.

For adherence, those with previous hard drug use had a decrease in mental QOL if and only if they had low adherence to the treatment regiment.

For depression, previous hard drug users had a larger decrease in mental QOL compared to never and current hard drug users.

Thus, we used both of these relationships as **strong evidence that previous hard drug users are a vulnerable population**. They are susceptible to losses in mental QOL if they have low adherence to the treatment regiment, and depression has a greater impact on their mental QOL compared to current and never hard drug users.

This finding has great clinical relevance for the treatment of HIV in hard drug users. Specifically, extra efforts should be made to help previous hard drug users in two ways: One, adherence appears to serve as a buffer for previous hard drug users in the relationship between hard drug use and mental QOL. Efforts to increase adherence should therefore be made to help patients receive this ameliorative effect. Two, previous hard drug users do not have the coping mechanism of heroin or opiates available to them to buffer against the impact of adverse effects from ART, and thus extra aid perhaps in the form of increased therapy should be provided to these patients to provide them with alternate coping strategies.

[Top of Tabset](#Data_Analysis)

## Bonus - Predicting Depression

Just for completion's sake, we can run a regression predicting depression score based on the interaction between hard drug use and adherence.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on mental QOL change by hard drugs group, full model
model_MENT_full1 <- lm(CESD_2 ~ hard_drugs_grp + ADH_HIGHVSLOW+ hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_MENT_full1)
```

```{r}
# Use interactions package to plot interaction
cat_plot(model_MENT_full1, pred = hard_drugs_grp, modx = ADH_HIGHVSLOW, geom = "line", colors = "Pastel2")
```
The interaction is significant, and we can see that previous hard drug users with low adherence had higher depression scores at year 2, and that those with high adherance were buffered from this effect.

The fact that depression and mental QOL both have this relationship, and are similar constructs, lends credence to the likelihood that this is a real relationship, and a strong one at that.

:::

## Physical QOL Score {#Phys}

The fourth outcome variable of interest was change physcal QOL over the first 2 years of the study.

::: panel-tabset

## Full Model

::: panel-tabset

## Model Selection

The candidate variables for inclusion in our model predicting `AGG_PHYS_CHANGE` were `hard_drugs_grp`, `ADH_HIGHVSLOW`, `FRP_2`, `CESD_2`, `BMI`, and `DKGRP_2`

We will remove `BMI` based on the missing values issue identified in the mental QOL model.

Let's run the full model including all those variables and the interaction between hard drug use group and adherence high vs low.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")


# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on Physical QOL change
model_PHYS_full1 <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + CESD_2 + DKGRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the model
summary(model_PHYS_full1)
```

```{r}
# Get the VIFs
vif_values <- vif(model_PHYS_full1)
pretty_print(vif_values)
```

The overall model is highly significant (F~(10,510)~ = 12.92, p < 0.0001, Adjusted R-squared = 0.187).

We have some nice significant covariates, but it looks like `FRP_2` is the main driver for this model.

We might have another double interaction situation like we did for the mental QOL model. Let's create an interaction term between `hard_drugs_grp` and `FRP_2` and run it through backwards elimination to select our final model based on BIC.


### Backwards Elimination

We will perform model selection using backwards elimination and BIC to select the most parsimonious model.

A delta BIC of >2 indicates a difference in model performance.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on physical QOL change
model_PHYS_full1 <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + CESD_2 + DKGRP_2 + hard_drugs_grp*ADH_HIGHVSLOW + hard_drugs_grp*FRP_2, data = data_wide_2)

# Perform backward elimination regression selection based on BIC 
ols_step_backward_sbc(model_PHYS_full1, include = c("hard_drugs_grp", "ADH_HIGHVSLOW", "hard_drugs_grp:ADH_HIGHVSLOW"))
```
The final model selected for `AGG_PHYS_CHANGE` includes the PEVs of `hard_drugs_grp` and `ADH_HIGHVSLOW` and their interaction term, and `FRP_2` as a precision variable. Luckily we only have to interpret one interaction for this model!


```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")


# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on Physical QOL change
model_PHYS_full1 <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + CESD_2 + DKGRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the model
summary(model_PHYS_full1)
```
```{r}
# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on Physical QOL change by hard drugs group, full model
model_PHYS_full <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Exmamine the summary
summary(model_PHYS_full)

# Use interactions package to plot interaction
cat_plot(model_PHYS_full, pred = hard_drugs_grp, modx = ADH_HIGHVSLOW, geom = "line", colors = "Pastel2")
```

[Top of Tabset](#Phys)

## Analysis

Let’s investigate the key relationships in the final model for `AGG_PHYS_CHANGE` as determined through backwards selection.

First let’s look at the impact of hard drug use on physical QOL at low adherence.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on phys QOL
model_PHYS_final1 <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_PHYS_final1)
```

```{r}
# Print useful model parameters
model_results(model_PHYS_final1)
```


The overall model is highly significant (F~(6, 525)~ = 20.67, p < 0.0001, adjusted R-squared = 0.1818).

At low adherence, previous hard drug users had on average a 10.89 point decrease in physical QOL compared to never hard drug users (t = -3.16, p-adjusted = 0.00493, 95% CI: -17.66	to -4.13). Current hard drug users did not differ significantly from never hard drug users at low adherence (t = -2.35, p-adjusted =0.0574, 95% CI: -17.72 to -1.58), although with a larger sample size that could become significant. 

For never hard drug users, those with high adherence had a 3.19 point increase in physical QOL compared to those with low adherence (t = 2.27, p = 0.0239).

Compare hard drug use groups at high adherence

```{r}

# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "High Adherence")

# Perform regression on phys QOL
model_PHYS_final2 <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_PHYS_final2)
```

```{r}
# Print useful model parameters
model_results(model_PHYS_final2)
```

At high adherence, current hard drug users had on average a 3.94 point decrease in physical QOL compared to never hard drug users (t = -3.545, p-adjusted = 0.00128, 95% CI: -6.12 to -1.75). Additionally, previous hard drug users did not differ significantly from never hard drug users at high adherence (t = 1.100, p-adjusted = 0.815, 95% CI: -1.11 to 3.94).

Change reference level to compare previous users

```{r}

# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on phys QOL
model_PHYS_final3 <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_PHYS_final3)
```

```{r}
# Print useful model parameters
model_results(model_PHYS_final3)
```

At low adherence, previous hard drug users did not differ significantly on change in physical QOL compared to current hard drug users (t = 0.25, p-adjusted = 1.00, 95% CI: -8.59 to 11.08).

For previous hard drug users, those with high adherence to the treatment regiment had on average a 15.49 point increase in physical QOL compared to those with low adherence (t = 4.56, p-adjusted < 0.0001, 95% CI: 8.82 to 22.17).

Change the reference level to current hard drug users.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Current User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "Low Adherence")

# Perform regression on phys QOL
model_PHYS_final4 <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_PHYS_final4)
```


```{r}
# Print useful model parameters
model_results(model_PHYS_final4)
```

For current hard drug users, those with high adherence had on average an 8.90 point increase in physical QOL compared to those with low adherence (t = 2.22, p = 0.027, 95% CI: 1.00 to 16.79).

Change reference level to high adherence to compare last group.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Current User")

# Relevel to change to the reference group to never user
data_wide_2$ADH_HIGHVSLOW <- relevel(data_wide_2$ADH_HIGHVSLOW, ref = "High Adherence")

# Perform regression on phys QOL
model_PHYS_final5 <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + FRP_2 + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

# Examine the summary
summary(model_PHYS_final5)
```


```{r}
# Print useful model parameters
model_results(model_PHYS_final5)
```

At high adherence, current hard drug users had on average a change in physical QOL that was 5.35 points less than previous hard drug users (t = 3.33, p-adjusted = 0.00279, 95% CI: 2.19 to 8.51).

[Top of Tabset](#Phys)

## Interpretation

### Overall Model

There were significant differences in change in physical QOL over 2 years based on hard drug usage and adherence to the treatment regiment, while controlling for Frailty Related Phenotype (F~(6, 525)~ = 20.67, p < 0.0001, adjusted R-squared = 0.1818).

#### Hard Drug Use

The relationship between hard drug use and change in physical QOL over 2 years depended on adherence to the treatment regiment.

#### Hard Drug Use at Low Adherence

At low adherence, previous hard drug users had on average a 10.89 point decrease in physical QOL compared to never hard drug users (t = -3.16, p-adjusted = 0.00493, 95% CI: -17.66	to -4.13), but did not differ significantly on change in physical QOL compared to current hard drug users (t = 0.25, p-adjusted = 1.00, 95% CI: -8.59 to 11.08).
. Current hard drug users did not differ significantly from never hard drug users at low adherence (t = -2.35, p-adjusted =0.0574, 95% CI: -17.72 to -1.58), although with a larger sample size that could become significant. 

#### Hard Drug Use at High Adherence

At high adherence, current hard drug users had on average a 3.94 point decrease in physical QOL compared to never hard drug users (t = -3.545, p-adjusted = 0.00128, 95% CI: -6.12 to -1.75), and 5.35 points decrease compared to previous hard drug users (t = 3.33, p-adjusted = 0.00279, 95% CI: 2.19 to 8.51). Additionally, previous hard drug users did not differ significantly from never hard drug users at high adherence (t = 1.100, p-adjusted = 0.815, 95% CI: -1.11 to 3.94).

### Adherence
The relationship between adherence and  change in physical QOL over 2 years depended on hard drug use.

#### Adherence for Current Hard Drug Users

For current hard drug users, those with high adherence had on average an 8.90 point increase in physical QOL compared to those with low adherence (t = 2.22, p = 0.027, 95% CI: 1.00 to 16.79).

#### Adherence for Previous Hard Drug Users

For previous hard drug users, those with high adherence to the treatment regiment had on average a 15.49 point increase in physical QOL compared to those with low adherence (t = 4.56, p-adjusted < 0.0001, 95% CI: 8.82 to 22.17).

#### Adherence for Never Hard Drug Users

For never hard drug users, those with high adherence had a 3.19 point increase in physical QOL compared to those with low adherence (t = 2.27, p = 0.0239).

### Frailty Related Phenotype

Frailty related phenotype was a significant predictor of change in physical QOL over 2 years (t = -8.72, p < 0.0001). On average, those with a frailty related phenotype had a 12.76 decrease in physical QOL compared to those without a frailty related phenotype (95% CI: -15.63 to -9.88).


[Top of Tabset](#Phys)

## Visualizing the Interaction 

The below plot is useful in interpreting the interaction.


```{r}
# Use interactions package to plot interaction
cat_plot(
  model_PHYS_final1, 
  pred = hard_drugs_grp, 
  modx = ADH_HIGHVSLOW, 
  geom = "line", 
  colors = "Pastel2",
  x.label = "Hard Drugs Group",
  y.label = "Predicted Physical QOL Change")
```

For those with low adherence, previous users had a greater decrease in physical QOL compared to never users. The difference between current and never hard drug users at low adherence is borderline significant, and may be so with a larger sample size.

For those with high adherence, the current hard drug use group had a greater decrease in physical QOL compared to both never and previous hard drug users.

And most importantly, for previous hard drug users, those with low adherence had a decrease in physical QOL when compared to those with high adherence.

We take this as **further evidence that previous hard drug users are at a vulnerable population**. High adherence serves as a buffer and could protect patients that have quit heroin or opiates within the past 2 years. 

Additionally, we have evidence that even at high adherence, current hard drug users have worse overall physical QOL.

:::

:::


# Evaluating Assumptions {#Assumptions}

In order to evaluate the assumptions of our models, we will first gather the residuals for the final model predicting each outcome variable.

```{r}
# Calculate the jackknife residuals of the model predicting VLOAD
jackknife_residuals_VLOAD <- rstudent(model_VLOAD_full1)

# Calculate the jackknife residuals of the model predicting VLOAD sub analyss
jackknife_residuals_VLOAD_sub <- rstudent(model_VLOAD_red1)

# Calculate the jackknife residuals of the model predicting LEU3N
jackknife_residuals_LEU3N <- rstudent(model_LEU3N_final1)

# Calculate the jackknife residuals of the model predicting mental QOL 1
jackknife_residuals_MENT_main <- rstudent(model_MENT_main1)

# Calculate the jackknife residuals of the model predicting mental QOL 2
jackknife_residuals_MENT_sub <- rstudent(model_MENT_sub1)

# Calculate the jackknife residuals of the model predicting physical QOL
jackknife_residuals_PHYS <- rstudent(model_PHYS_final1)

```

## Log Viral Load 

::: panel-tabset

## Linearity

Since the mains IVs are categorical, we do not need to evaluate linearity.

[Top of Tabset](#Assumptions)

## Independence

Independence can be assessed in part by the study design and how the data was collected. Based on the information provided by the PI, I will assume subjects are independent from each other.

Additionally, we can examine a scatter plot of the model’s residuals against any time point variable (such as ID).

```{r}

data_VLOAD <- data_wide_2 %>%
  dplyr::select(newid, VLOAD_log_CHANGE, hard_drugs_grp, ADH_HIGHVSLOW, EDUC_COLLEGE) %>%
  filter(
    !is.na(newid) & 
    !is.na(VLOAD_log_CHANGE) &
    !is.na(hard_drugs_grp) & 
    !is.na(ADH_HIGHVSLOW) & 
    !is.na(EDUC_COLLEGE) 
  )

# Create a scatterplot of jackknife residuals vs ID to assess independence 
ggplot(data_VLOAD, aes(x = newid, y = jackknife_residuals_VLOAD)) + 
  geom_point() +
  geom_hline(yintercept = 0) +
  labs(title = "Scatterplot of Jackknife Residuals vs ID for Log Viral Load",
       x = "ID",
       y = "Jackknife Residuals")
```

We may have some non-independence as seen by the further spread above 0.

[Top of Tabset](#Assumptions)

## Normality

Here we will asses that, for any fixed value of X, Y has a normal distribution. We will do this using Q-Q plots and histograms of the residuals.

```{r}
# Make the Q-Q plots using the jackknife residuals
qqnorm(jackknife_residuals_VLOAD, main = "Q-Q plots of Jackknife Residuals for Log Viral Load")
qqline(jackknife_residuals_VLOAD, col = "black")

# Create histogram of jackknife residuals
hist(jackknife_residuals_VLOAD, main = "Histogram of Jackknife Residuals",
     breaks = 24,
     xlab = "Jackknife Residuals",
     col = "lightblue",
     border = "black")
```

We can also include the Shapiro-Wilk test of normality, which provides a p-value and allows us to numerically establish that the assumption of normality is met. If the p-value is < 0.05 you conclude that the assumption of normality is not met.

```{r}
shapiro.test(jackknife_residuals_VLOAD)
```


We have some non-normality as seen by the higher end of the Q-Q Plot.

Looking at the histograms, the pattern is slightly bimodal, and may have some outliers at the high range.

We also fail Shapiro-Wilk's test, indicating non-normality.

[Top of Tabset](#Assumptions)

## Equal Variances (Homoscedasticity)

To assess homoscedasticity we examine the residual scatterplots by treatment group. The warning sign to look for here is if the variance differs greatly across groups.

```{r}
# Make the residual scatterplot using the jackknife residuals
ggplot(data_VLOAD, aes(x = hard_drugs_grp, y = jackknife_residuals_VLOAD)) +
  geom_boxplot() + 
  labs(title = "Jackknife Residuals vs Hard Drug Use for Log Viral Load",
       x = "Hard Drug Use Group",
       y = "JackKnife Residuals")
```
```{r}
# Make the residual scatterplot using the jackknife residuals
ggplot(data_VLOAD, aes(x = ADH_HIGHVSLOW, y = jackknife_residuals_VLOAD)) +
  geom_boxplot() + 
  labs(title = "Jackknife Residuals vs Adherence for Log Viral Load",
       x = "Adherence",
       y = "JackKnife Residuals")
```

It appears that our hard drug use groups have unequal variances.

Additionally, while it is not recommended to perform a statistical test to assess for equality of variances (because formal tests of equality of variance are not very powerful), we can still do this using Bartlett’s test. The null hypothesis of the Bartlett test is that the variances are equal. Thus failing to reject the null (p > 0.05) indicates that the data are consistent with the equal variance assumption.

```{r}
# Perform Bartlett's test to check for homogeneity of variances
bartlett.test(VLOAD_log_CHANGE ~ hard_drugs_grp, data = data_VLOAD)
```

We also do not meet the assumption for equality of variances (p < 0.05). 

This is likely because our patients were not randomly assigned into these groups!

[Top of Tabset](#Assumptions)

## Residuals Centered Around Zero

To start, we can simply check that the mean of our residuals is close to 0.
```{r}
# Generate the mean of the jackknife residuals. Should be close to 0.
mean(jackknife_residuals_VLOAD)

# Generate vectors containing the fitted values vs jackknife residuals so we can plot them 
fitted_values_VLOAD <- fitted(model_VLOAD_full1)

ggplot(data_VLOAD, aes(x = fitted_values_VLOAD, y = jackknife_residuals_VLOAD)) + 
  geom_point() +
  geom_smooth(method = "lm")
```

We definitely have outliers present.

The mean is close to 0.

A more sophisticated approach is to plot the fitted values vs jackknife residuals. We can then compare the trend between groups to see if they are random. The fitted line should gravitate around 0 with no obvious trends.

[Top of Tabset](#Assumptions)

## Summary

[Top of Tabset](#Assumptions)


:::


## CD4+ T Cell Count 



::: panel-tabset

## Linearity

We do not need to assess linearity since our main PEVs are categorical.

[Top of Tabset](#Assumptions)

## Independence

Independence can be assessed in part by the study design and how the data was collected. Based on the information provided by the PI, I will assume subjects are independent from each other.

Additionally, we can examine a scatter plot of the model’s residuals against any time point variable (such as ID).

```{r}
# Filter to create same data set as in the final analysis
data_LEU3N <- data_wide_2 %>%
  dplyr::select(newid, LEU3N_CHANGE, hard_drugs_grp, ADH_HIGHVSLOW, FRP_2) %>%
  filter(
    !is.na(newid) & 
    !is.na(LEU3N_CHANGE) &
    !is.na(hard_drugs_grp) & 
    !is.na(ADH_HIGHVSLOW) & 
    !is.na(FRP_2) 
  )

# Create a scatterplot of jackknife residuals vs ID to assess independence 
ggplot(data_LEU3N, aes(x = newid, y = jackknife_residuals_LEU3N)) + 
  geom_point() +
  geom_hline(yintercept = 0) +
  labs(title = "Scatterplot of Jackknife Residuals vs ID for CD4+ T Cells",
       x = "ID",
       y = "Jackknife Residuals")
```

Looks like we have 4 outlier points beyound 3 residuals from 0, but otherwise looking good.


[Top of Tabset](#Assumptions)

## Normality

Here we will asses that, for any fixed value of X, Y has a normal distribution. We will do this using Q-Q plots and histograms of the residuals.

```{r}
# Make the Q-Q plots using the jackknife residuals
qqnorm(jackknife_residuals_LEU3N, main = "Q-Q plots of Jackknife Residuals for Log Viral Load")
qqline(jackknife_residuals_LEU3N, col = "black")

# Create histogram of jackknife residuals
hist(jackknife_residuals_LEU3N, main = "Histogram of Jackknife Residuals",
     breaks = 24,
     xlab = "Jackknife Residuals",
     col = "lightblue",
     border = "black")
```

We look very normal here, sans some obvious outliers.

```{r}
shapiro.test(jackknife_residuals_LEU3N)
```

We have non-normality, but that is due to outliers.

[Top of Tabset](#Assumptions)

## Equal Variances (Homoscedasticity)

To assess homoscedasticity we examine the residual scatterplots by treatment group. The warning sign to look for here is if the variance differs greatly across groups.

```{r}
# Make the residual scatterplot using the jackknife residuals
ggplot(data_LEU3N, aes(x = hard_drugs_grp, y = jackknife_residuals_LEU3N)) +
  geom_boxplot() + 
  labs(title = "Jackknife Residuals vs Hard Drug Use for CD4+ T Cell Count Change",
       x = "Hard Drug Use Group",
       y = "JackKnife Residuals")

# Make the residual scatterplot using the jackknife residuals
ggplot(data_LEU3N, aes(x = ADH_HIGHVSLOW, y = jackknife_residuals_LEU3N)) +
  geom_boxplot() + 
  labs(title = "Jackknife Residuals vs Adherence for CD4+ T Cell Count Change",
       x = "Hard Drug Use Group",
       y = "JackKnife Residuals")
```

```{r}
# Perform Bartlett's test to check for homogeneity of variances
bartlett.test(LEU3N_CHANGE ~ hard_drugs_grp, data = data_LEU3N)
```
We can actually conclude that we have equality of variances! This will look even better once we get rid of outliers.

[Top of Tabset](#Assumptions)

## Residuals Centered Around Zero

to start, we can simply check that the mean of our residuals is close to 0.

```{r}
# Generate the mean of the jackknife residuals. Should be close to 0.
mean(jackknife_residuals_LEU3N)

# Generate vectors containing the fitted values vs jackknife residuals so we can plot them 
fitted_values_LEU3N <- fitted(model_LEU3N_final1)

ggplot(data_LEU3N, aes(x = fitted_values_LEU3N, y = jackknife_residuals_LEU3N)) + 
  geom_point() +
  geom_smooth(method = "lm")

```

The mean is close to 0. The residuals look centered around 0 excepting the outliers.

[Top of Tabset](#Assumptions)

## Summary

[Top of Tabset](#Assumptions)


:::


## Mental Quality of Life

::: panel-tabset

## Linearity

We do not need to assess linearity since our main PEVs are categorical.


[Top of Tabset](#Assumptions)

## Independence

Independence can be assessed in part by the study design and how the data was collected. Based on the information provided by the PI, I will assume subjects are independent from each other.

Additionally, we can examine a scatter plot of the model’s residuals against any time point variable (such as ID).

```{r}
# Filter to create same data set as in the final analysis
data_MENT_main <- data_wide_2 %>%
  dplyr::select(newid, AGG_MENT_CHANGE, hard_drugs_grp, ADH_HIGHVSLOW) %>%
  filter(
    !is.na(newid) & 
    !is.na(AGG_MENT_CHANGE) &
    !is.na(hard_drugs_grp) & 
    !is.na(ADH_HIGHVSLOW) 
  )

# Create a scatterplot of jackknife residuals vs ID to assess independence 
ggplot(data_MENT_main, aes(x = newid, y = jackknife_residuals_MENT_main)) + 
  geom_point() +
  geom_hline(yintercept = 0) +
  labs(title = "Scatterplot of Jackknife Residuals vs ID for Mental QOL Change",
       x = "ID",
       y = "Jackknife Residuals")
```

No clear pattern, we meet the assumption of independence.

[Top of Tabset](#Assumptions)

## Normality

Here we will asses that, for any fixed value of X, Y has a normal distribution. We will do this using Q-Q plots and histograms of the residuals.

```{r}
# Make the Q-Q plots using the jackknife residuals
qqnorm(jackknife_residuals_MENT_main, main = "Q-Q plots of Jackknife Residuals for Mental QOL Change")
qqline(jackknife_residuals_MENT_main, col = "black")

# Create histogram of jackknife residuals
hist(jackknife_residuals_MENT_main, main = "Histogram of Jackknife Residuals",
     breaks = 24,
     xlab = "Jackknife Residuals",
     col = "lightblue",
     border = "black")
```
```{r}
shapiro.test(jackknife_residuals_MENT_main)
```

We have non-normality. It does not look like outliers are driving this.

[Top of Tabset](#Assumptions)

## Equal Variances (Homoscedasticity)

To assess homoscedasticity we examine the residual scatterplots by treatment group. The warning sign to look for here is if the variance differs greatly across groups.

```{r}
# Make the residual scatterplot using the jackknife residuals
ggplot(data_MENT_main, aes(x = hard_drugs_grp, y = jackknife_residuals_MENT_main)) +
  geom_boxplot() + 
  labs(title = "Jackknife Residuals vs Hard Drug Use for Mental QOL Change",
       x = "Hard Drug Use Group",
       y = "JackKnife Residuals")
```

```{r}
# Make the residual scatterplot using the jackknife residuals
ggplot(data_MENT_main, aes(x = ADH_HIGHVSLOW, y = jackknife_residuals_MENT_main)) +
  geom_boxplot() + 
  labs(title = "Jackknife Residuals vs Adherence for Mental QOL Change",
       x = "Hard Drug Use Group",
       y = "JackKnife Residuals")
```

```{r}
# Perform Bartlett's test to check for homogeneity of variances
bartlett.test(AGG_MENT_CHANGE ~ hard_drugs_grp, data = data_MENT_main)
```

The test is significant, and we conclude we do not have homogeneity of variances.

[Top of Tabset](#Assumptions)

## Residuals Centered Around Zero

```{r}
# Generate the mean of the jackknife residuals. Should be close to 0.
mean(jackknife_residuals_MENT_main)

# Generate vectors containing the fitted values vs jackknife residuals so we can plot them 
fitted_values_MENT_main <- fitted(model_MENT_main1)

ggplot(data_MENT_main, aes(x = fitted_values_MENT_main, y = jackknife_residuals_MENT_main)) + 
  geom_point() +
  geom_smooth(method = "lm")
```

Our residuals look centered around 0, sans a few outlier points.

[Top of Tabset](#Assumptions)

## Summary

We have non-normality and non homogeneity of variances.

[Top of Tabset](#Assumptions)

:::

## Physical Quality of Life 

::: panel-tabset

## Linearity

We do not need to assess linearity since our main PEVs are categorical.

[Top of Tabset](#Assumptions)

## Independence


Independence can be assessed in part by the study design and how the data was collected. Based on the information provided by the PI, I will assume subjects are independent from each other.

Additionally, we can examine a scatter plot of the model’s residuals against any time point variable (such as ID).

```{r}
# Filter to create same data set as in the final analysis
data_PHYS <- data_wide_2 %>%
  dplyr::select(newid, AGG_PHYS_CHANGE, hard_drugs_grp, ADH_HIGHVSLOW, FRP_2) %>%
  filter(
    !is.na(newid) & 
    !is.na(AGG_PHYS_CHANGE) &
    !is.na(hard_drugs_grp) & 
    !is.na(ADH_HIGHVSLOW) &
    !is.na(FRP_2)
  )

# Create a scatterplot of jackknife residuals vs ID to assess independence 
ggplot(data_PHYS, aes(x = newid, y = jackknife_residuals_PHYS)) + 
  geom_point() +
  geom_hline(yintercept = 0) +
  labs(title = "Scatterplot of Jackknife Residuals vs ID for Physical QOL Change",
       x = "ID",
       y = "Jackknife Residuals")
```

Independence looks pretty good.

[Top of Tabset](#Assumptions)

## Normality

Here we will asses that, for any fixed value of X, Y has a normal distribution. We will do this using Q-Q plots and histograms of the residuals.

```{r}

# Make the Q-Q plots using the jackknife residuals
qqnorm(jackknife_residuals_PHYS, main = "Q-Q plots of Jackknife Residuals for Mental QOL Change")
qqline(jackknife_residuals_PHYS, col = "black")

# Create histogram of jackknife residuals
hist(jackknife_residuals_PHYS, main = "Histogram of Jackknife Residuals",
     breaks = 24,
     xlab = "Jackknife Residuals",
     col = "lightblue",
     border = "black")

shapiro.test(jackknife_residuals_PHYS)

```

Physical QOL looks mostly normal. There may be 1 outier at the upper and lower bound.

Shapiro Wilk's does say we fail normality however.

[Top of Tabset](#Assumptions)

## Equal Variances (Homoscedasticity)

To assess homoscedasticity we examine the residual scatterplots by treatment group. The warning sign to look for here is if the variance differs greatly across groups.

```{r}
# Make the residual scatterplot using the jackknife residuals
ggplot(data_PHYS, aes(x = hard_drugs_grp, y = jackknife_residuals_PHYS)) +
  geom_boxplot() + 
  labs(title = "Jackknife Residuals vs Hard Drug Use for Physical QOL Change",
       x = "Hard Drug Use Group",
       y = "JackKnife Residuals")

# Perform Bartlett's test to check for homogeneity of variances
bartlett.test(AGG_PHYS_CHANGE ~ hard_drugs_grp, data = data_PHYS)
```

We do have homogeneity of variances for physical QOL.

[Top of Tabset](#Assumptions)

## Residuals Centered Around Zero

```{r}
# Generate the mean of the jackknife residuals. Should be close to 0.
mean(jackknife_residuals_PHYS)

# Generate vectors containing the fitted values vs jackknife residuals so we can plot them 
fitted_values_PHYS <- fitted(model_PHYS_final1)

ggplot(data_PHYS, aes(x = fitted_values_PHYS, y = jackknife_residuals_PHYS)) + 
  geom_point() +
  geom_smooth(method = "lm")
```


[Top of Tabset](#Assumptions)

## Summary

The assumptions for CD4+ T cell count are almost met. Likely once removing those 4 or so outliers they would be perfect.

[Top of Tabset](#Assumptions)

To assess homoscedasticity we examine the residual scatterplots by treatment group. The warning sign to look for here is if the variance differs greatly across groups.

```{r}
# Make the residual scatterplot using the jackknife residuals
ggplot(data_PHYS, aes(x = hard_drugs_grp, y = jackknife_residuals_PHYS)) +
  geom_boxplot() + 
  labs(title = "Jackknife Residuals vs Hard Drug Use for Physical QOL Change",
       x = "Hard Drug Use Group",
       y = "JackKnife Residuals")
```

```{r}
# Make the residual scatterplot using the jackknife residuals
ggplot(data_PHYS, aes(x = ADH_HIGHVSLOW, y = jackknife_residuals_PHYS)) +
  geom_boxplot() + 
  labs(title = "Jackknife Residuals vs Adherence for Physical QOL Change",
       x = "Hard Drug Use Group",
       y = "JackKnife Residuals")
```

```{r}
# Perform Bartlett's test to check for homogeneity of variances
bartlett.test(AGG_PHYS_CHANGE ~ hard_drugs_grp, data = data_PHYS)
```

We do have homogeneity of variances.

## Residuals Centered Around Zero

```{r}
# Generate the mean of the jackknife residuals. Should be close to 0.
mean(jackknife_residuals_PHYS)

# Generate vectors containing the fitted values vs jackknife residuals so we can plot them 
fitted_values_PHYS <- fitted(model_PHYS_final1)

ggplot(data_PHYS, aes(x = fitted_values_PHYS, y = jackknife_residuals_PHYS)) + 
  geom_point() +
  geom_smooth(method = "lm")
```

The residuals appear centered around zero, for the most part.

## Summary

We do not meet the assumption of normality for physical QOL.

:::

# Outliers

Here we will investigate outliers using the jackknife residuals to assess leverage and influence.

Let’s generate a table so we can handily compare: ID, jackknife residual, leverage (diagonal hat), DFFITS, and DFBETAs for each participant.

::: panel-tabset

## Log Viral Load

```{r}
# Get leverage values (hat values)
hat_values_VLOAD <- hatvalues(model_VLOAD_full1)

# Get Cook's D values
cooks_d_VLOAD <- cooks.distance(model_VLOAD_full1)

# Get the DFFITS values
dffits_VLOAD <- dffits(model_VLOAD_full1)

# Get the DFBETAS
dfbetas_VLOAD <- dfbetas(model_VLOAD_full1)

# Make a table with ID and all diagnostic values
diagnostics_VLOAD <- data.frame(id = data_VLOAD$newid, jackknife_residuals = jackknife_residuals_VLOAD, leverage = hat_values_VLOAD, cooks_D = cooks_d_VLOAD, dffits = dffits_VLOAD, dfbetas = dfbetas_VLOAD)

pretty_print(head(diagnostics_VLOAD))
```

Plot to assess influence and leverage.

```{r}
# Influence plot
influencePlot(model_VLOAD_full1, main = "Influence Plot",
              sub = "Circle size is proportional to Cook's Distance")


# infIndexPlot gives us a series of plots that we need to investigate influence points
infIndexPlot(model_VLOAD_full1)
```

We have two immediately obvious values for participants 319 and 356. Let's examine them.

```{r}
diagnostics_VLOAD %>%
  arrange(-cooks_D) %>%
  head()
```

The values for 319 and 356 are actually all comparable to 11 and 15, I think they are just so far off to the side like that because otherwise you wouldn't be able to see anything in all those overlapping circles.

Let's remove them and replot, and I bet 11 and 15 will flag as outliers.

```{r}
# Remove outlier patients
data_VLOAD_outliers <- data_VLOAD %>%
  filter(!newid %in% c(11, 15, 319, 356))

# Re-run the model
# Perform the regression on log viral load change with the full model
model_VLOAD_full1 <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_VLOAD_outliers)

# Influence plot
influencePlot(model_VLOAD_full1, main = "Influence Plot",
              sub = "Circle size is proportional to Cook's Distance")


# infIndexPlot gives us a series of plots that we need to investigate influence points
infIndexPlot(model_VLOAD_full1)
```


Yup, 11 and 15 are now flagging as outliers, which makes sense because they had basically exactly the same values of who we just deleted.

That looks as good as it gets without removing too many observations.
```{r}
summary(model_VLOAD_full1)

# Remove outlier patients
diagnostics_VLOAD <- diagnostics_VLOAD %>%
  filter(!id %in% c(11, 15, 319, 356))

diagnostics_VLOAD %>%
  arrange(-cooks_D) %>%
  head()
```

At this point it appears that we have removed too many data points to be able to run our main interaction of interest.

This will have to be noted as a limitation in this analysis!

## CD4 + T Cell Count

```{r}
# Influence plot
influencePlot(model_LEU3N_final1, main = "Influence Plot",
              sub = "Circle size is proportional to Cook's Distance")


# infIndexPlot gives us a series of plots that we need to investigate influence points
infIndexPlot(model_LEU3N_final1)
```

Remove 63, 255, and 88, and 301 (residuals > +- 3)

```{r}
# Remove outlier patients
data_LEU3N_outliers <- data_LEU3N %>%
  filter(!newid %in% c(63, 255, 301, 88))

# Re-run the model
# Perform the regression on log viral load change with the full model
model_LEU3N_final1 <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW + FRP_2, data = data_LEU3N_outliers)

# Influence plot
influencePlot(model_LEU3N_final1, main = "Influence Plot",
              sub = "Circle size is proportional to Cook's Distance")

# infIndexPlot gives us a series of plots that we need to investigate influence points
infIndexPlot(model_LEU3N_final1)

summary(model_LEU3N_final1)
```

```{r}
# Calculate the jackknife residuals of the model predicting LEU3N
jackknife_residuals_LEU3N <- rstudent(model_LEU3N_final1)

# Make the Q-Q plots using the jackknife residuals
qqnorm(jackknife_residuals_LEU3N, main = "Q-Q plots of Jackknife Residuals for Log Viral Load")
qqline(jackknife_residuals_LEU3N, col = "black")
```

The final model for `LEU3N_CHANGE` now meets all assumptions! And it doesn't look like any of our p-values changed.

## Mental QOL Change

```{r}
# Influence plot
influencePlot(model_MENT_main1, main = "Influence Plot",
              sub = "Circle size is proportional to Cook's Distance")


# infIndexPlot gives us a series of plots that we need to investigate influence points
infIndexPlot(model_MENT_main1)
```

11 and 15 are flagging as outliers again. Let's remove them.

```{r}
# Remove outlier patients
data_MENT_outliers <- data_MENT_main %>%
  filter(!newid %in% c(11, 15, 319, 356))

data_MENT_outliers %>% arrange(AGG_MENT_CHANGE)

# Re-run the model
# Perform the regression on log viral load change with the full model
model_MENT_main1 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW, data = data_MENT_outliers)

# Influence plot
influencePlot(model_MENT_main1, main = "Influence Plot",
              sub = "Circle size is proportional to Cook's Distance")

# infIndexPlot gives us a series of plots that we need to investigate influence points
infIndexPlot(model_MENT_main1)

summary(model_MENT_main1)
```

```{r}
# Make the Q-Q plots using the jackknife residuals
qqnorm(jackknife_residuals_MENT_main, main = "Q-Q plots of Jackknife Residuals for Mental QOL Change")
qqline(jackknife_residuals_MENT_main, col = "black")

# Create histogram of jackknife residuals
hist(jackknife_residuals_MENT_main, main = "Histogram of Jackknife Residuals",
     breaks = 24,
     xlab = "Jackknife Residuals",
     col = "lightblue",
     border = "black")
```

This doesn't appear to do much for our assumptions for this model however.

It doesn't appear that outliers are driving this shape.

## Physical Quality of Life

```{r}
# Influence plot
influencePlot(model_PHYS_final1, main = "Influence Plot",
              sub = "Circle size is proportional to Cook's Distance")

# infIndexPlot gives us a series of plots that we need to investigate influence points
infIndexPlot(model_PHYS_final1)
```

Same high leverage points we saw with mental QOL.

```{r}
# Remove outlier patients
data_PHYS_outliers <- data_PHYS %>%
  filter(!newid %in% c(11, 15, 319, 356))

# Perform the regression on log viral load change with the full model
model_PHYS_final1 <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW + FRP_2, data = data_PHYS_outliers)

# Influence plot
influencePlot(model_PHYS_final1, main = "Influence Plot",
              sub = "Circle size is proportional to Cook's Distance")

# infIndexPlot gives us a series of plots that we need to investigate influence points
infIndexPlot(model_PHYS_final1)
```

```{r}
# Get leverage values (hat values)
hat_values_PHYS <- hatvalues(model_PHYS_final1)

# Make a table with ID and all diagnostic values
diagnostics_PHYS <- data.frame(id = data_PHYS_outliers$newid, leverage = hat_values_PHYS)

diagnostics_PHYS %>% arrange(-leverage)
```

```{r}
# Perform the regression on log viral load change with the full model
model_PHYS_final1 <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + hard_drugs_grp*ADH_HIGHVSLOW + FRP_2, data = data_PHYS_outliers)

# Influence plot
influencePlot(model_PHYS_final1, main = "Influence Plot",
              sub = "Circle size is proportional to Cook's Distance")

# infIndexPlot gives us a series of plots that we need to investigate influence points
infIndexPlot(model_PHYS_final1)
```

```{r}
# Make the Q-Q plots using the jackknife residuals
qqnorm(jackknife_residuals_PHYS, main = "Q-Q plots of Jackknife Residuals for Physical QOL Change")
qqline(jackknife_residuals_PHYS, col = "black")

# Create histogram of jackknife residuals
hist(jackknife_residuals_PHYS, main = "Histogram of Jackknife Residuals",
     breaks = 24,
     xlab = "Jackknife Residuals",
     col = "lightblue",
     border = "black")
```

The data looks slightly more normally distributed

:::

#  Results

Note: Co-written with project partner Dominick Demarsico (30% Dominick 70% Sean)

The total population of the study was 550 participants. Of that total, all were male, HIV+, and taking HAART treatment after baseline. Never drug use had 444 subjects, past drug use had 46 subjects, and current drug use had 60 subjects. While there are large population size discrepancies, all of the groups were sufficiently large (>30) (See Table 1). Primary outcome data was missing in 18 patients for Viral Load, 18 for Leukocyte count, 7 for Mental Wellbeing, and 7 for Physical wellbeing.  Income, Triglycerides, LDL, and BMI were all dropped from analysis due to missingness being greater than 20%. We then decided to move forward with a complete case analysis. Figure 1 reveals that there were moderate correlations (r = ~30% - 60%) between at least one of our primary outcome variables and education, frailty phenotype, age, smoking status, depression, and adherence. 

Backward elimination using BIC determined the final covariates to be included for viral load were education, hard drug use, adherence, and the interaction between drug use and adherence. There were significant differences in change in log viral load based on hard drug usage and adherence to the treatment regimen, while controlling for education at baseline (F(6, 513)= 9.51), p < 0.0001). Low Adherence led to 3.48 increased log viral load in Current users (p = .04) and 5.81 increased log viral load in past users (p <.001). However, there were no significant differences in viral load for drug users with High Adherence (See Figure 2)

Backwards elimination using BIC determined the covariates to be included for CD4+ T Cell count were frailty phenotype along with adherence, drug use category, and their interaction. There were significant differences in change in CD4+ T Cell count over 2 years based on hard drug usage and adherence to the treatment regimen, while controlling for Frailty Related Phenotype (F(6,512) = 8.42, p < 0.00001). Low Adherence led to a 197.90 cell increase in CD4 in previous users compared to never users (p = .04). Never users and current users did not differ significantly from each other. Current users had a 342.0 cell decrease compared to past users (p = 01). High Adherence led to a 99.23 cell decrease in past users (p = .003) and a 111.16 cell decrease in current users (p <.001) when compared to never users (See Figure 3)

For Mental Wellbeing, backward elimination using BIC determined that the final covariates to include were drug use, adherence, and their interaction. There were significant differences in mental QOL over 2 years based on hard drug usage and adherence to the treatment regimen (F(5,526) = 4.78, p = 0.000278). Low Adherence led to a 15.95 point decrease in mental QoL in previous drug users compared to never drug users (p =.009), and a 23.91 decrease compared to never hard drug users (p = 0.007). There was no difference in mental QOL between current and never hard drug users at low adherence (p = 0.64). At high adherence, there was no difference in mental QOL between previous and never hard drug users (p = 0.48), or between current and never hard drug users (p = 0.20). The difference in mental QOL for current and previous users was borderline significant (p =  0.050) (See Figure 3). While depression was highly correlated to mental QOL, it was determined to be a confounder and a separate analysis run, showing heightened risk of depression for previous users (See Figure 3a).

For Physical wellbeing, backward elimination using BIC selected the final model to include frailty related phenotype along with drug use, adherence, and their interaction. There were significant differences in change in physical QOL over 2 years based on hard drug usage and adherence to the treatment regimen, while controlling for Frailty Related Phenotype (F(6, 525) = 20.67, p < 0.0001). Low Adherence led to a 10.89 point decrease in physical QoL in past drug users compared to never drug users (p =.004). Current users did not differ significantly from never users. High Adherence led to current users having a 3.94 point decrease in physical QoL compared to never users (p = .001), and a 5.35 point decrease when compared to past users (p = .002). There was no difference between previous and never users (p = 0.8). See Figure 5.

Assumptions for a regression were assessed using Q-Q plots, histograms of the residuals, scale-location plots, and scatterplots of the residuals against the fitted-values. All assumptions were met for Leukocyte levels. However, Viral Load, Mental QoL, and Physical QoL have slight violations of normality and homogeneity of variances.

# Discussion

Note: Co-written with project partner Dominick DeMarsico (50% Dominick 50% Sean)

With regard to our research question, adherence played a major role in affecting the reliability of the models. We have evidence to suggest that the relationship between treatment outcomes and drug use is modified by the interaction of adherence and drug use. Therefore, we have evidence to reject the null hypothesis. From our perspective, adherence would act as a confounder if it were not already accounted for in our model. Specifically,  low adherence leads to worsened outcomes in current users for viral load, and in previous users for all outcome variables including mental and physical well being. Thus, previous hard drug users are a vulnerable population and appear to be struggling with quitting, and more aggressive treatment strategies should be considered to support them.

Additionally, only 7.8% of subjects fell into the category of low adherence, with only 4 previous and 6 current drug users. The lack of subjects in this category severely hampers our ability to use an interaction term at all for certain groups. A larger N in this category would allow for more information on the true interaction within these groups. 

Another consideration should be physical and mental changes that occur during pathology but can not be explained by treatment. Access to a list of Adverse Events suffered by the subjects would be very helpful to better understand what is causing changes. Additionally, the slight deviation from normality with some of our outcome variables can be attributed to using change scores rather than each individual time point as a unique observation. This method effectively cut our N by two-thirds. We expect that longitudinal analyses allowing for an N closer to the original value of 1600 would alleviate these symptoms for normality.

# Bonus

## Plotting Outcome Variables Across Full 8 Years

The below plots were used as justification and evidence for separating adherence from four levels to two levels, as this seemed to be whether the most meaninfgul and true split was.

### Mental QOL

```{r}

# Get rid of that value of 1 for adherence at baseline for patient 426
data$ADH[data$years == 0] <- NA

# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_QOL = mean(AGG_MENT, na.rm = TRUE))

# Create plot
p <- ggplot(summary_data, aes(x = years, y = Average_QOL, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Mental QOL Score by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average Mental QOL Score",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups

ggplotly(p)
```

Success! This is very interesting. It appears that the 100% adherence group has the highest average mental QOL score across the 8 year study, followed by the 95-99% group, followed by the \<75% group and followed by (with some variation) the \<75% and 75-94% groups.

### Physical QOL

Let's do the same thing but for `AGG_PHYS`.

```{r}
# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_QOL = mean(AGG_PHYS, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_QOL, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Physical QOL Score by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average Physical QOL Score",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

We see a similiar relationship here, though there's more variation. For some reason that \<75% group likes to spike in their QOL at year 7. Interesting.

### Log Viral Load

```{r}
# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_LEU3N = mean(LEU3N, na.rm = TRUE))

# Create plot
p <- ggplot(summary_data, aes(x = years, y = Average_LEU3N, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average LEU3N  by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average LEU3N",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups

ggplotly(p)

```

### CD4+ T Cell Count

```{r}
# Create log vload variable for original 8 year data set.
data$VLOAD_log <- log(data$VLOAD)

# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_VLOAD_log = mean(VLOAD_log, na.rm = TRUE))

# Create plot
p <- ggplot(summary_data, aes(x = years, y = Average_VLOAD_log, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average VLOAD log by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average VLOAD log",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups

ggplotly(p)
```

That's very interesting. The groups with the highest vload log had the least adherence. There is an inverse relationship here.

This is strong evidence that the treatment is efficacious and the `ADH` should be considered as a confounder.

Ohhhhh, that's super cool. So there is an inverse relationship between `LEU3N` and `VLOAD_log`, such that spikes in one should be dips in the other. We can see that in this data set! It appears that for the adherence group of \<75%, they had viral load spikes at years 5 and 7, which correspond with leukocyte dips at years 5 and 7! They weren't adhering to the protocol, which resulted in them getting infected (?) more and having more of the virus present compared to the other groups.

### Comparing High Vs Low Adherence Groups

```{r}
data$ADH_HIGHLOW <- ifelse(data$ADH == "<75%" | data$ADH == "75-94%", 0, 1)

data$ADH_HIGHLOW <- factor(data$ADH_HIGHLOW,
                           levels = c(0,1),
                           labels = c("Low Adherence", "High Adherence"))

#### tRY WITH HIGH LOW ADH
# Create log vload variable for original 8 year data set.
data$VLOAD_log <- log(data$VLOAD)

# Get means for each year
summary_data <- data %>%
  group_by(ADH_HIGHLOW, years) %>%
  summarize(Average_VLOAD_log = mean(VLOAD_log, na.rm = TRUE))

# Create plot
p <- ggplot(summary_data, aes(x = years, y = Average_VLOAD_log, color = ADH_HIGHLOW)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average VLOAD log by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average VLOAD log",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups

ggplotly(p)
```

High adherence patients have lower viral load then low adherence

Same for leu3n

```{r}
#### tRY WITH HIGH LOW ADH

# Get means for each year
summary_data <- data %>%
  group_by(ADH_HIGHLOW, years) %>%
  summarize(Average_LEU3N = mean(LEU3N, na.rm = TRUE))

# Create plot
p <- ggplot(summary_data, aes(x = years, y = Average_LEU3N, color = ADH_HIGHLOW)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average LEU3N by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average LEU3N",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups

ggplotly(p)
```

High adherence users have higher CD4+ T Cells, for the most part.

### Other literature

https://pmc.ncbi.nlm.nih.gov/articles/PMC9234842/

This one shows that poor adherence is related to anxiety and depression, leading credence to why I want to examine the impact of hard drugs and adherence while controlling for depression.

