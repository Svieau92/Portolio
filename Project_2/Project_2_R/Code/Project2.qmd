---
title: "Advanced Data Analysis - Project 2"
author: "Sean Vieau"
date: "October 9, 2024"
editor: visual
output: html_document
toc: true
---

```{r setup, include=FALSE}
# Sets the default for all chunks as echo = TRUE (ensures they show unless specified not to)
knitr::opts_chunk$set(echo = TRUE)

# Create a function to pretty print our dataframes
pretty_print <- function(x) {
  kable(x, format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
}

# Set options to avoid scientific notation
options(scipen = 999)
```

# Introduction

The aim of the current study is to assess how treatment response differs for HIV+ patients 2 years after initiating Highly Active Antiretroviral Therapy (HAART) based on hard drug usage (such as heroin or cocaine). This study is of particular scientific interest because it is unclear whether the use of hard drugs inhibits the immune system in humans; treatment strategies may differ based on these results. The researchers are interested in comparing subjects who never used hard drugs to current hard drug users (those that use hard drugs at year 2) or previous hard drug users (those who used drugs at year 0 or 1). Outcomes of interest are: viral load (HIV copies in a mL of blood), CD4+ T cell count (a measure of immunologic health), and aggregate physical and quality of life scores from the SF-36.

The clinical hypothesis is that, if hard drugs inhibit the immune system in humans, subjects who currently or previously used hard drugs will have higher viral load and lower CD4+ T cell counts than those who never used hard drugs. Additionally, the researchers are interested in knowing if potential differences between the drug use groups can be explained by differences in adherence to the treatment regimen. The researchers are agnostic on how quality of life changes after treatment, since side effects of the treatment are significant.

The project description provided by the PI is available below:

::: {style="text-align: center;"}
<img src="/Project_2/Project_2_R/Media/Project2_description1.png" width="85%"/>
:::

# Method

**Study Design**

This is a secondary data analysis of the Multicenter AIDS Cohort Study, an ongoing prospective cohort study investigating the natural and treated disease progression of HIV-1 in bisexual men in 4 major cities in the U.S. Measurements for all variables were taken once per year over an 8-year time period; however, the current analysis is only concerned with treatment outcomes after 2 years of HAART. Data was received as a longform .csv file containing 33 columns along with a data dictionary. The main outcomes of interest are viral load, CD4+ T cell count, and aggregate physical and quality of life scores. Adherence to treatment regiment will be investigated as a potential confounder.

Potential covariates of interest include: marijuana usage since last visit and frequency of usage, income, BMI, high blood pressure, diabetes, liver disease stage 3 / 4, kidney disease, frailty related phenotype, total cholesterol, triglycerides, fasting LDL, dyslipidemia, depression score, smoking status, alcohol use since last visit, heroin or opiate use since last visit, intravenous drug use since last visit, race, education at baseline, age, if they took ART at the visit or if they have ever taken it before, and years since initiating ART.

# Data Preparation

First we load the necessary packages

```{r, message = FALSE}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(plotly) # Used for interactive plots
library(naniar) # Used to visualize missing data
library(kableExtra) # Used for pretty printing (kable_styling)
library(table1) # Used to make Table 1
library(tidyr) # Used for reshaping
library(bestNormalize) # Used in selecting best transformation for a variable
library(corrplot) # Used to make the correlation matrix
library(corrtable) # used to make the table for the correlation matrix
```

Then we import the data set.

```{r, message = FALSE}
# Read in data
data <- read_csv("C:/Users/sviea/Documents/Portfolio/Project_2/Project_2_R/RawData/hiv_dataset.csv")
```

And take a look.

```{r}
# Examine data
glimpse(data)
```

Everything appears properly imported, however all our categorical variables are coded as doubles.

## Labeling Categorical Variables

Let's factor and label our categorical variables so they are appropriately represented (and not doubles, which will yield incorrect results in models)

```{r, results='hide'}
# Converting all appropriate variables from doubles to categorical variables

data$HASHV <- factor(data$HASHV,
                     levels = c(1, 2),
                     labels = c("No", "Yes"))

data$HASHF <- factor(data$HASHF,
                     levels = c(0, 1, 2, 3, 4),
                     labels = c("Never", "Daily", "Weekly", "Monthly", "Less Often"))

data$income <- factor(data$income,
                      levels = c(1, 2, 3, 4, 5, 6, 7, 9),
                      labels = c("Less than $10,000", "$10,000-$19,999", "$20,000-$29,999", "$30,000-$39,999", "$40,000-$49,999", "$50,000-$59,999", "$60,000 or more", "Do not wish to answer"))

data$HBP <- factor(data$HBP,
                   levels = c(1, 2, 3, 4, 9, -1),
                   labels = c("No", "Yes", "No, based on data trajectory", "Yes, based on data trajectory", "Insufficient data, may include reported treatment without diagnosis", "Improbable Value"))

data$DIAB <- factor(data$DIAB,
                    levels = c(1, 2, 3, 4, 9),
                    labels = c("No", "Yes", "No, based on data trajectory", "Yes, based on data trajectory", "Insufficient data"))
                      
data$LIV34 <- factor(data$LIV34,
                     levels = c(1, 2, 9),
                     labels = c("No", "Yes", "Insufficient Data"))

data$KID <- factor(data$KID,
                   levels = c(1, 2, 3, 4, 9),
                   labels = c("No", "Yes", "No, based on data trajectory", "Yes, based on data trajectory", "Insufficient data"))

data$FRP <- factor(data$FRP,
                   levels = c(1,2,9),
                   labels = c("No", "Yes", "Insufficient Data"))

data$FP <- factor(data$FP,
                  levels = c(1,2,9),
                  labels = c("No", "Yes", "Insufficient Data"))

data$DYSLIP <- factor(data$DYSLIP,
                      levels = c(1, 2, 3, 4, 9),
                      labels = c("No", "Yes", "No, based on data trajectory", "Yes, based on data trajectory", "Insufficient data"))

data$SMOKE <- factor(data$SMOKE,
                     levels = c(1, 2, 3),
                     labels = c("Never Smoked", "Former Smoker", "Current Smoker"))

data$DKGRP <- factor(data$DKGRP,
                     levels = c(0, 1, 2, 3),
                     labels = c("None", "1-3 drinks/week", "4-13 drinks/week", ">13 drinks/week"))

data$HEROPIATE <- factor(data$HEROPIATE,
                         levels = c(1, 2, -9),
                         labels = c("No", "Yes", "Not Specified"))

data$IDU <- factor(data$IDU,
                   levels = c(1, 2),
                   labels = c("No", "Yes"))

data$ADH <- factor(data$ADH,
                   levels = c(1, 2, 3, 4),
                   labels = c("100%", "95-99%", "75-94%", "<75%"))

data$RACE <- factor(data$RACE,
                    levels = c(1, 2, 3, 4, 5, 6, 7),
                    labels = c("White, non-Hispanic", "White, Hispanic", "Black, non-Hispanic ", "Black, Hispanic",  "American Indian or Alaskan Native", "Asian or Pacific Islander", "Other Hispanic"))

data$EDUCBAS <- factor(data$EDUCBAS,
                       levels = c(1, 2, 3, 4, 5, 6, 7),
                       labels = c("8th grade or less ", "9,10, or 11th grade", "12th grade", "At least one year college but no degree", "Four years college or got degree", "Some graduate work", "Post-graduate degree"))

data$hard_drugs <- factor(data$hard_drugs,
                          levels = c(0, 1),
                          labels = c("No", "Yes"))

# Create labels for variables to make the names of each variable more professional in outputs
label(data$newid) <- "ID"
label(data$AGG_MENT) <- "Aggregate Mental QOL Score"
label(data$AGG_PHYS) <- "Aggregate Physical QOL Score"
label(data$HASHF) <- "Hash/Marijuana Use Since Last Visit"
label(data$HASHV) <- "Frequency of Hash/Marijuana Use"
label(data$income) <- "Income"
label(data$HBP) <- "High Blood Pressure"
label(data$DIAB) <- "Diabetes"
label(data$LIV34) <- "Liver Disease Stage 3/4"
label(data$KID) <-"Kidney Disease"
label(data$FRP) <- "Frailty Related Phenotype"
label(data$FP) <- "Fraily Phenotype"
label(data$BMI) <- "BMI"
label(data$TCHOL) <- "Total Cholesterol"
label(data$TRIG) <- "Triglycerides"
label(data$LDL) <- "LDL"
label(data$DYSLIP) < "Dyslipidemia"
label(data$SMOKE) < "Smoking Status"
label(data$CESD) <- "CESD Depression Score"
label(data$SMOKE) < "Smoking Status"
label(data$DKGRP) <- "Drinking Group"
label(data$HEROPIATE) <- "Heroin or Opiate Use Since Last Visit"
label(data$IDU) <- "Intravenous Drug Usage Since Last Visit"
label(data$LEU3N) <- "CD4+ T Cell Count"
label(data$VLOAD) <- "Viral Load"
label(data$ADH) <- "Adherence to Treatment Regimen"
label(data$RACE) <- "Race"
label(data$EDUCBAS) <- "Education at Baseline"
label(data$hivpos) <- "HIV Serostatus"
label(data$age) <- "Age"
label(data$ART) <- "Antiretroviral Therapy"
label(data$years) <- "Year of Visit"
label(data$hard_drugs) <- "Hard Drug Usage"
```

Let's take another look to check that those variables are no longer doubles.

```{r}
# Examine data
glimpse(data)
```

Looks good.

## Filtering Data Set

Now let's take a look at the header to get a good feeling for our data.

```{r}
# Pretty print data header
pretty_print(head(data))
```

Hmm, we have 8 years worth of data points, but the experimenters are only interested in the first 2 years.

Out of curiosity, let's look at how many participants they had each year.

```{r}
# Visualize patient drop off over 8 years of study
barplot(table(data$years))

# Check number of patients in each year
pretty_print(table(data$years))
```

This is interesting, we don't seem to have as drastic a drop off as I expected. The researchers managed to retain all participants for the first 2 years, and 50% by the end of the 8-year study.

Let's filter to only include values from the first 2 years, as this is the timeframe the researchers are interested in.

```{r}
# Filter long form data set to be include only first 2 years
data_2 <- data[data$years <= 2,]

# Check how many visits we have in the filtered data set.
dim(data_2)
```

We went from 3632 visits in the 8 year data set to 1650 in the 2 year filtered data set.

```{r}
# Double check if any patients dropped out within the first 2 years
any(is.na(data_2$years))
```

Luckily, no patients dropped out within the first 2 years of the study!

## Transpose to Wideform

We can also see that the provided data set is in longform. Let's convert that to wideform.

```{r}
# Create new wideform data set for first 2 years of study              
data_wide_2 <- pivot_wider(data_2, id_cols = newid, names_from = years, values_from = -c(newid, years))
```

And take a look at the header to check that was done correctly.

```{r}
# Pretty print header of wideform data
pretty_print(head(data_wide_2))
```

Good. now we have a long and wide form of the data set for the first two years of the study.

Finally, let's just clean that wide data set up a bit to drop repeat measures of variables that are constant over time (race, education at baseline, HIV serostatus, everART)

```{r}
# Clean up the wide data set a bit by deleting multiple observations across time for constant variables such as race
data_wide_2 <- data_wide_2 %>% select(-RACE_1, -RACE_2, -EDUCBAS_1, -EDUCBAS_2, -hivpos_1, - hivpos_2, -everART_1, -everART_2)
```

Now that our data sets are adequately prepared, we can move on to performing our data checks to ensure fidelity of the data set.

# Missingness

First we begin by examining missingness in our data set

```{r}
# Check missingness for long form data
gg_miss_var(data_2)
```

This shows that we are missing the most values for `LDL`, `TRIG`, `ADH`, `TCHOL`, and `income`.

A closer examination reveals...

```{r}
# Visualize missing values for longform data
vis_miss(data_2)
```

53% of `LDL`, 53% of `TRIG`, 33% of `ADH`, 32% of `TCHOL`, and 24% of `income` values are missing.

`LDL` and`TRIG` have egregious amounts of missing data (\> 50%). `TCHOL` and `income` are in a range where we may be able to save them with MI or a linear mixed model that allows for missing data. We will have to see.

`ADH` is missing 33% of values. That could be problematic as that's a key variable the researchers are interested in.

But there's an odd, systematic pattern there... what if we look at the wide form of the data?

```{r}
# Visualize missing values for wideform data
vis_miss(data_wide_2)
```

Ah, 1/3 of the values for `ADH` are missing because there are 3 time points and you can't have baseline adherence to a protocol you just started (i.e. `ADH_0`).

There's a small blip there that looks like someone DOES have a value for `ADH_0`, I wonder what that's about...

```{r}
# For some reason participant 426 has an adherence of 1 at baseline
adh_at_baseline <- data_wide_2 %>%
  filter(ADH_0 == "100%") %>% 
  select(newid, ADH_0)

# Pretty print
pretty_print(adh_at_baseline)

```

Apparently if you're participant 426, you can have 100% adherence to a protocol you've just started (clearly a typo).

Conclusion is we can still use `ADH` as a variable! We just have to use adherence at years 1 or 2.

# Data Cleaning

We just examined missingness as a preliminary check. However there is more work to be done.

The dataset we received has variables that were coded inconsistently. For instance, some variables are coded so that missing values are represented by a blank, and some variables (like `CESD`) are coded so that missing values are represented by -1. In other cases, such as with `BMI`, improbable values are coded as 999.

We can see this if we examine the mins and maxes for each numerical variable.

```{r}
# Code from ChatGPT
# This function summarizes the mins and maxes of numeric variables
summarize_column <- function(column) {
  if (is.numeric(column)) {
    return(data.frame(
      Type = "Numeric",
      Min = min(column, na.rm = TRUE),
      Max = max(column, na.rm = TRUE)
    ))
  }
}

# Apply the function to each column and bind the results into a single data frame
summary_df <- map_dfr(data_2, summarize_column, .id = "Column") %>%
  mutate(across(everything(), ~ format(., scientific = FALSE))) # Eliminates scientific notation

# Pretty print the mins and maxes of longform data_2
pretty_print(summary_df)
```

In effect, our data is not correctly showing all missing values. Let's clean all that up, variable by variable.

### Cleaning Dependent Variables {#Clean_DVs}

First we will begin by examining and cleaning our 4 primary outcomes of interest.

The first two are laboratory measures.

-   [Viral load (VLOAD):]{.underline} The number of HIV copies in a mL of blood
-   [CD4+ T cell count (LEU3N):]{.underline} A measure of immunologic health.

In untreated HIV infection, viral load increases over time and CD4+ T cell counts decline as the immune system is attacked by the virus. Once treatment is initiated, we expect viral load to decrease rapidly and CD4 counts to recover.

Our last two measures are quality of life measures from the [SF-36](https://www.rand.org/health-care/surveys_tools/mos/36-item-short-form.html).

-   [Aggregate physical quality of life score (AGG_PHYS)]{.underline}

-   [Aggregate mental quality of life score (AGG_MENT)]{.underline}

These scores range from 0 to 100, with higher scores indicating better quality of life. The researchers are not sure what happens to quality of life after initiating treatment. While in theory subjects’ improving health should result in increased quality of life, the side effects of these treatments are significant. If subjects experience declines in quality of life after initiating treatment, we would be concerned that they would stop treatment.

:::::: panel-tabset
## Viral Load

Standardized viral load

-   0 = 0 copies/ml

-   999,999,999 = 999,999,999 copies/ml

-   Blank = Missing

Our min max function earlier showed the max VLOAD was 190695039.60. I wonder if this is real or a data error?

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# create histogram of viral load
hist(data_2$VLOAD)

# Create qqplots of viral load
qqnorm(data_2$VLOAD)
qqline(data_2$VLOAD)
```

Yeah, looks like there are about 3 data points throwing off our qqplot from being normal.

Let's investigate.

```{r}
# Sort data set by descending viral load
sorted_data <- data_2[order(-data_2$VLOAD),] %>%
  select(newid, VLOAD, years)

# Pretty print resulting table
pretty_print(head(sorted_data))
```

So the highest VLOAD value is 75x the 5th highest, and the 4th highest is 2x 5th highest. All these values are from different patients at the baseline.

Based on the data dictionary provided, these values fall below the specified range of 999,999,999 copies/ml. That the PI's specified this range could mean these are real data points. Maybe immediately after when someone is first exposed to HIV the viral load is incredibly high, and these 4 or so patients fell in that time period?

I will first check if removing them makes our data normally distributed.

We will then add them back into the data set and keep them in mind. Checking with the jackknife residuals after we run our model will tell us if they are high leverage points.

```{r}
# Create boxplot to assess for outliers
outlier_vload <- boxplot(data_2$VLOAD, main = "Boxplot for VLOAD")$out
text(x = rep(1.2, length(outlier_vload)),
     y = outlier_vload, labels = outlier_vload, col = 'red', cex = 0.8)
```

Indeed the boxplot shows these values really mess with our data.

These top 4 patients based on VLOAD are 224, 78, 437, and 196. Patient 196 has double the VLOAD of the next highest person, which means this could be an outlier or real data, but let's remove them just to see.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Remove 4 highest viral load visits
data_vload_removed <- data
data_vload_removed$VLOAD[data_vload_removed$newid %in% c(224, 78, 437, 196)] <- NA

# Create plots to assess for normality
hist(data_vload_removed$VLOAD)
qqnorm(data_vload_removed$VLOAD)
```

Oh, that makes more sense. Those might not have been outliers, we just need to log transform viral load. Right, viral load is often used as a real world example of a biological measurement that is logarithmic...

Let's do that log transform, and just pretend we remembered that from the start.

```{r}
# Log transform viral load in the long form data set
data_2$VLOAD_log <- log(data_2$VLOAD)

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create a histogram of log transformed viral load
hist(data_2$VLOAD_log)

# Create qqplot of log transformed viral load
qqnorm(data_2$VLOAD_log)
qqline(data_2$VLOAD_log)

# Create boxplot of log transformed viral load to assess for potential outliers
outlier_vload <- boxplot(data_2$VLOAD_log, main = "Boxplot for VLOAD")
```

That looks much better!

I'd say that's roughly normally distributed, maybe a bit right tailed but likely still acceptable.

Looks like this took care of those values that were showing up as outliers before, and we have no outliers for this variable.

`VLOAD` has now been cleaned!

[Top of Tabset](#Clean_DVs)

## CD4+ T Cell Count

A measure of immunologic health.

Number of CD4 positive cells (helpers)

-   0 - 9999 cells
-   Blank = Missing

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of CD4 T Cells
hist(data_2$LEU3N, breaks = 24)

# Create qqplot of CD4 T Cells
qqnorm(data_2$LEU3N)
qqline(data_2$LEU3N)

# Sort data set by descending CD4 T Cell
sorted_data <- data_2[order(-data_2$LEU3N),] %>%
  select(newid, LEU3N, years)

# Pretty print resulting table
pretty_print(head(sorted_data))
```

These values all look believable and like there was no errors during data collection or entering. It is unclear whether this variable is right tailed because of outliers, or if it needs to be transformed.

Let's look at potential outliers.

```{r}
# Create boxplot of CD4 T cell count to assess for outliers
outlier_leu3n <- boxplot(data_2$LEU3N, main = "Boxplot for Leu3n")$out
text(x = rep(1.2, length(outlier_leu3n)),
     y = outlier_leu3n, labels = outlier_leu3n, col = 'red', cex = 0.8)
```

Yeah, the boxplot is showing a lot of outliers.

Let's try a log transform.

```{r}
# Log transform CD4 T Cell count
data_2$LEU3N_log <- log(data_2$LEU3N)

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of log transformed CD4 T cell count
hist(data_2$LEU3N_log)

# Create qqplot of log transformed CD4 T cell count
qqnorm(data_2$LEU3N_log)
qqline(data_2$LEU3N_log)
```

That... didn't work. Maybe let's try standardization.

```{R}
# Perform a standardization transformation of CD4 T Cell Count
data_2$LEU3N_standard <- scale(data_2$LEU3N)

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of standardized CD4 T Cell count
hist(data_2$LEU3N_standard)

# Create qqplot of standardized CD4 T Cell count.
qqnorm(data_2$LEU3N_standard)
qqline(data_2$LEU3N_standard)
```

Hmm, that didn't do the trick.

At this point I asked my professor in passing and he recommended the bestNormalize package (which he happened to write) to help in selecting the best transformation for a variable.

Let's take a shot at it.

```{r}
# Use bestNormalize R package to select the best transformation for CD4 T Cell count
BNObject <- bestNormalize(data_2$LEU3N)
BNObject
```

The bestNormalize function selects the best transformation according to the Pearson P statistic (divided by its degrees of freedom), as calculated by the nortest package. There are a variety of normality tests out there, but the benefit of the Pearson P / df is that it is a relatively interpretable goodness of fit test, and the ratio P / df can be compared between transformations as an absolute measure of the departure from normality (if the data follows close to a normal distribution, this ratio will be close to 1).

Here we can see that orderNorm (1.14), Yeo-Johnson (1.26), and Box-Cox (1.26) all perform relatively similar to each other. Let's see what those plots look like if I do those transformations.

```{r}
# Peform ordernNorm transformation of CD4 T Cell count
data_2$LEU3N_orderNorm <- orderNorm(data_2$LEU3N)$x.t

# Peform Box-Cox transformation of CD4 T Cell count
data_2$LEU3N_boxcox <- boxcox(data_2$LEU3N)$x.t

# Peform Yeo-Johnson transformation of CD4 T Cell count
data_2$LEU3N_yeojohnson <- yeojohnson(data_2$LEU3N)$x.t

# Plot all histograms using MASS
par(mfrow = c(3,1))
MASS::truehist(data_2$LEU3N_orderNorm, main = "OrderNorm transformation", nbins = 24)
MASS::truehist(data_2$LEU3N_boxcox, main = "Box Cox transformation", nbins = 24)
MASS::truehist(data_2$LEU3N_yeojohnson, main = "Yeo-Johnson transformation", nbins = 24)
```

```{r}
# This function visualizes the estimated normality statistics obtained for each fold and repeat of cross-validation via boxplots. It allows you to compare transformation methods
boxplot(log10(BNObject$oos_preds), yaxt = 'n')
axis(2, at=log10(c(.1,.5, 1, 2, 5, 10)), labels=c(.1,.5, 1, 2, 5, 10))
```

I will select Box-Cox as those two names are more familiar to me so I trust it more per the availability heuristic (and because orderNorm looks TOO good to be true).

More information on Box-Cox Transformation [here](https://www.statisticshowto.com/probability-and-statistics/normal-distributions/box-cox-transformation/)

::: callout-note
## Note: [Later in the document](#Variable_Creation) we see that the distribution of the change score for each outcome variable is normally distributed, and thus absolves us of the need to perform any transformations besides log transforming `VLOAD`.
:::

[Top of Tabset](#Clean_DVs)

## Aggregate Mental QOL Score

The values for `AGG_MENT` in our data set range from 7.229315 to 73.31224, which is believable and leads us to conclude there were no data entry errors here.

Let's examine normality.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create a histogram for aggregate mental QOL score
hist(data_2$AGG_MENT)

# Create qqplot for aggregate mental QOL score
qqnorm(data_2$AGG_MENT)
qqline(data_2$AGG_MENT)

# Sort by descending to examine highest values
sorted_data_2 <- data_2[order(data_2$AGG_MENT),] %>%
  select(newid, AGG_MENT, years)

# Pretty print resulting table
pretty_print(head(sorted_data_2))

# Create boxplot of aggregate mental QOL to assess for outliers
outlier_AGG_MENT <- boxplot(data_2$AGG_MENT, main = "Boxplot for Aggregate Mental QOL")$out
text(x = rep(1.2, length(outlier_AGG_MENT)),
     y = outlier_AGG_MENT, labels = outlier_AGG_MENT, col = 'red', cex = 0.8)
```

It appears that `AGG_MENT` only has 2 potential outliers, and is also not normally distributed, it is left-tailed. Let's address that.

```{r}
# Use bestNormalize function to test which transformation performs the best
BNobject <- bestNormalize(data_2$AGG_MENT)
BNobject
```

The orderNorm transformation beats out the other transformations by a mile. Let's perform that.

```{r}
# Perform orderNorm transformation of aggregate mental QOL score
data_2$AGG_MENT_orderNorm <- orderNorm(data_2$AGG_MENT)$x.t
MASS::truehist(data_2$AGG_MENT_orderNorm, main = "OrderNorm transformation", nbins = 24)
```

That appears to be what we have to do but I have some misgivings with orderNorm transforming everything...

::: callout-note
## Note: [Later in the document](#Variable_Creation) we see that the distribution of the change score for each outcome variable is normally distributed, and thus absolves us of the need to perform any transformations besides log transforming `VLOAD`.
:::

[Top of Tabset](#Clean_DVs)

## Aggregate Physical QOL Score

AGG_PHYS has a min of 9.12 and a max of 73.57. These are within the specified range of 0 - 100, and it appears there were no data error entries.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Creat histogram of aggregate physical QOL score
hist(data_2$AGG_PHYS)

# Create qqplots of aggregate physical QOL score
qqnorm(data_2$AGG_PHYS)
qqline(data_2$AGG_PHYS)
```

`AGG_PHYS` is not normally distributed, it is left-tailed.

Let's test which type of transformation might suit it.

```{r}
# Use bestNormalize function to test which transformation performs the best
BNobject <- bestNormalize(data_2$AGG_PHYS)
BNobject
```

Again orderNorm performs the best.

```{r}
# Perform orderNorm transformation of aggregate mental QOL score
data_2$AGG_PHYS_orderNorm <- orderNorm(data_2$AGG_PHYS)$x.t
MASS::truehist(data_2$AGG_PHYS_orderNorm, main = "OrderNorm transformation", nbins = 24)
```

OrderNorm transforming all our DVs might make interpration difficult...

::: callout-note
## Note: [Later in the document](#Variable_Creation) we see that the distribution of the change score for each outcome variable is normally distributed, and thus absolves us of the need to perform any transformations besides log transforming `VLOAD`.
:::

[Top of Tabset](#Clean_DVs)
::::::

### Cleaning Covariates {#Clean_IVs}

Now let's perform data quality checks on our covariates.

::: panel-tabset
## Hash Use

Hash/marijuana use since last visit

-   1 = no
-   2 = yes
-   blank = missing

```{r}
# Create a barplot for hash use
barplot(table(data_2$HASHV))
```

Missing data is correctly handled for this variable.

We have more visits where participants used hash since the last visit than visits where participants did not use hash.

<a href="#Clean_IVs">Back to top of tabset</a>

## Hash Frequency

Frequency hash/marijuana was used since last visit.

-   0 = Never
-   1 = Daily
-   2 = Weekly
-   3 = Monthly
-   4 = Less Often
-   Blank = Missing

```{r}
# Create barplot for hash frequency
barplot(table(data_2$HASHF))
```

This variable is coded correctly. Most participants answered they have never used Hash.

<a href="#Clean_IVs">Back to top of tabset</a>

## Income

Income

-   1 = Less than \$10,000
-   2 = \$10,000 - \$19,999
-   3 = \$20,000 - \$29,999
-   4 = \$30,000 - \$39,999
-   5 = \$40,000 - \$49,999
-   6 = \$50,000 - \$59,999
-   7 = \$60,000 or more
-   9 = Do not wish to answer

The min and max for income are 1 - 9, which matches that data dictionary.

```{r}
# Create barplot for income
barplot(table(data_2$income))

# Get values for each income level
pretty_print(table(data_2$income))
```

We have to convert those values of 'Do not wish to answer' to be NA.

```{r}
# Converting scores of 9 (do not wish to answer) to be NA
data_2$income[data_2$income == "Do not wish to answer"] <- NA

# Drop empty levels
data_2$income <- droplevels(data_2$income) 

# Create a barplot of income with cleaned values
barplot(table(data_2$income))
```

Looks good, we just converted 38 participants from do not wish to answer, to count as missing.

<a href="#Clean_IVs">Back to top of tabset</a>

## BMI

Body Mass Index

We have a min of -1 and a max of 1000.

-   -1: Improbable values

-   999: Insufficient data (why it shows up with decimals and is not exactly 999, who knows).

```{r}
# Create histogram of BMI
hist(data_2$BMI)
```

Let's convert those values of -1 and \>= 998 into missing values.

```{r}
# Convert missing and improbably values to NA
data_2$BMI[data_2$BMI < 0 | data_2$BMI >= 998] <- NA
```

And check out the histogram again and the qqplot.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of BMI
hist(data_2$BMI, breaks = 20)

# Create qqplot of BMI
qqnorm(data_2$BMI)
qqline(data_2$BMI)

summarize_column(data_2$BMI)
```

Looks better. Now we have a BMI range of 15.94 - 52.83.

The histogram and qqplots show BMI is slightly right skewed, with more morbidly obese patients than underweight. Is this close enough to normal to ignore, if we take out outliers?

The patient with a BMI of 52.83 may be an outlier based on the qqplot.

```{r}
# Investigating highest BMI value to see if its an outlier
highest_bmi <- data[data$newid == 206,]

# Plot BMI for each year for this patient
plot(highest_bmi$years, highest_bmi$BMI)
```

Interestingly, participant 206 got heavier over the first year, then dropped weight in the proceeding years. Either that or that second year entry point was an error and was meant to be 42.83

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Testing to see if these plots look normal after taking the participant with BMI of 52.83 out
data_2$BMI[data_2$newid == 206 & data_2$years == 1] <- NA
hist(data_2$BMI, breaks = 20)
qqnorm(data_2$BMI)
qqline(data_2$BMI)
 
# Add back in that value we removed
data_2$BMI[data_2$newid == 206 & data_2$years == 1] <- 52.832
```

After removing that highest BMI value, the histogram is still right tailed.

What do the boxplots look like?

```{r}
outlier_bmi <- boxplot(data_2$BMI, main = "Boxplot for BMI")$out
text(x = rep(1.2, length(outlier_bmi)),
     y = outlier_bmi, labels = outlier_bmi, col = 'red', cex = 0.8)
```

That's a lot of potential outliers for BMI. If we really want to use this variable we may have to remove these values to keep BMI normally distributed.

```{r}
# Run simple correlation matrix to see if BMI correlated with any outcomes of interest

# Correlation between VMI and VLOAD log
cor_test_result <- cor.test(data_2$BMI, data_2$VLOAD_log)
cor_test_result

# Correlation between BMI and CD4+ T Cell count boxcox
cor_test_result <- cor.test(data_2$BMI, data_2$LEU3N_boxcox)
cor_test_result


# Correlation between BMI and mental QOL 
cor_test_result <- cor.test(data_2$BMI, data_2$AGG_MENT)
cor_test_result

# Correlation between BMI and physical QOL.
cor_test_result <- cor.test(data_2$BMI, data_2$AGG_PHYS)
cor_test_result
```

BMI is correlated with all our outcome variables, so we should make sure it's cleaned.

It looks like we have a lot of outliers for BMI we can clean out from our data set to make sure it has a normal distribution.

```{r}
# Compute mean and sd values for BMI
mean_value <- mean(data_2$BMI, na.rm = TRUE)
sd_value <- sd(data_2$BMI, na.rm = TRUE)

# Use plotly to label outliers
fig <- plot_ly(data = data_2, type = 'box') 
fig <- fig %>% add_boxplot(y = ~BMI, name = "Suspected Outlier", 
                           boxpoints = 'suspectedoutliers',
                           marker = list(color = 'rgb(8,81,156)',
                                         outliercolor = 'rgba(219, 64, 82, 0.6)',
                                         line = list(outliercolor = 'rgba(219, 64, 82, 1.0)',
                                                     outlierwidth = 2)),
                           line = list(color = 'rgb(8,81,156)'),
                           text = ~paste("ID:", newid),
                           hoverinfo = "text")
fig

# Identify outliers
data_2$BMI_outlier <- (abs(data_2$BMI - mean_value) > 3* sd_value)

# See how many outliers we have
filtered_data <- data_2 %>%
  select(newid, BMI, BMI_outlier) %>%
  filter(BMI_outlier == "TRUE")
dim(filtered_data)

# Pretty Print
pretty_print(head(filtered_data))

```

We have 22 patients that had a BMI +- 3 SD from the mean. Let's clear them from the data set.

```{r}
# Filter our values greater than 3SD from the mean.
data_2$BMI[(abs(data_2$BMI - mean_value) > 3* sd_value)] <- NA

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of BMI now that we have removed outleirs
hist(data_2$BMI)

# Create qqplot of BMI now that we have removed outliers
qqnorm(data_2$BMI)
qqline(data_2$BMI)

# Plot outliers one more time
fig <- plot_ly(data = data_2, type = 'box') 
fig <- fig %>% add_boxplot(y = ~BMI, name = "Suspected Outlier", 
                           boxpoints = 'suspectedoutliers',
                           marker = list(color = 'rgb(8,81,156)',
                                         outliercolor = 'rgba(219, 64, 82, 0.6)',
                                         line = list(outliercolor = 'rgba(219, 64, 82, 1.0)',
                                                     outlierwidth = 2)),
                           line = list(color = 'rgb(8,81,156)'),
                           text = ~paste("ID:", newid),
                           hoverinfo = "text")
fig

```

Those all look a lot better! We can now conclude that `BMI` is normally distributed and can be used as a covariate in our models.

<a href="#Clean_IVs">Back to top of tabset</a>

## High Blood Pressure

High Blood Pressure (SBP \>= 140 or DBP \>= 90 or (diagnosed with hypertension and use of medication)

-   1 = No
-   2 = Yes
-   3 = No, based on data trajectory
-   4 = Yes, based on data trajectory
-   9 = Insufficient data, may include reported treatment without diagnosis
-   -1 = improbable value

We will have to exclude values of 9 or -1.

```{r}
# Create barplot of high blood pressure
barplot(table(data_2$HBP))
```

```{r}
# Get values for high blood pressure category
pretty_print(table(data_2$HBP))
```

There are 137 participants with insufficient data. Let's purge them from the data set.

```{r}
# Convert values of insufficient data to NA for high blood pressure
data_2$HBP[data_2$HBP == "Insufficient data, may include reported treatment without diagnosis"] <- NA

# Drop empty levels
data_2$HBP <- droplevels(data_2$HBP) 

# Create barplot of high blood pressure 
barplot(table(data_2$HBP))

# Pretty print table
pretty_print(table(data_2$HBP))
```

Looks better.

Only 34 visits where participants had no based on trajectory, and 4 that had yes based on trajectory.

We will have to decide to either exclude these or merge them into the no or yes groups, respectively. We can do that after we run our correlations to see if there's any relationship here worth pursuing.

<a href="#Clean_IVs">Back to top of tabset</a>

## Diabetes

Diabetes (GLUC 2 \>= 126 or (diagnosed with diabetes and use of medication))

-   1 = No
-   2 = Yes
-   3 = No, based on data trajectory
-   4 = Yes, based on data trajectory
-   9 = Insufficient data

```{r}
# Create barplot of diabetes
barplot(table(data_2$DIAB))

# Pretty print table
pretty_print(table(data_2$DIAB))
```

There are 881 visits with patient who had insuffiicent data to make a diabetes diagnosis!

Let's change those values to NA.

```{r}
# Convert values of insufficient data to NA for diabetes
data_2$DIAB[data_2$DIAB == "Insufficient data"] <- NA

# Drop empty levels
data_2$DIAB <- droplevels(data_2$DIAB)

# Create a barplot for diabetes
barplot(table(data_2$DIAB))

# Pretty print table
pretty_print(table(data_2$DIAB))

```

Great, `HBP` is now cleaned.

Notably, there were no visits with a yes, based on trajectory.

<a href="#Clean_IVs">Back to top of tabset</a>

## Liver Disease

Liver disease stage 3/4 (SGPT or SGOP \> 150), preliminary algorithm

-   1 = No
-   2 = Yes
-   9 = Insufficient data

```{r}
# Create barplot of liver disease stage
barplot(table(data_2$LIV34))

# Pretty print table
pretty_print(table(data_2$LIV34))
```

There are 507 patients with insufficient data for a liver disease diagnosis.

Let's convert those values to NA to reflect this.

```{r}
# Convert values of insufficient data to NA for liver disease stage
data_2$LIV34[data_2$LIV34 == "Insufficient Data"] <- NA

# Drop empty levels
data_2$LIV34 <- droplevels(data_2$LIV34)

# Create barplot of cleaned liver stage disease
barplot(table(data_2$LIV34))

# Pretty print table
pretty_print(table(data_2$LIV34))
```

Looks good, `LIV34` is now cleaned!

<a href="#Clean_IVs">Back to top of tabset</a>

## Kidney Disease

Kidney disease (EGFR \< 60 or UPRCR \>= 200)

-   1 = No

-   2 = Yes

-   3 = No, based on data trajectory

-   4 = Yes, based on data trajectory

-   \- 9 = Insufficient data

```{r}
# Create barplots of kidney disease
barplot(table(data_2$KID))

# Pretty print table
pretty_print(table(data_2$KID))
```

There are 1068 visits where there was insufficient data for a diagnosis.

Let's convert those to NA values.

```{r}
# Convert values of insufficient data to NA for kidney disease
data_2$KID[data_2$KID == "Insufficient data"] <- NA

# Drop empty levels
data_2$KID <- droplevels(data_2$KID)

# Create barplot of kidney disease
barplot(table(data_2$KID))
```

Looks good, `KID` is now cleaned!

<a href="#Clean_IVs">Back to top of tabset</a>

## Frailty Related Phenotype

Frailty Related Phenotype (3 out of 4 conditions = YES; WTLOS, PHDWA, HLTWB, HLTVA

-   1 = No
-   2 = Yes
-   9 = Insufficient data

```{r}
# Create barplot of frailty related phenotype
barplot(table(data_2$FRP))

# Pretty print table
pretty_print(table(data_2$FRP))
```

Only 3 patients with insufficient data.

Let's convert them to NA.

```{r}
# Convert values of insufficient data to NA for frailty related phenotype
data_2$FRP[data_2$FRP == "Insufficient Data"] <- NA

# Drop empty levels
data_2$FRP <- droplevels(data_2$FRP)

# Create barplot of frailty related phenotype
barplot(table(data_2$FRP))
```

Looks good, `FRP` is now cleaned.

<a href="#Clean_IVs">Back to top of tabset</a>

## Frailty Phenotype

Frailty Phenotype (3 out of 5 conditions = YES: WTLOS, PHWDA, HLTVA, SLOW, WEAK)

-   1 = No
-   2 = Yes
-   9 = Insufficient Data

```{r}
# Create barplot of frailty phenotype
barplot(table(data_2$FP))

# Pretty print table
pretty_print(table(data_2$FP))
```

357 visits with insufficient data. Let's convert to NA.

```{r}
# Convert values of insufficient data to NA for frailty phenotype
data_2$FP[data_2$FP == "Insufficient Data"] <- NA

# Drop empty levels
data_2$FP <- droplevels(data_2$FP)

# Create barplot of frailty phenotype
barplot(table(data_2$FP))
```

Looks good, `FP` is now cleaned!

<a href="#Clean_IVs">Back to top of tabset</a>

## Total Cholesterol

Total cholesterol mg/dL

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram for total cholesterol
hist(data_2$TCHOL)

# Create qqplot for total cholesterol
qqnorm(data_2$TCHOL)
qqline(data_2$TCHOL)
```

The histogram and qq plot show what may be outliers for total cholesterol at the higher range. How many values are potential outliers?

```{r}
# Create boxplot to assess for outliers for total cholesterol
outlier_tchol <- boxplot(data_2$TCHOL, main = "Boxplot for Total Cholesterol")$out
text(x = rep(1.2, length(outlier_tchol)),
     y = outlier_tchol, labels = outlier_tchol, col = 'red', cex = 0.8)

# Sort by descending total cholesterol
sorted_data <- data_2[order(-data_2$TCHOL),] %>%
  select(newid, TCHOL, years)

# Pretty print table
pretty_print(head(sorted_data))
```

The highest cholesterol value is \~2x higher than the next highest value. Let's see what happens if we remove it.

```{r}
# Delete highest total cholesterol value
data_2$TCHOL[data_2$TCHOL == 613] <- NA 

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of total cholesterol
hist(data_2$TCHOL)

# Create qqplot of total cholesterol
qqnorm(data_2$TCHOL)
qqline(data_2$TCHOL)
```

Looks better but still slightly right skewed. This variable had \~30% missing values, so we may end up not using it.

<a href="#Clean_IVs">Back to top of tabset</a>

## Triglycerides

Triglycerides, mg/dL

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of triglycerides
hist(data_2$TRIG)

# Create qqplot of triglycerides
qqnorm(data_2$TRIG)
qqline(data_2$TRIG)
```

VERY skewed! Based on the qqplots, it looks like we would have to perform a log transform on `TRIG` if we wanted to use it. However we have nearly 50% missing values for this variable, so we should drop it as a covariate.

<a href="#Clean_IVs">Back to top of tabset</a>

## Low Density Lipoprotein

Low Density Lipoprotein (fasting) mg/dL

```{r}
# Create a histogram for LDL
hist(data_2$LDL)
```

Looks like we may have an erroneous value at the highest range there.

```{r}
# Sort by descending total cholesterol
sorted_data <- data_2[order(-data_2$LDL),] %>%
  select(newid, LDL, years)

# Pretty print table
pretty_print(head(sorted_data))
```

Patients 19 and 413 have the same value of 704 at baseline. Clearly an error with the measurement process.

`LDL` has close to 50% missing values and we will not be using it in our model, so I will move on. But good to know we can't just blindly trust all the values to be correct!

<a href="#Clean_IVs">Back to top of tabset</a>

## Dyslipidemia

Dyslipidemia at visit. fasting TC \>=200 mg/dl or \>=130 mg/dl or HDL \< 40 mg/dl or triglycerides \>=150 mg/dl or use of lipid lowering medications (HICHOLRX) with self report or clinical diagnosis in the past.

-   1 = No
-   2 = Yes
-   3 = No, based on data trajectory
-   4 = Yes from data trajectory
-   9 = Insufficient data

```{r}
# Create barplot of dyslipidemia
barplot(table(data_2$DYSLIP))

# Pretty print table
pretty_print(table(data_2$DYSLIP))
```

There are 718 visits with insufficient data for a dyslipidemia diagnosis.

Let's convert those to NAs to reflect this.

```{r}
# Convert values of insufficient data to NA for dyslipidemia
data_2$DYSLIP[data_2$DYSLIP == "Insufficient data"] <- NA

# Drop empty levels
data_2$DYSLIP <- droplevels(data_2$DYSLIP)

# Create barplot of dyslipidemia
barplot(table(data_2$DYSLIP))
```

Looks good, `DYSLIP` is now cleaned!

<a href="#Clean_IVs">Back to top of tabset</a>

## Depression

Center for Epidemiological Studies Depression Scale ( \>= 16 is depressed).

-   0 - 60

-   -1 = missing

```{r}
# Create histogram for depression score
hist(data_2$CESD)
```

Let's correctly reflect those -1's as NA's

```{r}
# Remove depression scores that were coded as missing
data_2$CESD[data_2$CESD == -1] <- NA

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of depression score
hist(data_2$CESD)

# Create qqplot for depression score
qqnorm(data_2$CESD)
qqline(data_2$CESD)
```

Looks good. `CESD` is now cleaned!

For fun, let's see if a square root transformation helps at all.

```{r}
# Try a sqrt transformation
data_2$CESD_sqrt <- sqrt(data_2$CESD)

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram of sqrt depression score
hist(data_2$CESD_sqrt)

# Create qqplot of sqrt depressions score
qqnorm(data_2$CESD_sqrt)
qqline(data_2$CESD_sqrt)
```

That does look a bit better, but the central limit theorem justifies inclusion of `CESD` without performing transformation.

<a href="#Clean_IVs">Back to top of tabset</a>

## Smoking Status

Smoking status

-   1 = Never smoked
-   2 = Former smoker
-   3 = Current smoker
-   Blank = missing

```{r}
# Create barplot of smoking status
barplot(table(data_2$SMOKE))
```

Looks good, nothing to do here.

<a href="#Clean_IVs">Back to top of tabset</a>

## Drinking Group

Alcohol use since last visit

-   0 = None
-   1 = 1 to 3 drinks/week
-   2 = 4 to 13 drinks/week
-   3 = More than 13 drinks/week
-   Blank = Missing

```{r}
# Create barplot of drinking group
barplot(table(data_2$DKGRP))
```

Looks good, nothing to do here.

<a href="#Clean_IVs">Back to top of tabset</a>

## Heroin or Opiate Use

Took heroin or other opiates since last visit?

-   1 = No
-   2 = Yes
-   -9 = Not specified in form
-   Blank = Missing

```{r}
# Create barplot of heroin or opiate use
barplot(table(data_2$HEROPIATE))

# Pretty print table
pretty_print(table(data_2$HEROPIATE))
```

Only 20 visits where participants did not specify drinking frequency on their form.

Let's correct those to be NA.

```{r}
# Convert values of insufficient data to NA for heroin or opiate use
data_2$HEROPIATE[data_2$HEROPIATE == "Not Specified"] <- NA

# Drop empty levels
data_2$HEROPIATE <- droplevels(data_2$HEROPIATE)

# Create barplot of heroin or opiate use
barplot(table(data_2$HEROPIATE))
```

Looks good. `HEROPIATE` is now cleaned!

<a href="#Clean_IVs">Back to top of tabset</a>

## Intravenous Drug Use

Took/used drugs with a needle since last visit?

-   1 = No
-   2 = Yes
-   Blank = Missing

```{r}
# Create barplot of intravenous drug use
barplot(table(data_2$IDU))
```

Looks good. Nothing to do here

<a href="#Clean_IVs">Back to top of tabset</a>

## Adherence

Adherence to meds taken since last visit

-   1 = 100%
-   2 = 95-99%
-   3 = 75-94%
-   4 \<75%
-   Blank = Missing

```{r}
# Create bar plot of adherence
barplot(table(data_2$ADH))

# Pretty print table
pretty_print(table(data_2$ADH))
```

VERY interesting. I was thinking that 100% vs 95-99% adherence was an arbitrary difference to choose to divide groups on, and was actually planning to merge the two. However, this shows why the experimenters likely made that decision: both groups have close to the same amount of observations (\~500)\> That's really good to know.

We could still play with the idea of simplifying this into two groups: \>= 95% and \< 95%. We will revisit that in the model selection.

<a href="#Clean_IVs">Back to top of tabset</a>

## Race

Race

-   1 = White, non-Hispanic
-   2 = White, Hispanic
-   3 = Black, non-Hispanic
-   4 = Black, Hispanic
-   5 = American Indian or Alaskan Native
-   6 = Asian or Pacific Islander
-   7 = Other 8 = Other Hispanic (created for 2001-03 new recruits)
-   Blank = Missing

```{r}
# Create barplot of race
barplot(table(data_2$RACE))

# Pretty print table
pretty_print(table(data_2$RACE))
```

This all looks coded properly. As is a common thing I am seeing, we have a predominant proportion of participants who are white, non-Hispanic. The data set might be large enough that we can use race as a covariate.

It might be worth dummy coding as white vs non white and see if there are any differences. That's not the main focus of this project though so I will leave that to if I have extra time at the end.

<a href="#Clean_IVs">Back to top of tabset</a>

## Education at Baseline

Baseline or earliest reported education (highest grade or level)

-   1 = 8th grade or less
-   2 = 9,10, or 11th grade
-   3 = 12th grade
-   4 = At least one year college but no degree
-   5 = Four years college / got degree
-   6 = Some graduate work
-   7 = Post-graduate degree
-   Blank = Missing

```{r}
# Create barplot of education at baseline
barplot(table(data_2$EDUCBAS))

# Pretty print table
pretty_print(table(data_2$EDUCBAS))
```

This all checks out. And it looks like there are enough participants in each group (except for 8th grade or less) to run analyses with this variable. It will be interesting to see what relationships arise, as I expect there to be a strong association between education and HIV exposure.

<a href="#Clean_IVs">Back to top of tabset</a>

## HIV Serostatus

HIV Serostatus

-   0 = Negative
-   1 = Positive

```{r}
# Checking that all patients are HIV pos
any(is.na(data_2$hivpos))
```

All patients in this data set are HIV+

<a href="#Clean_IVs">Back to top of tabset</a>

## Age

Age at visit

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create histogram for age
hist(data_2$age)

# Create qqplot for age
qqnorm(data_2$age)
qqline(data_2$age)
```

Nice and normally distributed, how we like it.

<a href="#Clean_IVs">Back to top of tabset</a>

## Antiretroviral Therapy

Take ART at visit

-   0 = NO
-   1 = YES

```{r}
# Create barplot of antiretroviral therapy
barplot(table(data_2$ART))

# Pretty print table
pretty_print(table(data_2$ART))
```

I'm not too sure how useful this variable will be. It just means there were some visits where patients were not given ART, I suppose. But most visits had participants receiving ART.

<a href="#Clean_IVs">Back to top of tabset</a>

## everART

Ever took ART.

-   0 = NO
-   1 = YES

```{r}
# Create barplot of everART
barplot(table(data_2$everART))

# Pretty print table
pretty_print(table(data_2$everART))
```

This has the exact same split as `ART`. Which makes me think they are exactly the same values for each participant

```{r}
# Check if everART and ART are identical
all(data_2$everART == data_2$ART)
```

Yup, this is either an accidental duplicate of `ART`, or there is no distinction of significance between the two. What exactly does "Ever took ART" (the explanation provided by the data dictionary) mean? Was this taken at baseline?

Either way looks like we're not using this variable.

<a href="#Clean_IVs">Back to top of tabset</a>

## Hard Drug Use

Hard drug use (either injection drugs or illicit heroin/opiate use) since last visit

-   0 = No
-   1 = Yes
-   Blank = Missing

```{r}
# Create barplot of hard drug use category
barplot(table(data_2$hard_drugs))

# Pretty print table
pretty_print(table(data_2$hard_drugs))
```

There were 198 visits where participants had used hard_drugs since the last visit.

This variable looks good. We will just have to do some dummy coding to create the categories the researchers were interested in.

<a href="#Clean_IVs">Back to top of tabset</a>

## Summary

For the CONSORT diagram, we just removed:

38 visits where patients did not report income.

X BMI values that were missing and y values that were improbable.

137 visits with insufficient data for a HBP diagnosis

881 visits with insufficient data for a DIAB diagnosis.

507 visits with insufficient data for a LIV34 diagnosis

1068 visits with insuffcient data for a kidney disease diagnosis

3 visits with insuffiient data for FRP diagnosis

357 visits with insufficient data for FP diagnosis

718 visits with insufficent data for dyslipidemia diagnosis

X visits with missing values for CESD

20 visits where heroin or opiate use was not specified

COME BACK TO THIS BECAUSE i THINK I NEED TO COME BACK AND DELETE OUTLIERS.

<a href="#Clean_IVs">Back to top of tabset</a>
:::

## Missingness Redux

We first examined missingness before performing data cleaning just to get a sense of the data set.

Let's compare what our missingness looked like pre- and post-data cleaning.

```{r}
# Visualize missingness for pre-cleaned data
gg_miss_var(data)

# Visualize missingness for post-cleaned data
gg_miss_var(data_2)
```

The order for missingness has changed, now with `KID` at the top, followed by `DIAB`, `LDL`, `TRIG`, and `DYSLIP`.

`TCHOL`, `LIV34`, and `income` are further behind, with levels of missingness that may be salvageable (\~30%).

```{r}
# Visualize missingness for pre-cleaned dataset
vis_miss(data)

# Visualize missingness for post-cleaned dataset
vis_miss(data_2)
```

And for good measure let's now examine missingness in the wide form data set.

```{r}
# Create new wideform data set for first 2 years of study              
data_wide_2 <- pivot_wider(data_2, id_cols = newid, names_from = years, values_from = -c(newid, years))

# Visualize missing values in the wideform data set
vis_miss(data_wide_2)
```

There are no real trends that become apparent when looking at this plot for the wideform data set.

To summarize, it appears that diagnoses that were determined by algorithm (such as `KID`, `DIAB`, `DYSLIP`, and `LIV34`, often had insufficient data to make a diagnosis, so perhaps this is an issue with those algorithms. Additionally, lab measurements of `LDL` and `TRIG` seem to have been too onerous for participants to have had collected. Maybe they opted out of those tests, or maybe the tests were only ordered under certain circumstances.

These would be valuable questions to bring forth to the PI. But for now it appear as if we won't be able to use these variables.

We may want to impute `income`, `LIV34`, and `TCHOL`, as these have missingness of 24%, 31%, and 32%, respectively.

#### Variables with minimal missing data (\<5%) that can be disregarded without affecting analysis integrity

-   `AGG_MENT`
-   `AGG_PHYS`
-   `HASH_V`
-   `HASHF`
-   `FRP`
-   `SMOKE`
-   `DKGRP`
-   `HEROPIATE`
-   `IDU`
-   `LEU3N`
-   `VLOAD`
-   `ADH`
-   `EDUCBASE`
-   `AGE`
-   `ART`
-   `years`
-   `hard-drugs`

#### Variables with moderate missing data (5-20%) that necessitate intervention

-   `BMI`
-   `HBP`

#### Variables with \>20% missing data that are edge cases and may require exclusion or imputation

-   `TCHOL`
-   `income`
-   `LIV34`

#### Variables with an excess of missing data (\>40%) that necessitate exclusion from the analysis

-   `LDL`
-   `TRIG`
-   `DIAB`
-   `KID`
-   `DYSLIP`

# Variable Creation {#Variable_Creation}

Here we will create the variables necessary for the analysis.

Since we cleaned the longform data set, let's go ahead and re-transpose it to update the wide form data set.

```{r}
# Create new wideform data set for first 2 years of study              
data_wide_2 <- pivot_wider(data_2, id_cols = newid, names_from = years, values_from = -c(newid, years))
```

:::::: panel-tabset
## Outcome Variable Change Scores

Here we will create our change scores for our dependent variables `LEU3N`, `VLOAD`, `AGG_MENT`, and `AGG_PHYS` to assess treatment response to ART. For `VLOAD` we will create change scores off the log transformed values.

Change scores are calculated as:

$$
y_{2year} - y_{baseline} = y_{change}
$$

::: callout-note
## Note

Change scores are coded such that:

-   For viral load, higher numbers are less desirable. Negative numbers signify a decrease in viral load over time, which is favorable.

-   For CD4+ T Cell count, higher numbers are more desirable. Negative numbers signify a decrease in leukocytes over time, which is not favorable.

-   For aggregate mental and physical QOL score, higher numbers signify an increase in mental/physical health from baseline. Negative values signify a decrease.
:::

```{r}
70 - 1

# Create change scores for outcome variables
data_wide_2$VLOAD_log_CHANGE <- data_wide_2$VLOAD_log_2 - data_wide_2$VLOAD_log_0
data_wide_2$LEU3N_CHANGE <- data_wide_2$LEU3N_2 - data_wide_2$LEU3N_0
data_wide_2$AGG_MENT_CHANGE <- data_wide_2$AGG_MENT_2 - data_wide_2$AGG_MENT_0
data_wide_2$AGG_PHYS_CHANGE <- data_wide_2$AGG_PHYS_2 - data_wide_2$AGG_PHYS_0
```

Now let's perform internal consistency checks to make sure those calculations were performed correctly, as well as reexamine the distributions of the change score for each variable.

::: panel-tabset
## Log Viral Load Change

```{r}
# Select only variables related to change scores to double check we performed calculation correctly.
filtered_data <- data_wide_2 %>%
  select(VLOAD_log_0, VLOAD_log_2, VLOAD_log_CHANGE)

# Pretty print
pretty_print(head(filtered_data))
```

The computation for change score was performed correctly.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create hist for vload log change score
hist(data_wide_2$VLOAD_log_CHANGE)

# Create qqplot for vload log change score
qqnorm(data_wide_2$VLOAD_log_CHANGE)
qqline(data_wide_2$VLOAD_log_CHANGE)
```

Looks like we have 1 outlier there that we should catch with the jackknife residuals after we fit the model, but `VLOAD_log_CHANGE` looks normally distributed!

[Top of Tabset](#Variable_Creation)

## CD4+ T Cell Count Change

```{r}
# Select only variables related to change scores to double check we performed calculation correctly.
filtered_data <- data_wide_2 %>%
  select(LEU3N_0, LEU3N_2, LEU3N_CHANGE)

# Pretty print
pretty_print(head(filtered_data))
```

The computation for change score was performed correctly.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create hist for CD4+ T Cell change score
hist(data_wide_2$LEU3N_CHANGE)

# Create qqplot for CD4+ T Cell change score
qqnorm(data_wide_2$LEU3N_CHANGE)
qqline(data_wide_2$LEU3N_CHANGE)
```

CD4+ T Cell count change score looks normally distributed, with 1 or 2 outliers that we can examine the leverage and influence of.

[Top of Tabset](#Variable_Creation)

## Aggregate Mental QOL Change

```{r}
# Select only variables related to change scores to double check we performed calculation correctly.
filtered_data <- data_wide_2 %>%
  select(AGG_MENT_0, AGG_MENT_2, AGG_MENT_CHANGE)

# Pretty print
pretty_print(head(filtered_data))
```

The computation for change score was performed correctly.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))

# Create hist for aggregate mental QOL change score
hist(data_wide_2$AGG_MENT_CHANGE, breaks = 24)

# Create qqplot for aggregate mental QOL change score
qqnorm(data_wide_2$AGG_MENT_CHANGE)
qqline(data_wide_2$AGG_MENT_CHANGE)
```

That looks more normally distributed now, and our sample size is very large so we can also count on the central limit theorem to help us with the assumption of normality.

[Top of Tabset](#Variable_Creation)

## Aggregate Physical QOL Change

```{r}
# Select only variables related to change scores to double check we performed calculation correctly.
filtered_data <- data_wide_2 %>%
  select(AGG_PHYS_0, AGG_PHYS_2, AGG_PHYS_CHANGE)

# Pretty print
pretty_print(head(filtered_data))
```

The computation for change score was performed correctly.

```{r}
# Set up the plotting area: 1 row, 2 columns
par(mfrow = c(1, 2))
    
# Create hist for aggregate physical  QOL change score
hist(data_wide_2$AGG_PHYS_CHANGE, breaks = 24)

# Create qqplot for aggregate physical QOL change score
qqnorm(data_wide_2$AGG_PHYS_CHANGE)
qqline(data_wide_2$AGG_PHYS_CHANGE)
```

Aggregate physical QOL change score appears more normally distributed now.

[Top of Tabset](#Variable_Creation)

## Summary

After computing the change scores, our outcome variables are now normally distributed and we can move forward with using them in models!

[Top of Tabset](#Variable_Creation)
:::

## Hard Drug Use Groups

We need to make dummy codes for our hard drug use groups.

The criteria outlined by the researchers are as follows:

-   [Never User:]{.underline} No drug use reported at 0, 1, or 2 years
-   [Previous User:]{.underline} Drug use reported at 0 or 1 years, but not 2 years
-   [Current User:]{.underline} Drug use reported at 2 years

::: panel-tabset
## Drug Use Classification

First we will create dummy codes for whether a patient was a never, previous, or current hard drug user.

```{r}
# Create dummy code for current drug users (those who used at year 2)
data_wide_2$current_drug <- ifelse(data_wide_2$hard_drugs_2 == "Yes", 1, 0) 

# Create dummy code for previous drug users (those who used at years 0 or 1, but not 2)
data_wide_2$previous_drug <- ifelse((data_wide_2$hard_drugs_1 == "Yes" | data_wide_2$hard_drugs_0 == "Yes") & data_wide_2$hard_drugs_2 == "No", 1, 0)

# Create dummy code for never drug users (did not use at years 0, 1, or 2)
data_wide_2$never_drug <- ifelse(data_wide_2$hard_drugs_1 == "No" & data_wide_2$hard_drugs_0 == "No" & data_wide_2$hard_drugs_2 == "No", 1, 0)

```

And perform some internal consistency checks to ensure we coded that correctly.

```{r}
# Double check our criteria worked as intended
filtered_data <- data_wide_2 %>%
  select(newid, hard_drugs_0, hard_drugs_1, hard_drugs_2, never_drug, previous_drug, current_drug)

# Pretty print
pretty_print(head(filtered_data))

# Double check no overlapping group assignments (such as a current AND previous drug user)
no_overlap <- apply(data_wide_2[, c("never_drug", "previous_drug", "current_drug")], 1, sum) <= 1
all_no_overlap <- all(no_overlap)

# Print result
if (all_no_overlap) {
  print("No overlapping group assignments")
} else {
  print("There are overlapping group assignments in some rows")
}

```

Great, that looks like we coded it properly and there are no overlaps between drug use conditions (e.g. there are no current drug users who are also previous drug users).

[Top of Tabset](#Variable_Creation)

## Drug Use Group

Now we will use those dummy codes to make a variable for which group each patient was in

-   0: Never User
-   1: Previous User
-   2: Current User

```{r, results = "hide"}
# Create a single variable for drug use group
data_wide_2$hard_drugs_grp <- ifelse(data_wide_2$never_drug == 1, 0, 
                                 ifelse(data_wide_2$previous_drug == 1, 1,
                                        ifelse(data_wide_2$current_drug == 1, 2, NA)))

# Factor this new variable and label it too
data_wide_2$hard_drugs_grp <- factor(data_wide_2$hard_drugs_grp,
                                     levels = c(0,1,2),
                                     labels = c("Never User", "Previous User", "Current User"))

# Label the new variable for better output
label(data_wide_2$hard_drugs_grp) <- "Hard Drug Use Group"

```

And perform an internal consistency check to make sure there are no overlapping group assignments.

```{r}
# Double check our criteria worked as intended
filtered_data <- data_wide_2 %>%
  select(newid, hard_drugs_0, hard_drugs_1, hard_drugs_2, hard_drugs_grp)

# Pretty print
pretty_print(head(filtered_data))
```

Let's do a final check for how many patients we have in each group.

```{r}
# Pretty print categories
pretty_print(table(data_wide_2$hard_drugs_grp))
```

Looks good, we can now move forward with analyses using the `hard_drgs_grp` variable!

[Top of Tabset](#Variable_Creation)
:::

## Adherence Groups

The experimenters coded adherence with 4 levels:

-   1: 100%
-   2: 95-99%
-   3: 75-94%
-   4: \<75%
-   Blank = Missing

However, it may be also be useful to think of adherence in terms of high vs. low adherence.

Let's go ahead and create a new category for patients that had:

-   High: 95% - 100%
-   Low: \< 95%

We will be using adherence at year 2 for these categories.

```{r}
# Create new groups based on high vs low adherence (based on adherence at 2 years)
data_wide_2$ADH_HIGH <- ifelse(data_wide_2$ADH_2 == "100%" | data_wide_2$ADH_2 == "95-99%", 1, 0)
data_wide_2$ADH_LOW <- ifelse(data_wide_2$ADH_2 == "75-94%" | data_wide_2$ADH_2 == "<75%%", 1, 0)

# Create a variable for high vs low adherence
data_wide_2$ADH_HIGHVSLOW <- ifelse(data_wide_2$ADH_LOW == 1, 0,
                                    ifelse(data_wide_2$ADH_HIGH == 1, 1, NA))

# Factor this new variable and label it too
data_wide_2$ADH_HIGHVSLOW <- factor(data_wide_2$ADH_HIGHVSLOW,
                                     levels = c(0,1),
                                     labels = c("Low Adherence", "High Adherence"))


# Label the new variable for better output
label(data_wide_2$ADH_HIGHVSLOW) <- "Adherence Level"

# Drop empty levels
data_wide_2$ADH_HIGHVSLOW <- droplevels(data_wide_2$ADH_HIGHVSLOW) 

```

Let's perform a consistency check to make sure that coding worked as intended.

```{r}
# Double check our criteria worked as intended
filtered_data <- data_wide_2 %>%
  select(newid, ADH_2, ADH_HIGHVSLOW)

# Pretty print
pretty_print(head(filtered_data, 20))
```

Looks great, now we have a new variable `ADH_HIGHVSLOW` to compare how high and low adherence to the medication regiment since the last visit impacts outcomes.

[Top of Tabset](#Variable_Creation)

## Race Groups

First let's examine how many patients of each race we have.

```{r}
# Get number of patients of each race
pretty_print(table(data_wide_2$RACE_0))
```

We have a very low number of patients in the minority race categories.

It may be informative to see how outcomes differ based on white vs non-white, as our sample is predominantly white and there is otherwise not enough patients in each category to use race as a meaningful variable.

Let's create a variable that captures this.

```{r}
# Create dummy variable for race, white vs non-white
data_wide_2$RACE_WHITEYN <- ifelse(is.na(data_wide_2$RACE_0), NA, 
                                   ifelse(data_wide_2$RACE_0 == "White, non-Hispanic", 1, 0))


# Factor this new variable and label it too
data_wide_2$RACE_WHITEYN <- factor(data_wide_2$RACE_WHITEYN,
                                     levels = c(0,1),
                                     labels = c("Non-White", "White"))

# Label the new variable for better output
label(data_wide_2$RACE_WHITEYN) <- "Race"

# Double check our criteria worked as intended
filtered_data <- data_wide_2 %>%
  select(newid, RACE_0, RACE_WHITEYN)

# Pretty print
pretty_print(head(filtered_data, 10))
```

Our dummy coding was performed correctly.

Let's see what our counts looks like now.

```{r}
# Check counts for each category in the new whiteYN variable.
table(data_wide_2$RACE_WHITEYN)
```

We have 186 non-white participants and 340 white participants.

[Top of Tabset](#Variable_Creation)

## Education Groups

```{r}
# Get number patients in each education tier
pretty_print(table(data_wide_2$EDUCBAS_0))
```

Education at baseline is currently coded as a categorical variable with 7 levels. It may be more helpful to classify education as a bivariate variable of college vs no college.

```{r}
# Create new dummy variable for college vs no college
data_wide_2$EDUC_COLLEGE <- ifelse(is.na(data_wide_2$EDUCBAS_0), NA, 
                                   ifelse(data_wide_2$EDUCBAS_0 %in% c("At least one year college but no degree", 
                                                                       "Four years college or got degree", 
                                                                       "Some graduate work", 
                                                                       "Post-graduate degree"), 1, 0))

# Factor new variable
data_wide_2$EDUC_COLLEGE <- factor(data_wide_2$EDUC_COLLEGE,
                                     levels = c(0,1),
                                     labels = c("No College", "College"))

# Label the new variable for better output
label(data_wide_2$EDUC_COLLEGE) <- "College Status"

# Double check our criteria worked as intended
filtered_data <- data_wide_2 %>%
  select(newid, EDUCBAS_0, EDUC_COLLEGE)

# Pretty print
pretty_print(head(filtered_data, 10))

# Get number of patients in each category
table(data_wide_2$EDUC_COLLEGE)
```

Looks good, we have 125 patients with no college, and 425 with at least some college.

[Top of Tabset](#Variable_Creation)
::::::

# Descriptive Statistics {#Descriptives}

Here we will acquire the descriptive statistics of our data set and create Table 1. Code modified from [cran.r-project.org](https://cran.r-project.org/web/packages/table1/vignettes/table1-examples.html)

Please note: These descriptive statistics are based on the cleaned data set, and will be different from the original data (e.g. `income` values of "Do not wish to answer" have been recoded as missing values).

```{r}
# Create Table 1 for longform data set, no stratification
table1 <- table1(~AGG_MENT + AGG_PHYS + HASHV + HASHF + income + BMI+ HBP + DIAB + LIV34 + KID + FRP + FP + TCHOL + TRIG + LDL + DYSLIP + CESD + SMOKE + DKGRP + HEROPIATE + IDU + LEU3N + VLOAD + ADH + RACE + EDUCBAS + hivpos + age + ART + everART + years + hard_drugs, data = data_2, caption = "Descriptive Statistics", overall = c(left="Total"))
table1
```

Now what if I create table 1 for the wideform data set?

```{r, results = "hide"}
# Create labels for variables to make the names of each variable more professional in outputs
label(data_wide_2$AGG_MENT_0) <- "Aggregate Mental QOL Score"
label(data_wide_2$AGG_PHYS_0) <- "Aggregate Physical QOL Score"
label(data_wide_2$HASHF_0) <- "Hash/Marijuana Use"
label(data_wide_2$HASHV_0) <- "Frequency of Hash/Marijuana Use"
label(data_wide_2$income_0) <- "Income"
label(data_wide_2$HBP_0) <- "High Blood Pressure"
label(data_wide_2$DIAB_0) <- "Diabetes"
label(data_wide_2$LIV34_0) <- "Liver Disease Stage 3/4"
label(data_wide_2$KID_0) <-"Kidney Disease"
label(data_wide_2$FRP_0) <- "Frailty Related Phenotype"
label(data_wide_2$FP_0) <- "Fraily Phenotype"
label(data_wide_2$BMI_0) <- "BMI"
label(data_wide_2$TCHOL_0) <- "Total Cholesterol"
label(data_wide_2$TRIG_0) <- "Triglycerides"
label(data_wide_2$LDL_0) <- "LDL"
label(data_wide_2$DYSLIP_0) < "Dyslipidemia"
label(data_wide_2$SMOKE_0) < "Smoking Status"
label(data_wide_2$CESD_0) <- "CESD Depression Score"
label(data_wide_2$SMOKE_0) < "Smoking Status"
label(data_wide_2$DKGRP_0) <- "Drinking Group"
label(data_wide_2$HEROPIATE_0) <- "Heroin or Opiate Use"
label(data_wide_2$IDU_0) <- "Intravenous Drug Usage"
label(data_wide_2$LEU3N_0) <- "CD4+ T Cell Count"
label(data_wide_2$VLOAD_log_0) <- "Log Viral Load"
label(data_wide_2$ADH_1) <- "Adherence to Treatment Regimen at Year 1"
label(data_wide_2$ADH_2) <- "Adherence to Treatment Regimen at Year 2"
label(data_wide_2$RACE_0) <- "Race"
label(data_wide_2$EDUCBAS_0) <- "Education at Baseline"
label(data_wide_2$hivpos_0) <- "HIV Serostatus"
label(data_wide_2$age_0) <- "Age"
label(data_wide_2$ART_0) <- "Antiretroviral Therapy"
label(data_wide_2$hard_drugs_0) <- "Hard Drug Usage"
label(data_wide_2$AGG_MENT_CHANGE) <- "Aggregate Mental QOL Change Score"
label(data_wide_2$AGG_PHYS_CHANGE) <- "Aggregate Physical QOL Change Score"
label(data_wide_2$VLOAD_log_CHANGE) <- "Log Viral Load Change Score"
label(data_wide_2$LEU3N_CHANGE) <- "CD4+ T Cell Count Change Score"

# Create Table 1 for the wideform data set,stratified by hard drug use group
table1 <- table1(~AGG_MENT_0 + AGG_PHYS_0 +  HASHV_0 + HASHF_0 + income_0 + BMI_0 + HBP_0 + DIAB_0 + LIV34_0 + KID_0 + FRP_0 + FP_0 + TCHOL_0 + TRIG_0 + LDL_0 + DYSLIP_0 + CESD_0 + SMOKE_0 + DKGRP_0 + HEROPIATE_0 + IDU_0 + LEU3N_0 +  VLOAD_log_0 + ADH_1 + ADH_2 + ADH_HIGHVSLOW +  RACE_WHITEYN + EDUC_COLLEGE + age_0 + AGG_MENT_CHANGE + AGG_PHYS_CHANGE + VLOAD_log_CHANGE + LEU3N_CHANGE| hard_drugs_grp, data = data_wide_2, caption = "Descriptive Statistics at Baseline", overall = c(left="Total"))
table1
```

For good measure, let's create Table 1 while stratifying by Adherence group at 2 years.

```{r}
# Create Table 1 for the wideform data set,stratified by adherence group
table1 <- table1(~AGG_MENT_0 + AGG_PHYS_0 +  HASHV_0 + HASHF_0 + income_0 + BMI_0 + HBP_0 + DIAB_0 + LIV34_0 + KID_0 + FRP_0 + FP_0 + TCHOL_0 + TRIG_0 + LDL_0 + DYSLIP_0 + CESD_0 + SMOKE_0 + DKGRP_0 + HEROPIATE_0 + IDU_0 + LEU3N_0 +  VLOAD_log_0 + ADH_1 + ADH_2 + ADH_HIGHVSLOW +  RACE_WHITEYN + EDUC_COLLEGE + age_0 + AGG_MENT_CHANGE + AGG_PHYS_CHANGE + VLOAD_log_CHANGE + LEU3N_CHANGE + hard_drugs_grp | ADH_2, data = data_wide_2, caption = "Descriptive Statistics at Baseline", overall = c(left="Total"))
table1
```

```{r}
# Gets average viral load per patient for example, can do min and max etc.
summary_table <- data %>%
  group_by(newid) %>%
  summarize(mean_vload = mean(VLOAD))
summary_table
```

```{r}
# Create boxplots for vload_log by hard_drugs
# _______come back to this and add multiple plots for each outcome variable in a single plot____________
fig <- plot_ly(ggplot2::diamonds, y = ~data_2$VLOAD_log, color = ~data_2$hard_drugs, type = "box")
fig
```

```{r}
# Create boxplots for vload_log by hard_drugs
fig <- plot_ly(data_wide_2, x = ~hard_drugs_grp, y = ~VLOAD_log_CHANGE, color = ~hard_drugs_grp, type = "box")
fig
```

# Correlation Matrix

First we will begin by making a correlation matrix to assess whether any of our IVs are related to each other (multicollinearity). This will also inform which variables to incorporate into the final model.

```{r}
# Let's clean our output by making a trimmed dataset excluding extaneous variables
data_for_matrix <- select(data_2, -newid, -ART, -everART, -LEU3N_log, -LEU3N_yeojohnson, -LEU3N_boxcox, -LEU3N_orderNorm, - LEU3N_standard, -AGG_MENT_orderNorm, -AGG_MENT_orderNorm, -BMI_outlier, -CESD_sqrt, -hivpos, -AGG_PHYS_orderNorm, - LIV34)

# We factored our variables at the start. To make a correlation matrix we must reconvert those back to numeric
data_for_matrix <- data.frame(lapply(data_for_matrix, function(x) if (is.factor(x)) as.numeric(x) else x))

# Make a correlation matrix with all variables of the trimmed data set
correlation_matrix <- cor(data_for_matrix, use = "complete.obs")

# Plot the matrix
corrplot(correlation_matrix, method = "circle")
```

There are a host of strong correlations in our data set.

### Precision Variables

`CESD` has a strong negative associated with `AGG_MENT`, which makes perfect sense. Those who are are more depressed will have lower mental health scores. `CESD` will have to be included as a precision variable for any analysis with `AGG_MENT` as the outcome variable.

`FRP` and `FP` are strongly negatively associated with `AGG_PHYS`. This also makes perfect sense: Those who are frail will have lower overall physical health scores. They are both highly correlated though and essentially measure the same thing. One will have to be dropped.

### Mutlicollinearity Issues

`EDUCBASE` is strongly associated with `income`, `RACE`, `SMOKE`, and weakly correlated with `TCHOL`, `LDL`, and `VLOAD_log`.

`Hard_drugs` is highly correlated with `HEROPIATE` and `IDU`, which makes perfect sense, as they are all basically the same thing.

We appear to have notable multicollinearity between `DYSLIP` and `TCHOL`, `LDL`, and `TRIG`. This makes sense because all these variables are highly related (dyslipidemia is abnormal levels of fats in the blood). This is interesting because these variables are where a lot of our missingness occured.

We also have some possible multicollinearity to be aware of between `KID`, `HBP`, and `DIAB`.

Let's clean this up a bit and remove unneccessary variables.

## Removing Superfluous Variables

We previously determined that `LDL`, `TRIG`, `DIAB`, `KID`, and `DYSLIP` had excessive missing values (\>40%).

Now that we have seen that they are not strongly related to the outcome variables, we can be assured that we can safely remove them with no need for imputation.

```{r}
# Drop variables with excessive missing values from the wideform data set
data_2 <- data_2 %>%
  select(-LDL, -TRIG, -DIAB, -KID, -DYSLIP)
```

`FRP` and `FP` are both precision variables for `AGG_PHYS`, but highly correlated to each other.

`FP` has more missing values (22%) than `FRP`(\~0%), and will thus be dropped.

```{r}
# Drop FP
data_2 <- data_2 %>%
  select(-FP)
```

`EDUCBASE` is highly correlated with `income`, `TCHOL`, `SMOKE`, and `RACE`.

`income` has 27% missing values and thus will be dropped from further analysis.

`TCHOL` has 32% missing values and will thus be dropped.

`SMOKE` and `RACE` will be dropped to avoid issues of multicollinearity, and `EDUCBASE` used as the covariate of choice.

```{r}
# Drop income, total cholesterol, smoke, and race
data_2 <- data_2 %>%
  select(-income, -TCHOL, -SMOKE, -RACE)
```

`Hard_drugs` is highly correlated with `HEROPIATE` and `IDU`.

`Hard_drugs` is our main independent variable of interest and thus we drop `HEROPIATE` and `IDU`.

```{r}
# Drop income, total cholesterol, smoke, and race
data_2 <- data_2 %>%
  select(-HEROPIATE, -IDU)
```

`HBP` is lightly correlated with `age` and `BMI`. Let's drop it to avoid multicollinearity.

```{r}
# Drop high blood pressure.
data_2 <- data_2 %>%
  select(-HBP)
```

## Correlation Matrix Redux

Let's take another look at that correlation matrix now that we have cleaned up our data set to remove variables with excessive missing values and issues of multicollinearity.

```{r}
# Let's clean our output by making a trimmed dataset excluding extraneous variables
data_for_matrix <- select(data_2, -newid, -ART, -everART, -LEU3N_log, -LEU3N_yeojohnson, -LEU3N_boxcox, -LEU3N_orderNorm, - LEU3N_standard, -AGG_MENT_orderNorm, -AGG_MENT_orderNorm, -BMI_outlier, -CESD_sqrt, -hivpos, -AGG_PHYS_orderNorm, - LIV34)

# We factored our variables at the start. To make a correlation matrix we must reconvert those back to numeric
data_for_matrix <- data.frame(lapply(data_for_matrix, function(x) if (is.factor(x)) as.numeric(x) else x))

# Make a correlation matrix with all variables of the trimmed data set
correlation_matrix <- cor(data_for_matrix, use = "complete.obs")

# Plot the matrix
corrplot(correlation_matrix, method = "circle")
```

Looking MUCH better! Here we can see some potentially strong relationships emerge.

-   `CESD` as mentioned will be included as a precision variable for `AGG_MENT`

-   `FRP` as mentioned will be included as a precision variable for `AGG_PHYS`

-   `EDUCBASE` looks like it will be a predictor for all outcome variables except `AGG_MENT`

-   `BMI` appears to have a weak correlation with all outcome variables and will likely be included in the final models.

-   `age` also looks weakly correlated to all outcome variables except `VLOAD_log`

Let's run some individual regression and assess these relationships more closely.

p-values of \< 0.1 will be considered for the final models.

I just want to try making a correlation matrix of the wideform data set and see what it looks like

```{r}
# Let's clean our output by making a trimmed dataset excluding extraneous variables
data_for_matrix <- select(data_wide_2, AGG_MENT_CHANGE, AGG_PHYS_CHANGE, LEU3N_CHANGE, VLOAD_log_CHANGE, BMI_2, FRP_2, CESD_2, DKGRP_2, ADH_2, ADH_HIGHVSLOW, EDUCBAS_2, EDUC_COLLEGE, age_2, hard_drugs_grp)

# We factored our variables at the start. To make a correlation matrix we must reconvert those back to numeric
data_for_matrix <- data.frame(lapply(data_for_matrix, function(x) if (is.factor(x)) as.numeric(x) else x))

# Make a correlation matrix with all variables of the trimmed data set
correlation_matrix <- cor(data_for_matrix, use = "complete.obs")

# Plot the matrix
corrplot(correlation_matrix, method = "circle")
```

# Interactive Variable Selection {#EDA}

Here I will plot the data and perform a number of simple linear regressions to examine relationships between variables in order to determine which covariates to include in the model.

Remember that:

-   For viral load, higher numbers are less desirable. Negative numbers signify a decrease in viral load over time, which is favorable.

-   For CD4+ T Cell count, higher numbers are more desirable. Negative numbers signify a decrease in leukocytes over time, and which is not favorable.

-   For aggregate mental and physical QOL score, higher numbers signify an increase in mental/physical health from baseline. Negative values signify a decrease.

::::: panel-tabset
## Log Viral Load 

Let's focus first on a model predicting Log Viral Load change.

::: panel-tabset
## PEV - Hard Drug Use

Let's begin by seeing if there appears to be a difference in log viral load change based on hard drug use, the primary explanatory variable.

```{r}
# Create boxplots of log viral load change by hard drug use group
p <- ggplot(data_wide_2, aes(x = hard_drugs_grp, y = VLOAD_log_CHANGE, fill = hard_drugs_grp)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Log Viral Load Change by Hard Drug Use Group",
       x = "Hard Drug Use Group",
       y = "Log Viral Load Change") +
  guides(fill = guide_legend(title = "Hard Drug Use Group"))

ggplotly(p)
```

There may be a difference between log viral load change and hard drug use group, especially between never users and previous users. Visually, it appears that that never use group had more of a decrease in log viral load over 2 years compared to the previous and current drug use groups.

Let's run the regression to see if this relationship is statistically significant.

```{r}
# Perform regression predicting log vload change by hard drug use group with never user as the reference group
model <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)
```

```{r}
# Gather p-values of the model
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model_attach), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

Change the reference level to previous users and re-run the model.

```{r}
# Relevel to change to the reference group to previous user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression predicting log vload change by hard drug use group, with previous users as the reference group
model <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)

# Apply Bonferroni correction
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model_attach), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

The overall model is significant (F~(2,529)~= 3.991, p = 0.01903). The group comparisons were not significant after applying Bonferroni correction however (all p-adjusted > 0.05). They may be significant after including precision variables or confounders, and thus we continue with the analysis and include `hard_drugs_group` as the PEV.


[Top of Tabset](#EDA)

## Adherence

The researchers are interested in if treatment response between the drug use groups can be explained by differences in adherence to the HAART treatment regimen.

The first step toward investigating this is to examine if there is a relationship between adherence and treatment response, starting with log viral load change.

We can examine this by plotting the average log viral loads each year by adherence group.

```{r}
# Get rid of that value of 1 for adherence at baseline for patient 426
data_2$ADH[data_2$years == 0] <- NA

# Get means for each year
summary_data <- data_2 %>%
  group_by(ADH, years) %>%
  summarize(Average_VLOAD_log = mean(VLOAD_log, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_VLOAD_log, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Log Viral Load Change by Adherence Group Over 2 Years",
       x = "Year",
       y = "Average Log Viral Load Change",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

Indeed we can see that, across the first 2 years of the study, as adherence decreased, average log viral load increased!

That is, groups with higher adherence had a smaller increase in log viral load over 2 years compared to those with lower adherence. This is evidence that the ART treatment is efficacious in reducing viral load!

Let's examine that relationship with boxplots.

```{r}
# Create boxplots of log viral load change by adherence group
p <- ggplot(data_wide_2, aes(x = ADH_2, y = VLOAD_log_CHANGE, fill = ADH_2)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Log Viral Load Change by Adherence at Year 2",
       x = "Adherence at year 2",
       y = "Log Viral Load Change") +
  guides(fill = guide_legend(title = "Adherence Group"))

ggplotly(p)
```

This relationship is reflected in the boxplots: Groups with high adherence had a greater decrease in log viral load over 2 years compared to those with low adherence.

Let's run the regression to ensure this difference is statistically significant.

```{r}
# Perform regression predicting log vload change by adherence group at year 2, with the 100% adherence group as the reference level
model <- lm(VLOAD_log_CHANGE ~ ADH_2, data = data_wide_2)

# Examine Summary
summary(model)
```

```{r}
# Apply Bonferroni correction
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model_attach), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

Change the reference level to the 75-94% group and re-run the model.

```{r}
# Relevel to change to the reference group to 75-94%
data_wide_2$ADH_2 <- relevel(data_wide_2$ADH_2, ref = "75-94%")

# Perform regression predicting log vload change by adherence group at year 2, with the 75-94% group as the reference level
model <- lm(VLOAD_log_CHANGE ~ ADH_2, data = data_wide_2)

# Examine Summary
summary(model)

# Apply Bonferroni correction
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model_attach), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```


The overall model is significant (F~(3, 528)~= 8.261, p < .0001). 

Looking at the between-group comparisons, the 100% group is statistically different from the 75-95% group (p-adjusted < 0.0001) and the <75% group (p-adjusted = 0.0266). 

The 75-95% group is significantly different from the 95-99% group (p-adjusted <0.0001).

The 100% and 95-99% group were not significantly different from each other (p-adjusted > .05), and the 75-95% and <75% groups were not significantly different from each other (p-adjusted > 0.5).

In other words, there is no difference between the two highest adherence groups from each other, and between the two lowest adherence groups from each other, providing strong evidence for grouping these levels together and separating based on high vs low adherence.


::: callout-note
Based on the above findings, there is no difference between the two highest adherence level groups from each other, and the two lowest adherence level groups from each other.

Therefore, analyses moving forward will only make comparisons between high vs low adherence for ease of interpretation.
:::

[Top of Tabset](#EDA)

## Adherence High vs Low

Based on the plots and regression results from looking at adherence group and log viral load, there is no difference between the two highest adherence level groups from each other, and the two lowest adherence level groups from each other.

Therefore, it is more prudent to collapse this variable and make comparisons only between high adherence (95-100%) and low adherence (<95%) groups

Let's examine change in log viral load based on these criteria.

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(ADH_HIGHVSLOW))

# Create boxplots of log viral load change by adherence group
p <- ggplot(data_no_na, aes(x = ADH_HIGHVSLOW, y = VLOAD_log_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Boxplot of Log Viral Load Change by Adherence at Year 2",
       x = "Adherence Level",
       y = "Log Viral Load Change") +
  guides(fill = guide_legend(title = "Adherence Group"))

ggplotly(p)
```

Indeed, this plot is simpler and encapsulates the true relationships better!

The high adherence group had a greater decrease in log viral load over 2 years compared to the low adherence group.

Let's perform the linear regression.

```{r}
# Perform regression predicting log vload change by adherence group at year 2
model <- lm(VLOAD_log_CHANGE ~ ADH_HIGHVSLOW, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is statistically significant (F~(1,518)~= 17.78, p < 0.0001). On average, those in the high adherence group have a mean change in log viral load that is 1.86 log copies/mL (or 72.44 copies/mL) lower than those in the low adherence group

`ADH_HIGHVSLOW` will absolutely be included in the final model for `VLOAD_log`.

[Top of Tabset](#EDA)

## BMI

The correlation matrix reveals a relationship between BMI and each outcome variable. Let's examine this relationship more closely.

```{r}
# Create a scatterplot of log vload change by BMI at baseline
p <- ggplot(data_wide_2, aes(x = BMI_0, y = VLOAD_log_CHANGE, color = BMI_0)) + 
  geom_point() +
  theme_minimal() +
  labs(title = "Log Viral Load Change by BMI at Baseline",
       y = "Log Viral Load Change",
       x = "BMI at Baseline") + 
  scale_fill_brewer(palette = "Pastel2")

# Make the plot interactive
ggplotly(p)
```

That does not look like a very strong association.

Let's run a regression to see if there is any kind of linear relationship in there.

```{r}
# Perform a linear regression predicting log viral load change by BMI at baseline
model <- lm(VLOAD_log_CHANGE ~ BMI_0, data = data_wide_2)

# Examine model summary
summary(model)
```

`BMI` is not a significant predictor of log viral load change (p = 0.246) and will not be included in the final model.

[Top of Tabset](#EDA)

## College Education

Based on the correlation matrix, `EDUC_COLLEGE` appears to be significantly associated with our outcome variables.

```{r}
# Create a scatterplot of log vload change by college education
ggplot(data_wide_2, aes(x = EDUC_COLLEGE, y = VLOAD_log_CHANGE, fill = EDUC_COLLEGE)) + 
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  labs(title = "Log Viral Load Change by College Education",
       y = "Log Viral Load Change",
       x = "College Education") + 
  scale_fill_brewer(palette = "Pastel2")
```

There appears to be a difference in log viral load change based on college education. Remember that this is on a logarithmic scale, so the real differences will be much more pronounced, even if the differences seem small here!

Let's run the regression.

```{r}
# Perform a linear regression predicting log viral load change by college education
model <- lm(VLOAD_log_CHANGE ~ EDUC_COLLEGE, data = data_wide_2)

# Examine model summary
summary(model)
```

The overall model is significant F~(1,530)~= 9.204, p = 0.002533). On average, those with a college educaton had change in viral load that was 0.8979 log copies/mL (or 7.9 copies/mL) than those who did not have a college education.

`EDUC_COLLEGE` is a significant predictor of log viral load change and should be included in the final model.

[Top of Tabset](#EDA)

## Summary

Based on the results of the exploratory data analysis, the variables that will be included in the final model for `VLOAD_log_CHANGE` are `hard_drug_grp`, `ADH_HIGHLOW`, and `EDUC_COLLEGE`.

[Top of Tabset](#EDA)

:::

## CD4+ T Cell Count

Now let's examine relationships for the model predicting CD4+ T Cell Count

::: panel-tabset

## PEV - Hard Drug Use

Let's see if there is a a difference in CD4+ T Cell count based on hard drug use, the primary explanatory variable.

```{r}
# Relevel to change the reference cateory to Never User
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Create boxplots of CD4+ T Cell count change by hard drug use group
p <- ggplot(data_wide_2, aes(x = hard_drugs_grp, y = LEU3N_CHANGE, fill = hard_drugs_grp)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of CD4+ T Cell Count Change by Hard Drug Use Group",
       x = "Hard Drug Use Group",
       y = "CD4+ T Cell Count Change") +
  guides(fill = guide_legend(title = "Hard Drug Use Group"))

ggplotly(p)
```

Previous and current hard drug users may have low CD4+ T Cell count compared to never users.

Let’s run the regression to see if this relationship is statistically significant.

```{r}
# Perform regression predicting CD4+ T Cell count change by hard drug use group with never user as the reference group
model <- lm(LEU3N_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)

# Gather p-values of the model
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model_attach), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

Change the reference group to previous users and re-run the model. 

```{r}
# Relevel to change the reference category to Previous User
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression predicting CD4+ T Cell count change by hard drug use group with previous user as the reference group
model <- lm(LEU3N_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)

# Gather p-values of the model
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model_attach), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

The overall model is statistically significant F~(2,529)~ = 12.55, p < 0.0001). On average current drug users have a change in CD4+ T cell count that is 119.467 cells lower than never drug users (p-adjusted < 0.0001). The other between group comparisons were not significant (p-adjusted > 0.05).

`hard_drug_grp` will be included as a predictor in the final model for `LEU3N`.

[Top of tabset](#EDA)

## Adherence High vs Low

For ease of mind, let's plot our average `LEU3N` values each year by adherence group.

```{r}
# Get means for each year
summary_data <- data_2 %>%
  group_by(ADH, years) %>%
  summarize(Average_LEU3N = mean(LEU3N, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_LEU3N, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average CD4+ T Cell Count change by Adherence Group Over 2 Years",
       x = "Year",
       y = "Average CD4+ T Cell Count",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

We have the same relation we did with log viral load, where higher adherence groups tend to have better outcomes (higher average CD4+ T Cell count in this case). The <75% has a pretty high average CD4+ T cell count, but I think we can chalk this up to variance due to a smaller sample size. We still see the general trend that both high adherence groups are performing better than both low adherence groups, and we can safely collapse these categories into high adherence (95-100%) and low adherence (<95%) groups. 

Let’s examine change in CD4+ T Cell count based on high vs low adherence.

```{r}
# Create boxplots of CD4+ T Cell count change by adherence group
ggplot(data_no_na, aes(x = ADH_HIGHVSLOW, y = LEU3N_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Boxplot of CD4+ T Cell Count Change by Adherence at Year 2",
       x = "Adherence Level",
       y = "CD4+ T Cell Count Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```

It appears that the high adherence group may have a slightly higher gain in CD4+ T Cells over 2 years (its pretty close though).

Let's run a regression to see if this is statistically significant.

```{r}
# Perform regression predicting CD4+ T Cell count change by adherence group at year 2
model <- lm(LEU3N_CHANGE~ ADH_HIGHVSLOW, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is not significant (F~(1,518)~= 2.152, p = 0.143).

Just for sanity's sake let's run that with our uncollapsed adherence categories.

```{r}
# Perform regression predicting CD4+ T Cell count change by adherence group at year 2
model <- lm(LEU3N_CHANGE~ ADH_2, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is significant (F~(3, 528)~, = 4.353, p = 0.0048). However, none of those between group comparisons are significant after Bonferroni correction.

So no matter how you run it, adherence is not related to CD4+ T Cell count.

We will still include `ADH_HIGHLOW` as a covariate in the final model for `LEU3N_CHANGE`, since it was a confounder in the model predicting `VLOAD_log_CHANGE`, and new relationships may become apparent if it is included in this model.

[Top of tabset](#EDA)

## BMI

The correlation matrix reveals a potential relationship between BMI and each CD4+ T Cell count.

Let's assess.

```{r}
# Create a scatterplot of CD4+ T Cell Count change by BMI at baseline
ggplot(data_wide_2, aes(x = BMI_0, y = LEU3N_CHANGE, color = BMI_0)) + 
  geom_point() +
  theme_minimal() +
  labs(title = "CD4+ T Cell Count Change by BMI at Baseline",
       y = "CD4+ T Cell Count Change",
       x = "BMI at Baseline") + 
  scale_fill_brewer(palette = "Pastel2")
```

There does not appear to be a strong relationship between BMI and CD4+ T Cell count change.

We perform the regression to double check.

```{r}
# Perform a linear regression predicting CD4+ T Cell count change by BMI at baseline
model <- lm(LEU3N_CHANGE ~ BMI_0, data = data_wide_2)

# Examine model summary
summary(model)
```

Let's plot the regression line.

```{r}
# Create a scatterplot of CD4+ T Cell Count change by BMI at baseline
ggplot(data_wide_2, aes(x = BMI_0, y = LEU3N_CHANGE, color = BMI_0)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal() +
  labs(title = "CD4+ T Cell Count Change by BMI at Baseline",
       y = "CD4+ T Cell Count Change",
       x = "BMI at Baseline") + 
  scale_fill_brewer(palette = "Pastel2")
```

The overall model is non-significant (F~(1,517)~ = 2.798, p = 0.095). On average, every 1 unit increase in BMI is associated with a 0.0034 increase in CD4+ T Cell count. Though not significant, the model is below that p = 0.10 cutoff for potential covariates we established a priori. On average, every 1 unit increase in BMI is associated with a 0.0034 increase in CD4+ T Cell count.

`BMI` will be included as a potential precision variable for the model predicting `LEU3N_CHANGE`.

[Top of Tabset](#EDA)

## Frailty Related Phenotype

Fraily related phenotype was also correlated to CD4+ T Cell count in the correlation matrix. 

Let's assess that relationship.

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(FRP_2))

# Create boxplots of CD4+ T Cell count change by frailty related phenotype at year 2
ggplot(data_no_na, aes(x = FRP_2, y = LEU3N_CHANGE, fill = FRP_2)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Boxplot of CD4+ T Cell Count Change by Frailty Related Phenotype",
       x = "Frailty Related Phenotype",
       y = "CD4+ T Cell Count Change") +
  guides(fill = guide_legend(title = "Frailty Related Phenotype"))
```
It appears that those with a frailty related phenotype have a lower increase in CD4+ T Cell count over the 2 years of the study.

Let's run a regression to see if that relationship is statistically significant.

```{r}
# Perform regression predicting physical QOL change by Frailty Related Phenotype
model <- lm(LEU3N_CHANGE ~ FRP_2, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is statistically significant (F~1,528)~= 11.66, p < 0.0001). On average, those with a frailty related phenotype had a change in CD4+ T Cell count over 2 years that was 124.046 cells lower than those without a frailty related phenotype (p < 0.0001).

`FRP_2` will be included as a precision variable for the model predicting `LEU3N_CHANGE`.

[Top of Tabset](#EDA)

## College Education

College education did not look strongly related to CD4+ T Cell count change, but let's run a simple regression just to make sure.

```{r}
# Create a scatterplot of CD4+ T Cell count change by college education
ggplot(data_wide_2, aes(x = EDUC_COLLEGE, y = LEU3N_CHANGE, fill = EDUC_COLLEGE)) + 
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  labs(title = "CD4+ T Cell Count Change by College Education",
       y = "CD4+ T Cell Count Change",
       x = "College Education") + 
  scale_fill_brewer(palette = "Pastel2")
```
They appear comparable, but there may be a slight difference. Run regression to be sure.

```{r}
# Perform regression predicting log vload change by college education
model <- lm(LEU3N_CHANGE ~ EDUC_COLLEGE, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is significant (F~(1,530)~= 4.231, p = 0.0401). On average, those with a college education had a change in CD4+ T cell count that was 40.20 cells higher than those without a college education.

`EDUC_COLLEGE` will be included as a precision variable for the model predicting `LEU3N_CHANGE`.

[Top of Tabset](#EDA)

## Summary 

[Top of Tabset](#EDA)

Based on the results of the exploratory data analysis, the variables that will be included for consideration in the final model for `LEU3N_CHANGE` are `hard_drugs_grp`, `ADH_HIGHLOW`, `BMI_2`, `FRP_2`, and `EDUC_COLLEGE`
:::

## Aggregate Mental QOL Change

Now let's examine relationships for the model predicting aggregate mental QOL change. 

The researchers are concerned that the a

They want to investigate how mental QOL is after 2 years. If there is a 

We can also see if mental QOL differs by hard drug use grp and adherence, and any other covariates.

Does viral load predict mental QOL?

does LEU3n predict mental QOL?

Do I have to do something here concerning dropout?


::: panel-tabset

## PEV - Hard Drug Use

Let's assess if mental QOL is related to the hard drug use categories.

```{r}
# Create boxplots of log viral load change by hard drug use group
ggplot(data_wide_2, aes(x = hard_drugs_grp, y = AGG_MENT_CHANGE, fill = hard_drugs_grp)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Mental QOL Change by Hard Drug Use Group",
       x = "Hard Drug Use Group",
       y = "Aggregate Mental QOL Change") +
  guides(fill = guide_legend(title = "Hard Drug Use Group"))
```

There does not appear to be much of a difference in mental QOL by hard drug use groups.

Let's run a regression.

```{r}
# Perform regression predicting mental QOL change by hard drug use group
model <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)
```

`hard_drugs_grp` is not a significant predictor of `AGG_MENT_CHANGE`, and will be dropped from further consideration for this outcome variable.

This is interesting, because when we plot average mental QOL over 8 years by hard drug use, we can see a clear relationship 

```{r}
# Get means for each year
summary_data <- data %>%
  group_by(hard_drugs, years) %>%
  summarize(Average_agg_ment = mean(AGG_MENT, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_agg_ment, color = hard_drugs)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average mental QOL by Hard Drug Use Over 8 Years",
       x = "Year",
       y = "Average mental QOL",
       color = "Hard Drug Use") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

Where those who did not use hard drugs since the last visit had higher mental QOL.

It seems that somewhere when we created our 3 hard drug use categories of never user, previous user, and current user, we lost some of this information.

`hard_drg_group` will still be included as a potential covariate in case there is a confounding variable present.

[Top of Tabset](#EDA)

## Adherence 

If adverse reactions from the HAART treatment negatively impacted patients, then we would expect to see the higher adherence groups having a smaller increase, or even decrease, in mental QOL compared to those in the low adherence groups.

Let's first examine this by plotting the average mental QOL for each year by adherence group.

```{r}
# Get means for each year
summary_data <- data_2 %>%
  group_by(ADH, years) %>%
  summarize(Average_AGG_MENT = mean(AGG_MENT, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_AGG_MENT, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Mental QOL by Adherence Group Over 2 Years",
       x = "Year",
       y = "Average Mental QOL",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

This plot shows that, over the first 2 years, the < 75% adherence group had the highest increase in mental QOL! This is the opposite of expected; you would expect the 100% adherence group to have the highest mental QOL if there were no adverse effects from the drug and it was improving QOL overall by decreasing HIV viral load.

However, the relationship looks different if we create this same plot over the entire 8 years of the study.

```{r}
# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_QOL = mean(AGG_MENT, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_QOL, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Mental QOL Score by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average Mental QOL Score",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

Here we see the true relationship emerge! The 100% adherence group has the highest aggregate mental QOL score across the 8 years of the study, followed by the 95-99% adherence group, then the 75-94% and <75% adherence groups trailing behind with fair amounts of year to year variation.

Could we calculate AUC and use that to answer the researchers' question?

Therefore we can reasonably conclude that higher adherence is related to better overall mental QOL. Which would likely not be the case if the side effects of the drug were worse than the benefits from taking them.


Let's examine these relationships with boxplots.

First looking at adherence split into four categories.

```{r}
# Change reference group
data_wide_2$ADH_2 <- relevel(data_wide_2$ADH_2, ref = "100%")

# Create boxplots of mental QOL change by adherence group
ggplot(data_wide_2, aes(x = ADH_2, y = AGG_MENT_CHANGE, fill = ADH_2)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Mental QOL Change by Adherence at Year 2",
       x = "Adherence at year 2",
       y = "Mental QOL Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```

And then adherence split into two categories of high vs low.

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(ADH_HIGHVSLOW))

# Create boxplots of mental QOL change by adherence group
ggplot(data_no_na, aes(x = ADH_HIGHVSLOW, y = AGG_MENT_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Mental QOL Change by Adherence at Year 2",
       x = "Adherence at year 2",
       y = "Mental QOL Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```
This plot shows that there is a slight difference in aggregate mental QOL over the first 2 years of the study between the high and low adherence groups.

While not a perfect encapsulation of the true relationship between adherence and mental QOL over time, I believe this comparison adequately captures the differences between adherence groups we can see with our data visualizations.

Let's perform a regression to see if this relationship is statistically significant.

```{r}
# Perform regression predicting mental QOL change by adherence group
model <- lm(AGG_MENT_CHANGE ~ ADH_HIGHVSLOW, data = data_wide_2)

# Examine Summary
summary(model)
```

Great! `ADH_HIGHLOW` is a significant predictor of mental QOL change over 2 years (F~(1,530)~= 6.092). On average, those who had high adherence to the treatment regiment had an aggregate mental QOL score that was 4.79 points higher than those who had low adherence (p = 0.0139).

`ADH_HIGHLOW` will be included in the final model as a predictor of `AGG_MENT_CHANGE`.

[Top of Tabset](#EDA)

## CESD - Depression

The only other variable that flagged as being associated with mental QOL was the CESD Depression score.

Let's examine this relationship with a plot.

```{r}
# Create a scatterplot of mental QOL change score by depression at 2 years
ggplot(data_wide_2, aes(x = CESD_2, y = AGG_MENT_CHANGE, color = CESD_2)) + 
  geom_point() +
  theme_minimal() +
  labs(title = "Mental QOL Change by Depression at Baseline",
       y = "Mental QOL Change ",
       x = "Depression Score") + 
  scale_fill_brewer(palette = "Pastel2")
```

There appears to be a negative linear relationship here. Let's run the regression and fit the model.

```{r}
# Perform a linear regression predicting mental QOL change by depression at baseline
model <- lm(AGG_MENT_CHANGE ~ CESD_2, data = data_wide_2)

# Examine model summary
summary(model)
```

```{r}
# Create a scatterplot of mental QOL change score by depression at baseline
ggplot(data_wide_2, aes(x = CESD_2, y = AGG_MENT_CHANGE, color = CESD_2)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal() +
  labs(title = "Mental QOL Change by Depression at Baseline",
       y = "Mental QOL Change ",
       x = "Depression Score") + 
  scale_fill_brewer(palette = "Pastel2")
```

Depression score is a significant predictor of mental QOL change over the first 2 years of treatment (F~(1, 536)~= 52.05). On average, a 1-point increase in depression score is associated with a 0.33 point decrease in mental QOL score (p < 0.0001).

`CESD_0` will be included as a precision variable in the model predicting `AGG_MENT_CHANGE`



## Depression and Hard Drug Use

It appears that depression and hard drug use may be correlated based on the correlation matrix. 

If so, we have potential confounding between hard drug use and depression. Maybe those who used hard drugs have worse QOL, but it's because they are depressed. Or vice versa. 

Let's assess.

First we can plot depression by hard drug use group.

```{r}
# Create a scatterplot of depression score at year 2 by hard drug use group
ggplot(data_wide_2, aes(x = hard_drugs_grp, y = CESD_2, fill = hard_drugs_grp)) + 
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Depression Score by Hard Drug Use Group",
       y = "Depression Score ",
       x = "Hard Drug Use Group") + 
  scale_fill_brewer(palette = "Pastel2")
```

It appears that current and previous drug users have higher depression scores than those who never used drugs.

Let's run a regression to see if that relationship is statistically significant.

```{r}
# Refactor to never users as reference group
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform a linear regression predicting depression by hard drug use group
model <- lm(CESD_2 ~ hard_drugs_grp, data = data_wide_2)

# Examine model summary
summary(model)
```

Hard drug use is a significant predictor of depression score (F~(2, 542)~= 14.31). On average, current hard drug users had depression scores that were 5.23 points higher than never hard drug users (p < 0.0001), and previous hard drug users had depression scores that were 7.29 points higher than those who never used hard drugs (p < 0.0001).

`hard_drug_grp` will be included as a possible confounder for the relationship between depression and mental QOL. Or rather depression will be included as a possible confounder for the relationship between hard_drug_use and mental QOL.

[Top of Tabset](#EDA)

:::

## Aggregate Physical QOL Change

If the ART has a strong adverse effect on QOL, then we can expect those with high adherence to have worse QOL. Maybe.

::: panel-tabset

## Drug Use Groups

Let’s assess if physical QOL is related to the hard drug use categories by itself.

```{r}
# Create boxplots of aggregate physical QOL by hard drug use group
ggplot(data_wide_2, aes(x = hard_drugs_grp, y = AGG_PHYS_CHANGE, fill = hard_drugs_grp)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Aggregate Physical QOL by Hard Drug Use Group",
       x = "Hard Drug Use Group",
       y = "Aggregate Physical QOL Change") +
  guides(fill = guide_legend(title = "Hard Drug Use Group"))
```

It looks like current hard drug users have a lower physical QOL score than never hard drug users.

Let's run a regression to see if that difference is statistically significant.

```{r}
# Perform regression predicting physical QOL change by hard drug use group
model <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)
```

```{r}
# Gather p-values of the model
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model_attach), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

Change the reference group to previous drug users and re-run the model.

```{r}
# Relevel hard drug use to have the reference level as previous users
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression predicting physical QOL change by hard drug use group
model <- lm(AGG_PHYS_CHANGE ~ hard_drugs_grp, data = data_wide_2)

# Examine Summary
summary(model)

# Gather p-values of the model
p_values <- summary(model)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model_attach), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

Yes it is. Hard drug use is a significant predictor of physical QOL change over 2 years (F~(2, 540)~= 9.019). On average, current drug users have a physical QOL score that is 4.90 points lower than never drug users (p-adjusted = 0.0000792), and 4.65 points lower than previous drug users (p-adjusted = 0.0147).

`hard_drug_group` will be included as a predictor of `AGG_PHYS_CHANGE`.

[Top of Tabset](#EDA)

## Adherence

If adverse reactions from the HAART treatment negatively impacted patients, then we would expect to see the higher adherence groups having a smaller increase, or even decrease, in physical QOL compared to those in the low adherence groups.

Let’s first examine this by plotting the average mental QOL for each year by adherence group.

```{r}
# Get means for each year
summary_data <- data_2 %>%
  group_by(ADH, years) %>%
  summarize(Average_AGG_PHYS = mean(AGG_PHYS, na.rm = TRUE))
```

```{r}
# Create plot
ggplot(summary_data, aes(x = years, y = Average_AGG_PHYS, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Physical QOL by Adherence Group Over 2 Years",
       x = "Year",
       y = "Average Physical QOL",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

Here we can see that the 2 highest adherence groups have the highest physical QOL scores, which tracks with what we would expect if the drugs were helping.

For good measure, let's examine this relationship across the entire 8 years of the study.

```{r}
# Get rid of that value of 1 for adherence at baseline for patient 426
data$ADH[data$years == 0] <- NA

# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_AGG_PHYS = mean(AGG_PHYS, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_AGG_PHYS, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Physical QOL Score by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average Physical QOL Score",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

We see a similiar relationship looking at the full 8 years of the study. You can visualize how the two highest adherence groups would have a greater AUC than the two lowest adherence groups.

Let’s examine these relationships with boxplots.

First looking at adherence split into four categories.

```{r}
# Change reference group
data_wide_2$ADH_2 <- relevel(data_wide_2$ADH_2, ref = "100%")

# Create boxplots of physical QOL change by adherence group
ggplot(data_wide_2, aes(x = ADH_2, y = AGG_PHYS_CHANGE, fill = ADH_2)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Physical QOL Change by Adherence at Year 2",
       x = "Adherence at year 2",
       y = "Physical QOL Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```

That doesn't look as informative as our high vs low comparison should be.

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(ADH_HIGHVSLOW))

# Create boxplots of Physical QOL change by adherence group
ggplot(data_no_na, aes(x = ADH_HIGHVSLOW, y = AGG_PHYS_CHANGE, fill = ADH_HIGHVSLOW)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette="Pastel2") +
  labs(title = "Boxplot of Physical QOL Change by Adherence at Year 2",
       x = "Adherence at year 2",
       y = "Physical QOL Change") +
  guides(fill = guide_legend(title = "Adherence Group"))
```
It appears that the high adherence group has a higher increase in physical quality of life compared to the low adherence groups. 

Let's run the regression to see if that difference is statistically significant.

```{r}
# Perform regression predicting physical QOL change by adherence
model <- lm(AGG_PHYS_CHANGE ~ ADH_HIGHVSLOW, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is statistically significant (F~(1,530)~=12.7). On average, those with high adherence had a change in physical QOL score that was 4.81 points higher than those with low adherance. (p = 0.00399).

`ADH_HIGHVSLOW` will be included as a predictor for `AGG_PHYS_CHANGE`.

[Top of Tabset](#EDA)

## Frailty Related Phenotype

Frailty related phenotype was strongly correlated to pysical QOL change in the correlation matrix.

Let’s assess that relationship.

```{r}
# Filter out NA values
data_no_na <- data_wide_2 %>% filter(!is.na(FRP_2))

# Create boxplots of physical QOL change by frailty related phenotype at year 2
ggplot(data_no_na, aes(x = FRP_2, y = AGG_PHYS_CHANGE, fill = FRP_2)) +
  geom_boxplot(alpha = 0.5) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel2") +
  labs(title = "Boxplot of Physical QOL Change by Frailty Related Phenotype",
       x = "Frailty Related Phenotype",
       y = "Physical QOL Change") +
  guides(fill = guide_legend(title = "Frailty Related Phenotype"))
```

There is a very strong association here: those with frailty related phenotype have a large decrease in physical QOL over 2 years compared to those without a frailty related phenotype, who seem to have barely had any decrease in physical QOL at all.

Let's assess this relationship with a regression.

```{r}
# Perform regression predicting physical QOL change by Frailty Related Phenotype
model <- lm(AGG_PHYS_CHANGE ~ FRP_2, data = data_wide_2)

# Examine Summary
summary(model)
```

The overall model is statistically significant (F~(1,541)~ = 72.39. On average, those with a frailty related phenotype had a change in physical QOL that was 12.79 points lower than those without a frailty related phenotype (p < .0001).

`FRP_2` will be included as a precision variable for the full model predicting  `AGG_PHYS_CHANGE`.

[Top of Tabset](#EDA)

## CESD Depression

```{r}
# Perform regression predicting physical QOL change by depression
model <- lm(AGG_PHYS_CHANGE ~ CESD_2, data = data_wide_2)

# Examine Summary
summary(model)
```

Is sig. but teeny tiny amount, not really needed.

[Top of Tabset](#EDA)

## LEU3N

```{r}
# Perform regression predicting physical QOL change by CD4+ T Cell Count
model <- lm(AGG_PHYS_CHANGE ~ LEU3N_CHANGE, data = data_wide_2)

# Examine Summary
summary(model)
```

Is sig but that doesn't even make sense cause that's one of our outcome variables.

Unless we're making this a complex model with multiple inputs.

[Top of Tabset](#EDA)

## College Education

```{r}
# Perform regression predicting physical QOL change by college education
model <- lm(AGG_PHYS_CHANGE ~ EDUC_COLLEGE, data = data_wide_2)

# Examine Summary
summary(model)
```

Not sig baby. Don't need to include.

[Top of Tabset](#EDA)

## Age

```{r}
# Perform regression predicting physical QOL change by age
model <- lm(AGG_PHYS_CHANGE ~ age_2, data = data_wide_2)

# Examine Summary
summary(model)
```

Woohoo, not sig, don't need to include.

## BMI

```{r}
# Perform regression predicting physical QOL change by BMI
model <- lm(AGG_PHYS_CHANGE ~ BMI_2, data = data_wide_2)

# Examine Summary
summary(model)
```

Is significant.

## DKGRP

```{r}
# Perform regression predicting physical QOL change by drinking group
model <- lm(AGG_PHYS_CHANGE ~ DKGRP_2, data = data_wide_2)

# Examine Summary
summary(model)
```
 Could maybe include

## Multicollinearity 

I just need to recheck what I just did for multicollinearity tho.

[Top of Tabset](#EDA)

:::
::::::

# Data Analysis {#Data_Analysis}

Now we will perform the actual analysis.

ADD STUFF HERE ABOUT THE STATISTICAL HYPOTHESES IN LATEX NOTATION.

## Log Viral Load Change

::: panel-tabset

## Log Viral Load Change

```{r}
# Refactor reference level of hard drug use group back to Never User
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform final model regression predicting log viral load change by hard drug use group, adherence group, and college education
model_log_VLOAD1 <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_wide_2)

# Examine summary
summary(model_log_VLOAD1)

# Refactor reference level of hard drug use group to Previous User
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform final model regression predicting log viral load change by hard drug use group, adherence group, and college education
model_log_VLOAD2 <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + EDUC_COLLEGE, data = data_wide_2)

# Examine summary
summary(model_log_VLOAD2)

# Testing with an interaction term. I don't believe this is the appropriate method.

model_log_VLOAD <- lm(VLOAD_log_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + EDUC_COLLEGE + hard_drugs_grp*ADH_HIGHVSLOW, data = data_wide_2)

summary(model_log_VLOAD)
```
I guess the interaction term shows that there is an interaction for never and previous users, based on adherence. Look into this more later. It may be that never users with low adherence are different from previous users with high adherence!! HOW TO INTERPRET??

So it seems that adherence IS a confounder for drug use.

When we ran `drug_use_grp` by itself as a predictor on log viral load, the overall model was significant, but after correcting for multiple pairwise comparisons, none of the between-group comparisons was significant (p > 0.05).

However, after including `ADH_HIGHLOW` in the model, the overall model was still significant, but now the current vs never drug use comparison is significant, even after performing a bonferroni correction (p-adjusted = 0.0447). This is in comparison to the model without ADH, where this same p-adjusted value was 0.1377. The beta coefficient is not > 10% different, however based on the shifts in the p-values, I will conclude that adherence is a confounder for the relationship between hard drug use and log viral load.

Take a look at the unadjusted vs adjusted CIs for hard drug use groups.

Add stuff here about pre-inclusion and post-inclusion SEs and parameter estimates.

2.50 2.65

```{r}
model_anova <- aov(VLOAD_log_CHANGE ~ hard_drugs_grp * ADH_HIGHVSLOW, data = data_wide_2)

summary(model_anova)
TukeyHSD(model_anova)
```
Based on the results of the ANOVA, we can see that at high adherence, there is no difference between the never and previous drug use groups (p = .9835298). However, there is a difference when 
adherence for both groups is low (p = 0.0000455) and when never users have high adherence and previous users have low adherence (p = 0.0000001), but NOT when Previous Users have High Adherence and Never User have Low Adherence (p = 0.9687938).

In other words, the relationship between never and previous drug users depends on adherence. If adherence is high, then there is no statistical difference in log viral load change over 2 years between both groups. However, if adherence is low

In other words, previous hard drug users can make up for the impact of hard drug use on log viral load by having high adherence to the treatment regiment. Where if they have high adherence, their log viral loads are comparable to those who never used hard drugs.

How to show that in a plot??

CHECK HERE IF THERE IS AN ASSOCIATION BETWEEN HARD DRUG USE GROUP AND ADHERENCE

IF YES THEN ADHERENCE IS A CONFOUNDER

Under the classical but not but not operational definition (% change not > 20%). It is therefore a Maverick variable!!!


Under the classical definition of a confounder, a variable Z is a confounder if:

 - 1) It is associated with outcome Y
 - 2) It is associated with PEV X
 - 3) It is not on the causal pathway (not a mediator)
 
To assess if Adherence is associated with hard drug use group, we can run a chi-square test

```{r}
# Make a contingency table for hard drug use and adherence high vs low
contingency_table <- table(data_wide_2$hard_drugs_grp, data_wide_2$ADH_HIGHVSLOW)
contingency_table

# We have to run Fisher's Exact test since we have fewer than 5 observations in some categories
fisher_test <- fisher.test(contingency_table)

fisher_test
```

They are NOT associated. Which means that adherence is NOT a confounder????? But it basically is.

However, it is NOT necessary for this associaton to be statistically significant for there to be important confounding present.

In our case I think we conclude adherence IS a confounder for the relationship between hard drug use and log viral load.

ADD INTERPRETATIONS HERE.

[Top of Tabset](#Data_Analysis)

## Test

:::

## CD4+ T Cell Count Change

The second outcome variable of interest was change in CD4+ T Cell Count over the first 2 years of the study.

::: panel-tabset

## Full Model 

The candidate variables for inclusion in our model predicting `LEU3N_CHANGE` were `LEU3N_CHANGE are `hard_drugs_grp`, `ADH_HIGHLOW`, `BMI_2`, `FRP_2`, and `EDUC_COLLEGE`.

We begin by examining the full model with the PEV, potential confounder, and all potential covariates.

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform regression on CD4+ T Cell count change by hard drugs group, include adherence as confounder, and BMI, frailty related phenotype, and college education as precision variables.
model_LEU3N_full <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + BMI_2 + FRP_2 + EDUC_COLLEGE, data = data_wide_2)

# Exmamine the summary
summary(model_LEU3N_full)
```

```{r}
# Gather p-values of the model
p_values <- summary(model_LEU3N_full)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model_attach), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```


Relevel to set previous user as the reference category and re-run the model.

```{r}
# Relevel to change to the reference group to previous user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression on CD4+ T Cell count change by hard drugs group, include adherence as confounder, and BMI, frailty related phenotype, and college education as precision variables.
model_LEU3N_full <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + BMI_2 + FRP_2 + EDUC_COLLEGE, data = data_wide_2)

# Exmamine the summary
summary(model_LEU3N_full)
```

```{r}
# Gather p-values of the model
p_values <- summary(model_LEU3N_full)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model_attach), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```


The overall model is significant (F~(6,454)~= 9.62, p < .0001). 

Current hard drug users have an average change in CD4+ T Cell count that is 118.45 cells lower than never drug users (p-adjusted < 0.0001), and previous drug users have an average change in CD4+ T Cell count that is 94.636 cells lower (p-adjusted = 0.0190) than never drug users, while controlling for all the other variables in the model. The other between group comparisons were not significant (p-adjusted > 0.05).

`ADH_HIGHLOW` is now significant in the full model (p = 0.02463), when it was not by itself. This means that, while controlling for hard drug use and the precision variables in the model, those who had high adherence to the treatment regiment had a change in CD4+ T Cell count that was 75.017 cells higher than those with low adherence on average.

For precision variables, we can see that `BMI` is now statistically significant (p = 0.00603), when it was not so by itself. `FRP_2` is still a significant predictor (p = 0.00343).

However, `EDUC_COLLEGE` is not longer a predictor of `LEU3N_CHANGE` when controlling for the other variables in the model (p = 0.15395).

[Top of Tabset](#Data_Analysis)

## Reduced Model

Let's examine a reduced model excluding `EDUC_COLLEGE`., since it was no longer significant in the full model.

```{r}
# Relevel to change to the reference group to Never user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform regression on CD4+ T Cell count change by hard drugs group, include adherence as confounder, and BMI, FRP, as precision variables.
model_LEU3N_red <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + BMI_2 + FRP_2, data = data_wide_2)

# Exmamine the summary
summary(model_LEU3N_red)

# Gather p-values of the model
p_values <- summary(model_LEU3N_red)$coefficients[,4] # This line selects the fourth column of the resulting coefficients table from summary(model_attach), which is the p-values

# Perform Bonferroni correction 
p_adjusted <- p.adjust(p_values, method = "bonferroni")

# Compare adjusted p-values to unadjusted p-values
p_comparison <- cbind(p_values, p_adjusted)
pretty_print(p_comparison)
```

```{r}
# Relevel to change to the reference group to previous user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression on CD4+ T Cell count change by hard drugs group, include adherence as confounder, and BMI, FRP, as precision variables.
model_LEU3N_red <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + BMI_2 + FRP_2, data = data_wide_2)

# Exmamine the summary
summary(model_LEU3N_red)

# Get the 95% CIs
conf_intervals <- confint(model_LEU3N_red)
pretty_print(conf_intervals)
```
```{r}
# Relevel to change to the reference group to previous user
data_wide_2$hard_drugs_grp<- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression on CD4+ T Cell count change by hard drugs group, include adherence as confounder, and BMI, FRP, as precision variables.
model_LEU3N_red <- lm(LEU3N_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + BMI_2 + FRP_2, data = data_wide_2)

# Exmamine the summary
summary(model_LEU3N_red)
```


The previous relationships all hold, with a similar adjusted R-squared (0.1011 in the full model, now 0.09901). 

We can perform a nested F-Test to determine if the additional variable of `EDUC_COLLEGE` in the full model significantly improves the model fit compared to the reduced model without it.

```{r}
# Perform a nested/partial F-Test to compare the full and reduced model
anova(model_LEU3N_full, model_LEU3N_red)
```

The partial F-test is not signifant (p = 0.154), and we conclude that the addition of `EDUC_COLLEGE` does not significantly improve the model fit. Thus the reduced model without it will be considered the final model for `LEU3N_CHANGE`.

[Top of Tabset](#Data_Analysis)

### [Conclusion:]{.underline}

The overall model is significant (F~(6,455)~= 11.11, p < .0001). 

Current hard drug users have an average change in CD4+ T Cell count that is 115.502 cells lower than never drug users (95% CI: 165.88 cells to 65.13 cells lower; p-adjusted < 0.0001), and previous drug users have an average change in CD4+ T Cell count that is 107.272 cells lower (95% CI: 166.54 cells lower to 48.00 cells lower; p-adjusted = 0.00249) than never drug users, while controlling for all the other variables in the model. Previous and current drug users did not differ in CD4+ T Cell count change over 2 years (p-adjusted > 0.05).

Adherence to the treatment regiment was a significant predictor for change in CD4+ T Cell count over 2 years, while controlling for hard drug use and the precision variables in the model (t = 2.30, p =  0.0219). Those who had high adherence to the treatment regiment had a change in CD4+ T Cell count that was 76.60 cells higher than those with low adherence on average (95% CI: 11.17 to 142.019 cells higher).

BMI is a significant predictor of change in CD4+ T cell count over 2 years, while controlling for the other variables in the model (t = 2.974, p = 0.00310). On average, every 1 unit increase in BMI is associated with a 6.24 cell increase in CD4+ T cell count (95% CI: 2.12 to 10.38 cells higher).

Frailty related phenotype is a significant predictor for change in CD4+ T Cell count over 2 years, while controlling for the other variables in the model (t = -2.901, p = 0.0039). On average, those with a frailty related phenotype had a change in CD4+ T Cell count that was 104.74 cells lower than those without a frailty related phenotype (95% CI: 175.69 to 33.79 cells lower).

[Top of Tabset](#Data_Analysis)

:::

## Mental QOL Change

The candidate variables for mental QOL change as determined by interactive variable selection are `hard_drug_grp`, `ADH_HIGHLOW`, `CESD_2`.

::: panel-tabset

## Full Model

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform regression on mental QOL change by hard drugs group, include adherence highlow and depression score.
model_MENT_full <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + ADH_HIGHVSLOW + CESD_2, data = data_wide_2)

# Exmamine the summary
summary(model_MENT_full)
```


## Reduced Model 1

Let's try that removing `hard_drugs_grp`

```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform regression on mental QOL change by adherence highlow and depression score.
model_MENT_red1 <- lm(AGG_MENT_CHANGE ~ ADH_HIGHVSLOW + CESD_2, data = data_wide_2)

# Exmamine the summary
summary(model_MENT_red1)
```

Adherence is no longer significant.

What about with an interaction term?
```{r}
# Relevel to change to the reference group to never user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform regression on mental QOL change by adherence highlow and depression score.
model_MENT_red2 <- lm(AGG_MENT_CHANGE ~ ADH_HIGHVSLOW + CESD_2 + ADH_HIGHVSLOW*CESD_2, data = data_wide_2)

# Exmamine the summary
summary(model_MENT_red2)
```

there's no interaction

```{r}
# Perform regression on mental QOL change by adherence highlow and depression score.
model_MENT_red3 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + CESD_2, data = data_wide_2)

# Exmamine the summary
summary(model_MENT_red3)
```


```{r}
# Relevel to change to the reference group to previous user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression on mental QOL change by adherence highlow and depression score.
model_MENT_red3 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + CESD_2, data = data_wide_2)

# Exmamine the summary
summary(model_MENT_red3)
```

```{r}
# Relevel to change to the reference group to Never user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform regression on mental QOL change by adherence highlow and depression score.
model_MENT_red4 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + CESD_2 + hard_drugs_grp*CESD_2, data = data_wide_2)

# Exmamine the summary
summary(model_MENT_red4)
```

```{r}
# Relevel to change to the reference group to Previous user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Previous User")

# Perform regression on mental QOL change by adherence highlow and depression score.
model_MENT_red4 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + CESD_2 + hard_drugs_grp*CESD_2, data = data_wide_2)

# Exmamine the summary
summary(model_MENT_red4)
```

We have interaction. That just looks really crazy to interpret...

Let's try plotting it.

```{r}
# Create a scatterplot of mental QOLchange by depression score, colored by hard drug use group.
ggplot(data_wide_2, aes(x = CESD_2, y = AGG_MENT_CHANGE, color = hard_drugs_grp)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  labs(title = "Mental QOL Change by Depression at 2 years, Colored by Hard Drug Use Group",
       y = "Mental QOL Change",
       x = "Depression Score") + 
  scale_fill_brewer(palette = "Pastel2")
```

Does this show previous drug users are dealing with withdrawls and mental pains of quitting still?

Yeah I guess so.

Maybe the downsides of the drug are so bad that taking hard drugs helps with it??

```{r}
# Relevel to change to the reference group to Never user
data_wide_2$hard_drugs_grp <- relevel(data_wide_2$hard_drugs_grp, ref = "Never User")

# Perform regression on mental QOL change by adherence highlow and depression score.
model_MENT_red5 <- lm(AGG_MENT_CHANGE ~ hard_drugs_grp + CESD_2 + ADH_HIGHVSLOW + hard_drugs_grp*CESD_2, data = data_wide_2)

# Exmamine the summary
summary(model_MENT_red5)
```

So we def don't include adherence into this model.

The main driver of mental QOL change is not adherence to the protocol, but drug use and depression scores!!!

Do I have to predict depression scores with mental QOL??? Or adherence??? 

:::

_______
TO DO: PERFORM BACKWARDS SELECTION AND COMPARE THE RESULTING MODEL WITH MY MANUALLY SELECTED MODEL USING AICC AND BIC AND PICK BEST MODEL.
_____

# Backwards Selection

# CONSORT Flow Chart

Here is where I will go back and add details for how many participants we removed at each stage.

This function is useful for tabulating missing data for each variable.

```{r}
# Print number of missing data for each column 
kable(colSums(is.na(data_2)), format = "html", col.names = "Missing") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

# To do

-   Go back and add title and axes labels to all your plots dude
-   investigate these to analyze non normal data: quantile regression, best normalized r package, gamma link GLM

"The transformations contained in this package and implemented in bestNormalize are reversible (i.e., 1-1), which allows for straight-forward interpretation and consistency. In other words, any analysis performed on the normalized data can be interpreted using the original unit (see application)." Cool.

```{r}
library(mice)

imputed_data <- mice(mtcars, m = 5, method = 'pmm', maxit = 50, seed = 500)

# Check the imputed data
summary(imputed_data)

complete_data <- complete(imputed_data, 1) # 1 refers to the first imputed dataset
complete_data

```

variables he said he'd include BMI, educbase, smoking

Filtered table 1 based on likely variables for end model. or atleast dropping the crunk ones

```{r}
# Create Table 1 for the wideform data set,stratified by hard drug use group
table1 <- table1(~AGG_MENT_0 + AGG_PHYS_0 + BMI_0 + HBP_0 + CESD_0 + SMOKE_0 + DKGRP_0 + LEU3N_0 +  VLOAD_log_0 + ADH_HIGHVSLOW + RACE_WHITEYN + EDUC_COLLEGE + age_0 + AGG_MENT_CHANGE + AGG_PHYS_CHANGE + VLOAD_log_CHANGE + LEU3N_CHANGE| hard_drugs_grp, data = data_wide_2, caption = "Descriptive Statistics at Baseline", overall = c(left="Total"))
table1
```
______________
Checking for multicollinearity between BMI and College education

`BMI` may still be associated with another outcome variable, so we should check for multicollinearity between `BMI` and `EDUC_COLLEGE`. 

```{r}

data_wide_2$EDUC_COLLEGE <- as.numeric(data_wide_2$EDUC_COLLEGE)

# # Perform a point-biserial correlation to see if BMI and college education are correlated.
point_biserial <- cor.test(data_wide_2$BMI_0, data_wide_2$EDUC_COLLEGE)
point_biserial
```

The correlation between `BMI` and `EDUC_COLLEGE` is not significant (p = 0.083) or strong enough (r = 0.075) to be of concern. Both variables can be included in models without raising issues of multicollinearity.


# Bonus

Out of curiosity I started look into the 8 year relationships we have in this data set, and found some interesting results.


I think I have to do an analysis of aggregate QOL scores predict adherence or dropout...

```{r}
p <- ggplot(data, aes(x = years, y = AGG_MENT, color = ADH)) +
  geom_point()

ggplotly(p)
```

```{r}

# Get rid of that value of 1 for adherence at baseline for patient 426
data$ADH[data$years == 0] <- NA

# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_QOL = mean(AGG_MENT, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_QOL, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Mental QOL Score by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average Mental QOL Score",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

Success! This is very interesting. It appears that the 100% adherence group has the highest average mental QOL score across the 8 year study, followed by the 95-99% group, followed by the \<75% group and followed by (with some variation) the \<75% and 75-94% groups.

I think we're on to something here. This could mean that better adherence was improving mental QOL and thus patients were continuing the regimen. OR it could mean that for patients whom the medication was affecting negatively mentally, they adhered less to the drug or lessened their dose to control for adverse psychological effects.

Let's do the same thing but for `AGG_PHYS`.

```{r}
# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_QOL = mean(AGG_PHYS, na.rm = TRUE))

# Create plot
ggplot(summary_data, aes(x = years, y = Average_QOL, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average Physical QOL Score by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average Physical QOL Score",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups
```

We see a similiar relationship here, though there's more variation. For some reason that \<75% group likes to spike in their QOL at year 7. Interesting.

What about for our other outcome variables while we're at it?

```{r}
# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_LEU3N = mean(LEU3N, na.rm = TRUE))

# Create plot
p <- ggplot(summary_data, aes(x = years, y = Average_LEU3N, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average LEU3N  by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average LEU3N",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups

ggplotly(p)

```

```{r}
# Create log vload variable for original 8 year data set.
data$VLOAD_log <- log(data$VLOAD)

# Get means for each year
summary_data <- data %>%
  group_by(ADH, years) %>%
  summarize(Average_VLOAD_log = mean(VLOAD_log, na.rm = TRUE))

# Create plot
p <- ggplot(summary_data, aes(x = years, y = Average_VLOAD_log, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average VLOAD log by Adherence Group Over 8 Years",
       x = "Year",
       y = "Average VLOAD log",
       color = "Adherence Group") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups

ggplotly(p)
```

That's very interesting. The groups with the highest vload log had the least adherence. There is an inverse relationship here.

This is strong evidence that the treatment is efficacious and the `ADH` should be considered as a confounder.

Ohhhhh, that's super cool. So there is an inverse relationship between `LEU3N` and `VLOAD_log`, such that spikes in one should be dips in the other. We can see that in this data set! It appears that for the adherence group of \<75%, they had viral load spikes at years 5 and 7, which correspond with leukocyte dips at years 5 and 7! They weren't adhering to the protocol, which resulted in them getting infected (?) more and having more of the virus present compared to the other groups.

What about if we do this by hard drug use group?

```{r}
# Get means for each year
summary_data <- data %>%
  group_by(hard_drugs, years) %>%
  summarize(Average_VLOAD_log = mean(VLOAD_log, na.rm = TRUE))

# Create plot
p <- ggplot(summary_data, aes(x = years, y = Average_VLOAD_log, color = hard_drugs)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average VLOAD log by Hard Drug Use Over 8 Years",
       x = "Year",
       y = "Average VLOAD log",
       color = "Hard Drug Use") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups

ggplotly(p)
```

This looks like those that use hard drugs have a lower log vload over the entire study. Is that because hard drug use is being confounded with adherence?

dunno how to read that...

```{r}
# Assuming your dataset is called data_long and has columns: ID, Year, and Outcome_Var

# Step 1: Create a variable to indicate dropout
data <- data %>%
  group_by(newid) %>%
  mutate(Dropout = ifelse(any(is.na(VLOAD_log)), 1, 0))

# Step 2: Create a summary dataset to show the dropout status
dropout_status <- data %>%
  group_by(newid) %>%
  summarize(Dropout = max(Dropout))

# Check the result
head(dropout_status)



```

```{r}
summary_data <- data %>%
  group_by(Dropout, years, ADH) %>%
  summarize(Average_VLOAD_log = mean(VLOAD_log, na.rm = TRUE))

p <- ggplot(summary_data, aes(x = years, y = Average_VLOAD_log, color = ADH, linetype = as.factor(Dropout))) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Average VLOAD log by Adherence Group and Dropout Status Over 8 Years",
       x = "Year",
       y = "Average VLOAD log",
       color = "Adherence Group",
       linetype = "Dropout Status") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups

ggplotly(p)
```

```{r}
# Assuming your dataset is called data_long and has columns: ID, Year, and Dropout
dropout_summary <- data %>%
  group_by(years, ADH) %>%
  summarize(Dropout_Count = sum(Dropout, na.rm = TRUE))

# Check the summarized data
head(dropout_summary)
```

```{r}
# Create plot
p <- ggplot(dropout_summary, aes(x = years, y = Dropout_Count, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Dropout Count by Adherence Over 8 Years",
       x = "Year",
       y = "Dropout Count",
       color = "Adherence") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups

ggplotly(p)
```

```{r}
# Summarize total participants per ADH group and year
total_participants_per_adh <- data %>%
  group_by(years, ADH) %>%
  summarize(Total_Participants = n_distinct(newid))


# Summarize dropout count and calculate dropout percent per ADH group
dropout_summary <- data %>%
  group_by(years, ADH) %>%
  summarize(Dropout_Count = sum(Dropout, na.rm = TRUE)) %>%
  left_join(total_participants_per_adh, by = c("years", "ADH")) %>%
  mutate(Dropout_Percent = (Dropout_Count / Total_Participants) * 100)


# Create plot
p <- ggplot(dropout_summary, aes(x = years, y = Dropout_Percent, color = ADH)) +
  geom_line(size = 1) +   # Line plot
  geom_point(size = 2) +  # Add points for clarity
  labs(title = "Dropout Percent by Adherence Over 8 Years",
       x = "Year",
       y = "Dropout Percent",
       color = "Adherence") +
  theme_minimal() +       # Clean theme
  scale_color_brewer(palette = "Pastel2")  # Nice color palette for groups

ggplotly(p)
```

I dunno how to read this lol

Is there more dropout based on adherence?

Is there more dropout based on quality of life?

[**does QOL predict adherence?**]{.underline}

```{r}
model_test <- lm(AGG_MENT_CHANGE ~ ADH_2, data = data_wide_2)

summary(model_test)

```

It does... that's not good I think.

```{r}
model_test_phys <- lm(AGG_PHYS_CHANGE ~ ADH_2, data = data_wide_2)
summary(model_test_phys)
```

It also does for `AGG_PHYS`... weird.

Compared to those with 100% adherence, those with 75-95% had a physical change score that was 3.66 points lower.





# Weird relationship with depression and mental QOL

If we plot it with depression at baseline, the relationship is positive, opposite of expected.

If we plot it with depression at 2 years, the relationship is negative, as expected.

```{r}
# Create a scatterplot of mental QOL change score by depression at baseline
ggplot(data_wide_2, aes(x = CESD_0, y = AGG_MENT_CHANGE, color = CESD_0)) + 
  geom_point() +
  theme_minimal() +
  labs(title = "Mental QOL Change by Depression at Baseline",
       y = "Mental QOL Change ",
       x = "Depression Score") + 
  scale_fill_brewer(palette = "Pastel2")
```

There appears to be a linear relationship here. Let's run the regression and fit the model.

```{r}
# Perform a linear regression predicting mental QOL change by depression at baseline
model <- lm(AGG_MENT_CHANGE ~ CESD_0, data = data_wide_2)

# Examine model summary
summary(model)
```

```{r}
# Create a scatterplot of mental QOL change score by depression at baseline
ggplot(data_wide_2, aes(x = CESD_0, y = AGG_MENT_CHANGE, color = CESD_0)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal() +
  labs(title = "Mental QOL Change by Depression at Baseline",
       y = "Mental QOL Change ",
       x = "Depression Score") + 
  scale_fill_brewer(palette = "Pastel2")
```

Depression score is a significant predictor of mental QOL change over the first 2 years of treatment (F~(1, 527)~= 92.64). On average, a 1-point increase in depression score is associated with a 0.41 point increase in mental QOL score (p < 0.0001).

This is the complete opposite of what is expected. Those with more depression should have lower mental QOL. Is this due to confounding?


If we plot it with depression at 2 years, the relationship is negative, as expected.

```{r}
# Create a scatterplot of mental QOL change score by depression at baseline
ggplot(data_wide_2, aes(x = CESD_2, y = AGG_MENT_CHANGE, color = CESD_2)) + 
  geom_point() +
  theme_minimal() +
  labs(title = "Mental QOL Change by Depression at Baseline",
       y = "Mental QOL Change ",
       x = "Depression Score") + 
  scale_fill_brewer(palette = "Pastel2")
```

There appears to be a linear relationship here. Let's run the regression and fit the model.

```{r}
# Perform a linear regression predicting mental QOL change by depression at baseline
model <- lm(AGG_MENT_CHANGE ~ CESD_2, data = data_wide_2)

# Examine model summary
summary(model)
```

```{r}
# Create a scatterplot of mental QOL change score by depression at baseline
ggplot(data_wide_2, aes(x = CESD_2, y = AGG_MENT_CHANGE, color = CESD_2)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal() +
  labs(title = "Mental QOL Change by Depression at Baseline",
       y = "Mental QOL Change ",
       x = "Depression Score") + 
  scale_fill_brewer(palette = "Pastel2")
```



Should I calculate a depression change score???

